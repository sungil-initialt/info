[IDE]
-sts : spring(boot) 연동 강점
	-java project(pojo) : pojo 프로젝트를 구성한다. new>project>java>java project
	-web project(tomcat base) : tomcat을 통한 기본 서블릿 구성. new>project>web>dynamic web project
	-svn project : svn에서 checkout 받아 프로젝트 구성. new>project>SVN>checkout projects from SVN>기본 연결된 repo에서 가져올지 새 repo를 연동해서 가져올지 정함
	
	-maven project
		-maven project(new) : new>project>Maven>Maven Project>quickstart>
			-group id : local/remote repo(.m2)에 위치하는 경로(?), 코드의 pakage와는 무관하지만 pakage 경로와 통일성 있게 쓰기도 함
			-artifact id : project 이름으로 사용되며 패키징 파일(jar,war)의 이름이 됨 
			-version : pakage 파일(jar,war)의 초기 버전 설정, 실제 repo에 가보면 group-id(경로)>artifact명>virsion 순으로 저장됨
			-package : code상의 class pakage 경로
			
		-maven project(exist) : import>Maven>Check out Maven Project from SCM(git등 연동), Existing Maven Project(로컬파일)
	
		-Add Dependency : project에 필요한 lib를 추가 할수 있음(직접 pom 파일을 건들지 않는게 좋음)
			-project(클릭)>maven>Add Dependency>필요한 lib 검색 후 선택 (Enter groupid, artifact.. 입력란에서 검색해 봄. ex) log4로 검색해봄> 검색된 리스트에서 선택하면 pom에 적용됨
				-Scope : 해당 lib(dependency가 적용되는 범위, 테스트때만 필요한건지 최종 패키징에도 포함될지 말지..)
					-compile : ??
					-provided : ??
					-runtime : ??
					-test : ??
					-system : ??
		-Add Plugin : dependency와 동일한 개념으로 필요한 maven plugin(빌드 또는 deploy 하는 과정에서 필요로 하는 plugin등)을 추가 할수 있음 
			-project(클릭)>maven>Add Plugin>필요한 Plugin 검색 후 선택, ex) deploy로 검색해봄
			
	-git project :
	
	-spring boot project :
		-import Spring Getting Started Content : Spring starter가 제공하는 project 유형별 샘플을 통해 프로젝트 구성. new>project>spring Boot>import Spring Getting Started Content>프로젝트 유형 및 빌드타입(maven/gradle)선택
		-Spring Starter Project : Spring starter가 제공하는 주요 dependency를 추가하여 프로젝트 구성. new>project>spring Boot>Spring starter Project>빌드타입(maven/gradle) 및 dependency 선택.
	
	-Eclipse plugin : 개발관련 IDE 플러그인 추가
		-Eclipse Marketplae : 
			-ANSI Escape in Console 
			-Buildship Gradle Integration 3.0
			-Darkest Dark Theme with DevStyle CI 2019.6.17
			-Eclipse Marketplace Client 1.7.7
			-Eclipse XML Editors and Tools 3.14
			-EGradle Editor 2.6.1
			-Enhanced Class Decompiler 3.1.1
			-Enide(Studio)2015
			-Enide.p2f
			-Gradle IDE pack 3.8.x
			-Minimalist Gradle Editor 1.0.1
			-Multiproperties 1.4.0
			-Nodeclipse/Enide Gradle for Eclipse 0.17
			-pmd-eclipse-plugin 4.6.0
			-Quick Search for Eclipse 3.9.9.RELEASE
			-Spring Tools 4
			-Subclipse 4.3.0
			
	-shortcut Keys
		-CTRL+SHIFT+T : class 찾기
		-CTRL+SHIFT+R : 파일 찾기		
		-CTRL+E : 열려진 파일 목록
		-CTRL+F7 : view 목록 

		-CTRL+M : 창 확대
		-CTRL+SHift+{ : 한파일 분할해 보기
		
		-CTRL+I : indentation 교정
		-CTRL+SHIFT+O : import 정리
		-CTRL+1 : fix 제안
		-ALT+Left/Right Arrow : 최근 작업 파일 이동				
	
	-문제 해결
		-red-x icon : java 에러가 파일에 반영이 되지 않는 경우 확인, project->build automatically 확인
		-Hangs when building project : copying resources to output folder
			
	-bookmark : 원하는 위치에서 코드 라이 맨 앞에서 오픈쪽 마우스 클릭 -> add bookmark ->bookmarks(general) view에서 확인 가능
	-task : 원하는 위치에서 코드 라이 맨 앞에서 오픈쪽 마우스 클릭 -> add task ->tasks(general) view에서 확인 가능
	
	
	-debuging : 
	
	
	
-atom : git 연동 강점, 특정 language에 제한되지 않는다. (editplus 같은 느낌임)
	
	
 
[JAVA]
-class 실행 : java -cp target/classesName
-jar 실행 : java -jar target/jarFileName.jar MainClassFileName (실행가능 jar파일로 패키징 되어 있어야 함)

-System property : 
	- JVM 고유값 : System.getProperty("java.vm.version")
	- 코드 상에서 추가 : 클레스페스 내부의 yml 파일을 프로퍼티로 올림
		-----------
		System.setProperty("spring.config.location", "classpath:/application-rstg.yml");
		-----------
	- JVM 구동시 param으로 전달 : -D my.id=sungil

-Handler and Listener : Handler는 어떤 역할을 담당하기 위한 클레스, Listener는 어떤 객체를 모니터링(상태 체크)하기 위한 클레스
	-doxxx(method) : Handler에서 보통 사용되는 method 이름
	-xxxCreated, xxxDestroyed(method) : Listener에서 보통 사용되는 method 이름
	
-ThreadLocal : 동일한 스레드에서만 공유되는 일종의 전역적 변수입니다. 
	-웹 서비스에서 Request는 스레드기반이므로 동일 요청에서 호출된 메서드에서는 동일한 ThreadLocal 변수를 참조할 수 있습니다.(일반적인 WAS 서버가 Thread Pool 방식을 사용하기 때문에 재사용시 반드시 remove를 통해 초기화 필요)
	- InheritableThreadLocal : 하위 Thread에서 변수를 공유하기 위해서는 InheritableThreadLocal 로 생성해야 함
	
-this and this() :
	-this : 자신의 클레스 변수를 의미
		-----------
		private int myValue = 10;
		
		void myMethod(int value){
			this.myValue = value;
		}
		-----------
	
	-this([params]) : 생성자가 여러개 있는 클레스의 경우 생성자 메서드 내에서 다른 생성자를 호출하는 의미
		-----------
		Class MyClass {
			private initValue;
			
			void MyClass(){
				this("default"); // 다른 생성자 메소드를 호출하는 방식
			}			
			void MyClass(String value){
				this.initValue = value;
			}
		-----------
		
-Thread and Runable : Thread를 만들기 위한 class and implement 
	-----------
	class MyThread extends Thread{ 
		public void run(){ //overwirte 
			for(int i=0; i<1-; i++) System.out.println(i);
		}
	}
	
	class MyRunable implements Runable{
		public void run(){ //overwirte 
			for(int i=0; i<1-; i++) system.out.println(i);
		}
	}
	
	class MyMain{
		public static void main(String args[]){
			Thread myThread = new MyThread();
			myThread.start();
			
			MyRunable myRunable = new MyRunable();
			Thread myRunalbeThread1 = new Thread(myRunable);
			Thread myRunalbeThread2 = new Thread(myRunable); //myRunable 객체를 재활용 할수 있다(메모리 이점)
			myRunalbeThread1.start();
			myRunalbeThread2.start();
			
			//Thread myRunalbeThread = new Thread(()->{System.out.println();}); 람다로 작성할수도 있음
		}
	}
	-----------
	-Runable 장점 : Thread에 비해 장점을 갖음
		-extends 하지 않으므로 extends가 필요한 경우 사용할수 있다.
		-Thread 객체와 동작 메소드(run)를 구분하여 클래스를 생성 할수 있다. 이경우 메서드를 여러게 만든다면 runalble 객체를 재활용(공유)하여 사용할수 있다. (메모리 이점이 생긴다)
		-일회성 클래스의 경우 람다 또는 instance class를 생성하여 코드 작성을 간단히 할수 있다.

		
-Thread and join() : 해당 Thread가 작업을 완료할때 까지 호출자 클래스가 wait 함 (Thread 안에서 Thread를 생성하면 APP 전체는 멀티쓰레드로 동작하면서 필요에 따라 하위 Thread가 종료될때까지 상위 Thread를 대기 시킬수 있다)
	-----------
	Thread myThread = new Thread();
	myThread.start();
	
	try {
		myThread.join(); //이 지점에서 콜러 쓰레드는 myThread가 작업을 종료할때까지 wait하게 됨, myThread.join(5000); 최대 wait 시간을 설정할 수도 있다.
	} catch (InterruptedException e) {
		System.out.println(t1.getName() + " interrupted");
	}
	
	System.out.println("end");
	-----------

-enum (class): class 와 유사한 형태의 열거체, 이름과 값을 동시에 사용할수 있다(boolean 의 true/false, 0/1 처럼) index 번호도 알수 있음
	-선언 :
		-별도 class 형태 : 별도의 자바 파일로 생성
			-----------
			enum Rainbow {
			  RED, ORANGE, YELLOW, GREEN, BLUE, INDIGO, VIOLET //선언 끝에 ;(세미콜론) 없음
			}	

		-class 내부 형태 : class 파일 내부에 inner class 형태로 생성
			-----------
			public class Myclass{
				...
				enum Rainbow {
					//()를 통해 상수에 값을 할당 할수 있음 (boolean 의 True=1 과 같은 의미)
					RED(3), ORANGE(10), YELLOW(21), GREEN(5), BLUE(1), INDIGO(-1), VIOLET(-11); //내부 선언시 끝에 ; 있음					

					//상수에 값을 할당 했으면 값을 가져오기 위한 생성자 및 메소드를 enum 내부에 구현 해야함
					private final int myValue;		  		  
					Rainbow(int value) { 
						this.myValue = value; 
					}
					public int getMyValue() { 
						return myValue; 
					}
				}
			}
			-----------
			
	-사용 :	
		-----------
		public void myTest() {
			Rainbow myRainbow = Rainbow.RED;				
			Rainbow yourRainbow = Rainbow.BLUE;
			
			if(myRainbow.compareTo(yourRainbow) < 0) {
				System.out.println(myRainbow);
				System.out.println(myRainbow.name());
				System.out.println(myRainbow.getMyValue());
				
				for(Rainbow rainbow : Rainbow.values()) {
					System.out.println(rainbow);
				}
			}
		}
		-----------
	
-call by value & reference 
	-call by value : 기본 type(int, long, String..), 값만 복사해서 넘어감
	-call by reference : 기본 타입이 아닌 클래스, 해당 클레스의 "주소변수"를 복사해서 새로운 "주소변수"를 넘김(두개의 "주소변수"에서 "가리키는" 실제값의 주소는 동일함)

		-----------
		String a ="a", b = "b"; 
		public void mytest1(String c, String d) { //내부에서 하는 어떤 행위도 origin 값에 영향을 못준다.		
		-----------
		Myclass c = new Myclass()
		Myclass d = new Myclass()
		public void mytest1(Myclass c, Myclass d) { //위의 c,d 와 메소드 네의 c,d는 동일한 실제값의 주소를 가리키지만 해당 4개의 주소 변수는 모두 각각임
			c.setName(d.getName); //주소를 통해 실제 object의 값을 변경했으므로 origin 값이 바뀐다.
			c = d;                //메소드 내의 c는 메소드 밖의 c와 다른 변수임으로(실제값의 같은 주소를 보기하지만) 메소드내의 c의 주소값을 변경해도 메소드 밖의 c에 주소값에는 영향이 없다
		-----------	
		
-Generic : 데이터의 타입(data type)을 일반화 하는것, 아직은 알수 없는 클래스 타입을 임의로 잡아놓고 처리하는것, 프레임워크 기술에서 많이 사용됨
	- 이전에는 모든 클래스를 대표하는 object 클래스를 사용하였으나, 실제 사용에서 다시 타입 케스팅을 하는등 오류가 여지가 많았음. (1.7부터 generic 지원)
		-----------
		class My3Lists<T1, T2, T3> { //클래스 이름옆에 임의의 타입을 적는다.
			ArrayList<T1> al = new ArrayList<T1>(); //필요한 위치에 아직 알수 없는 임이의 타입을 이용한다.
			ArrayList<T2> a2 = new ArrayList<T2>();
			ArrayList<T3> a3 = new ArrayList<T3>();	

			void metho1(T1 element) {...    	
			}
		}
		-----------
		//다향한 조합의 리스트를 갖은 클래스로 생성해 낼수 있다.
		My3Lists<Integer, Integer, Integer> myList1 = new My3Lists<>();
		My3Lists<String, String, String> myList2 = new My3Lists<>();
		My3Lists<Integer, String, Long> myList3 = new My3Lists<>();
		-----------

-Reflection : java.lang.reflect.*패키지를 이용하여 주어진 특정 객체(클래스)의 정보를 분석(확인)할 수 있는 기술, https://www.geeksforgeeks.org/reflection-in-java/
	-해당 객체가 어떤 메소드, 어떤 필드를 갖고 있는지 알수 있다.
	-스트링을 값을 통해 해당 이름의 메소드 및 필드에 호출(접근)할 수 있다. 다시말해 메소드 및 필드 접근을 컴파일 이후 실시간으로 처리할 수 있다(획기적인?)
	-주로 프레임워크 기술 또는 개발툴, 디버깅툴 개발 기술에 활용 된다.

-Callback & listener & handler : 본질적으로 유사하다, 개발자 측면에서 다른점은 callback은 상황이 될때 이걸 호출해줘(처리할코드를포함), listener은 특정 상황이 될때 이걸 호출할께 여길 구현해놔, handler는 이것좀 처리해줘(메시지를 보낸다) 요청하면 처리른 main(?) 프로세스에서 
	-callback : callback interface를 구현한 클레스를 main(?) 프로세스에 넘겨주는 형태로 구현하며 main은 특점 시점에 넘겨받은 callback 클레스의 특정 메소드를 호출한다.
	-listener : mina framework의 OnConnected, OnDisconnected 또는 android view에서 OnClick 등과 같이 framework로 부터 전달되는 이벤트에 대해 처리하는 방식이다.
	-handler : Android에서 UI 처리를 위해서 main 쓰레드로 메시지를 보내는 것이 예가 될수 있다 (받은 메세지는 메시지큐에 쌓이고 looper가 돌며 해당 메시지를 핸들러의 처리하는 곳으로 넘긴다)



[build automation tool]
-maven : Apache, Apache License 2.0
	-의존성 관리(개발자마다 다를수 있는 lib 버전등을 명시적으로 관리), 패키징 처리(war, jar..), 버전과 릴리즈 관리, 원격 저장소 배포 지원	
	-maven 설치
		-https://maven.apache.org/download.cgi 에서 다운로드
		-Windows : 제어판 > 시스템 등록 정보 > 고급 > 시스템 환경 변수 추가 Path 항목에 java/bin와 maven/bin 위치 추가
		-Mac & Linux : bash 정보 파일에서 Path java/bin와 maven/bn 위치 추가 (mvn --version 으로 테스트)
		
	-main goals
		-validate : ??
		-clean : target 폴더를 비워준다
		-compile : target/classes 에 컴파일
		-test : ??
		-package : pom에 명시된 패키징 수행(jar, war..)
		-install : local repo(사용자/.m2)에 install 수행
		-deploy : remote repo에 배포
		
	-maven project Dir 구조 : https://maven.apache.org/guides/introduction/introduction-to-the-standard-directory-layout.html
		-src/main/java(언어)/package : 실제 소스
		-src/test/java(언어)/package : maven 빌드시 테스트를 위한 클래스가 위치한다. src/main/java/package와 동일한 패키지 처럼 동작하나 빌드 package(jar..)에 포함되지 않는다.
		
	-pom 파일 : code 관련 dependency(lib) 및 build 나 deploy 관련 plugin을 정의한다. (직접 치지 말고 STS의 Add Dependency 또는 Add Plugin 활용할 것)
	
	-repository
		-local repository : central에서 down 받아 local에 저장된 repo, install시 빌드된 package가 저장되기도 한다. (사용자/.m2 에 위치)
		-central repository : local repo에 없는 의존성을 다운받기 위한 repo, 기본 위치는 https://repo.maven.apache.org/maven2/
		-plugin repository : maven plugin을 다운받을 수 있는 repo (컴파일 기능등을 위한 3rd p`arty? 정확히 몰겠음??)
		
	-versioning
		-x.x-SNAPTION : 개발진행 중임을 나타낸다.
		-x.x.x : release 버전
		-관용표현 : x.x-RC(release candidate), -M(milestone release), -RELEASE(release 버전)
		
	-maven Command :
		-mvn dependency:tree
		-mvn clean
		-mvn compile
		-mvn test
		-mvn package
		-mvn deploy
		-mvn install
		
	-maven build elements
		-----------
		<build>		
			<!-- package 파일명 -->
			<finalName>Maven-Webapp</finalName>
		
			<!-- resource 폴더를 인식하게 해줌 -->
			<resources>
				<resource>
					<directory>src/main/resources</directory><filtering>true</filtering>
				</resource>
			</resources>			
			
			<!-- mvn exec:java로 실행 가능하도록 해줌 -->
			<plugins>
				<plugin>
					<groupId>org.codehaus.mojo</groupId>
					<artifactId>exec-maven-plugin</artifactId>
					<configuration>
						<mainClass>com.sungil.H2_JPA.App</mainClass>
					</configuration>
				</plugin>		
			
				<!-- target 폴더에 libs 폴더를 만들어 maven-dependency 라이브러리를 카피해줌 -->
				<plugin>
					<groupId>org.apache.maven.plugins</groupId>
					<artifactId>maven-dependency-plugin</artifactId>
					<executions>
						<execution>
							<id>copy-dependencies</id>
							<phase>prepare-package</phase>
							<goals>
								<goal>copy-dependencies</goal>
							</goals>
							<configuration>
								<outputDirectory>
									${project.build.directory}/libs
								</outputDirectory>
							</configuration>
						</execution>
					</executions>
				</plugin>

				<!-- 메인 클레스를 알고있는 jar를 만들고(실행 가능 jar 생성) 해당 jar 실행시 참고할 libs 폴더를 알수 있게 해줌 (libs가 실제 jar에 포함되는 것은 아님) -->
				<plugin>
					<groupId>org.apache.maven.plugins</groupId>
					<artifactId>maven-jar-plugin</artifactId>
					<configuration>
						<archive>
							<manifest>
								<addClasspath>true</addClasspath>
								<classpathPrefix>libs/</classpathPrefix>
								<mainClass>
									com.sungil.H2_JPA.App
								</mainClass>
							</manifest>
						</archive>
					</configuration>
				</plugin>

				<!-- 모든 libs 및 기타 doc 파일을 실제 jar에 포함되도록 함 -->
				<plugin>
					<groupId>org.apache.maven.plugins</groupId>
					<artifactId>maven-assembly-plugin</artifactId>
					<executions>
						<execution>
							<phase>package</phase>
							<goals>
								<goal>single</goal>
							</goals>
							<configuration>
								<archive>
									<manifest>
										<mainClass>
											com.sungil.H2_JPA.App
										</mainClass>
									</manifest>
								</archive>
								<descriptorRefs>
									<descriptorRef>jar-with-dependencies</descriptorRef>
								</descriptorRefs>
							</configuration>
						</execution>
					</executions>
				</plugin>				
				
				<!-- mvn jetty:run 로 실행할 수 있게 해줌 -->
				<!-- http://www.eclipse.org/jetty/documentation/current/jetty-maven-plugin.html -->
				<plugin>
					<groupId>org.eclipse.jetty</groupId>
					<artifactId>jetty-maven-plugin</artifactId>
				</plugin>

				<!-- Default is too old, update to latest to run the latest Spring 5 + jUnit 5 -->
				<plugin>
					<groupId>org.apache.maven.plugins</groupId>
					<artifactId>maven-surefire-plugin</artifactId>
				</plugin>
				
				<plugin>
					<groupId>org.apache.maven.plugins</groupId>
					<artifactId>maven-war-plugin</artifactId>
				</plugin>
			</plugins>		
		</build>	
		-----------
		
		
-gradle : build automation system. 빌드 스크립트(Groovy, Kotlin 언어)에 논리적 개념(프로그램 처럼)을 적용, java뿐 아니라 여러 언어 프로젝트 지원
	-DSL : Domain Specific Language (Groovy 기반)
		-Internal(비공개) :
		-Incubating(실헝) :
		-Public(공개) : 
		-Deprecated(패지) : 
		
	-장점 : 
		-xml을 사용하지 않아 장황하지 않고 간결하다.
		-Groovy 언어를 기반으로 하기때문에 변수, if, else, for 등의 로직을 포함할 수 있다.
		-공식 사이트에 문서화가 잘되어 있다. (변화 속도가 빠르므로 가능한 공식 사이트를 이용하자)
		-빌드 속도를 개선하기 위한 여러 준비가 있다
			-증분 빌드 :
			-작업 결과 캐싱 :
			-증분 하위 작업 :
			-데몬 프로세스 재사용 :
			-병렬 실행 :
			-병렬 다운로드 :
			
		-멀티 프로젝트 지원 : 하나의 Repository에 여러 프로젝트를 구성할 수 있다.		
		-유연성, 확정성 :
			-Groovy 기반 스크립팅을 통해서 다양한 기능을 스크립트안에 직접 구현할 수 있다. (system 정보를 읽어 빌드시 이용등..)
			-직접 Task를 구현하고 플러그인을 만들어 기능을 추가할 수도 있다.
			-Plugin 허브를 지원하며 유용한 plugin을 이용할 수 있다.
				-checkstyle, pmd, findBugs, Sonar, Lint : 소스코드 정적 분석 툴을 적용하면 빌드시, 룰에 어긋나는 코드를 경고한다(리포트도 만들어줌)
				-jacoco, cobertura, clover, sonarqube : 테스트 커버리지 툴을 적용하면 빌드시, 테스크 커버리지에 대한 리포트가 만들어지고, 경고를 띄우는 등의 설정도 가능하다.
		
	-설치 : 
		-Groovy 설치시 Library가 포함되어 있어 별도 설치 필요 없음
		-https://gradle.org/releases/ : 공식 사이트를 통해 다운로드 (5.6.2 binary-only)
			-unZip binary : C:\Program Files\Gradle (적당한 위치)에 다운받은 압축을 풀고 저장
			-환경변수 설정 :
				-GRADLE_HOME : C:\Program Files\Gradle\gradle-5.6.2
				-path 설정 : C:\Program Files\Gradle\gradle-5.6.2\bin				
	
	-기본구조
		- gradle/wrapper/gradle-wrapper.jar : 생성된 프로젝트를 이후 어느 시스템에서도(java나 gradle이 설치되지 않은) 빌드할수 있도록 빌드가 가능한 환경 자체를 포함함
			-gradle build : system에 설치된 gradle 환경을 이용하여 빌드
			-./gradle build : gradle-wrapper.jar을 이용하여 빌드
			
		-gradle/wrapper/gradle-wrapper.properties : gradle-wrapper에 대한 설정 파일
		-gradlew.bat : 윈도우용 실행 스크립트 (gradlew build = gradle-wrapper.jar을 이용하여 프로젝트 빌드)
		-gradlew : 리눅스용 실행 스크립트 (gradle.bat 과 동일 기능)
		-build.gradle : 의존성이나 플러그인 설정 등을 위한 스크립트 파일 (pom.xml과 유사), 하위 프로젝트가 있는경우 프로젝트 별로 각각의 build.gradle을 갖는다.
		-settings.gradle : 프로젝트의 구성 정보(어떤 하위프로젝트들이 어떤 관계로 구성되어 있는지) 파일이다. Gradle은 이 파일을 토대로 프로젝트를 구성한다.
		
	-settings.gradle 구성 요소 : 
		-----------
		rootProject.name = 'algorithm' //최상위 프로젝트
		include 'java' //하위 프로젝트
		include 'java::kotlin' //하위의 하위 프로젝트
		-----------
			
	-build.gradle 구성 요소 :
		-----------
		plugins { // 빌드(컴파일??)를 위한 plugin 
			id 'org.springframework.boot' version '2.1.8.RELEASE'
			id 'io.spring.dependency-management' version '1.0.8.RELEASE'
			id 'java'
		}

		group = 'com.sungil' // 패키지의 그룹?
		version = '0.0.1-SNAPSHOT' // 패키지 버전
		sourceCompatibility = '1.8' //java 호환 버전

		configurations {
			compileOnly {
				extendsFrom annotationProcessor
			}
		}

		repositories {
			mavenCentral()
		}

		dependencies { // 컴파일을 위한 dependencies
			implementation 'org.springframework.boot:spring-boot-starter-data-jpa'
			implementation 'org.springframework.boot:spring-boot-starter-jdbc'
			implementation 'org.springframework.boot:spring-boot-starter-web'
			compileOnly 'org.projectlombok:lombok'
			annotationProcessor 'org.projectlombok:lombok'
			testImplementation 'org.springframework.boot:spring-boot-starter-test'
		}		
		-----------


-jenkins server : continuous integration and continuous delivery (CI/CD) server(pipeline) written in Java, Stable release	2.176.1, MIT License
	-jenkins 설치 : java 설치 필수 
		-$wget -q -O - https://pkg.jenkins.io/debian/jenkins.io.key | sudo apt-key add - : apt로 설치하기 위해 jenkins repo를 접속하기 위한 key 값을 받아 온다
		-$sh -c 'echo deb http://pkg.jenkins.io/debian-stable binary/ > /etc/apt/sources.list.d/jenkins.list' : apt list에 jenkins repo 추가
		-$sudo apt updatesudo : apt 업데이트
		-$apt install jenkins : jenkins install (설시시 자동 서비스 등록 및 실행)
		-$systemctl status jenkins : 서비스 상태 확인
		-$sudo ufw allow 8080 : 방화벽 오픈 (sudo ufw status 확인, port 변경(vi /etc/default/jenkins 에서 HTTP_PORT=XXXX 변경 후 restart)		
	
	-user 생성 및 환경 설정 : (https://linuxize.com/post/how-to-install-jenkins-on-ubuntu-18-04/)	
	
	-주요 메뉴
		-첫화면 : jenkins의 모든 빌드 상태를 보여줌
		-새로운 Item : 새 빌드 추가 (하나의 빌드 환경을 하나의 Item으로 보는 듯), Freestyle, Maven, Pipeline, Git등 여러 템플릿 선택 가능
		-사람 : Users 정보 (새 유저 등록 방법은 ??)
		-빌드 기록 : 모든 빌드 기록
		-프로젝트 연관 관련 : ??
		-파일 핑거프린트 확인 : 어떤 빌드 패키지(jar, war..)의 빌드 번호가 몇 인지 확인할 수 있다.
		-Jenkins 관리 : 연동 환경에 대한 설정(설치된 plugin에 따라 다양한 설정이 필요)
			-System Admin 정보 : email
			-Maven 관련 : Local Maven Repository 위치, 
			-Git 정보 : ??
			-Pipeline :
		-My Views : 로그인 사용자 Item 빌드 상태를 보여주는 View
		-Lockable Resource : ??
		-Credentials : ??
		-New View : jenkins의 모든 Item의 빌드 상태를 보여주는 view를 추가해줌(filter 및 기타 컬럼 지정 하여 customize 함)
		
		-Build 시나리오
			-jenkins + maven + svn : jenkins 서버의 maven local repo로 빌드 
				-sts에 코드 작성 및 svn commit : main/java 와 test/java, Resouces파일(해당시), pom.xml 들을 commit
				-jenkins Item(maven) 생성 : 소스코드관리>Repository URL(끌고올 프로젝트의 svn주소), Credentials(svn 계정, jenkins에서 생성하여 연동)
				-Build Now : 빌드 처리				
				-Console Output : 빌드 결과 확인
					-빌드결과, 테스트결과 확인
					-jenkins의 workspace 확인 가능 (svn에서 소스를 가져다논 위치), /var/lib/jenkins/workspace/projectName/
					-jenkins가 빌드한 package를 저장한 maven local repo 확인 가능, /var/lib/jenkins/.m2/repository/groupName/projectName/
					
	
[server/os]
-ubuntu : 18.xx LTS(long-term support)
	-Commands : 활용 높은 Commands
		-특정 프로그램(install)의 관련 파일 위치 확인 : dpkg --listfiles firefox
		-TCP 네트워크 사용 상태 확인(port) : sudo lsof -i -n -P | grep TCP | more
		-비밀번호 변경 : passwd
		
		



[VM/Hypervisor, Container]
-VirtualBox : oracle
	-take(snapshot) : 메모리 상태등을 포함한 현재 서버를 프리징(특정 서버 상태로 돌아갈수 있다)
	-clone : 현재 서버를 복제(여러개의 vm 실행 가능)
	-host2guest, guest2guest 현결을 위한 셋팅
		- Network : Host-only-Adapter 설정
		- File>Host Network Manage>comfigure adapter manually(host의 vip 셋팅, maskset 셋팅, dhcp enable) - host의 vip가 guest의 dhcp 또는 gateway ip가 됨

-Docker : 커널을 공유함, Docker is a platform for developers and sysadmins to develop, deploy, and run applications with containers.
	-Images : A container is launched by running an image. An image is an executable package that includes everything needed to run an application--the code, a runtime, libraries, environment variables, and configuration files.
	-Containerization 장점
		-Flexible: Even the most complex applications can be containerized.
		-Lightweight: Containers leverage and share the host kernel.
		-Interchangeable: You can deploy updates and upgrades on-the-fly.
		-Portable: You can build locally, deploy to the cloud, and run anywhere.
		-Scalable: You can increase and automatically distribute container replicas.
		-Stackable: You can stack services vertically and on-the-fly.

	-구조 : Docker는 이미지를 통째로 생성하지 않고, 바뀐 부분만 생성한 뒤 부모 이미지를 계속 참조하는 방식으로 동작
		-Image : 베이스 이미지에 필요한 프로그램과 라이브러리, 소스를 설치한 뒤 파일 하나로 만든 것 		
		-Container : image 파일을 실행하여 메모리로 올린 상태
		-특징 : Docker는 특정 실행 파일 또는 스크립트를 위한 실행 환경임
			-Docker는 이미지를 통째로 생성하지 않고, 바뀐 부분만 생성한 뒤 부모 이미지를 계속 참조하는 방식으로 동작
			-이미지를 저장소에 올릴 때는 자식 이미지와 부모 이미지를 함께 올려야함. 받을 때도 부모 이미지를 함께 받음. 이후에는 내용이 바뀐 이미지만 주고받음
			
	-설치 : https://docs.docker.com/install/linux/docker-ce/ubuntu/
	-docker 설치 위치 : /var/lib/docker, 이미지 파일등이 있는것 같은데 실제 파일은 권한의 이유로 볼수 없다, 보는 방법은 ??
	-docker 서비스 실행 : service docker restart 또는 systemctl restart docker
	-Docker Hub : docker image를 공유하기 위한 public Repository (https://hub.docker.com)
		
	-docker Command : docker command는 항상 root(sudo)권한으로 실행해야 함 
		-sudo를 안쓰기 위해 나의 user를 docker 그룹에 포함시킬 수 있음(sudo usermod -aG docker ${USER}, 재 로그인 필요)
		-search : docker search [특정유저]/ubuntu[:latest] (호스트가 CentOS 라도 Ubuntu image 사용 가능)
		-pull : docker pull ubuntu:latest (docker hub에서 이미지 내려 받기)
		-images : docker images [imageName] (로컬에 다운받은 이미지 목록 조회)
		-run : docker run [-i(input) -t(out) --name containerName] ubuntu [/bin/bash(실행사항)]
			-.. -v /root/data:/data (host의 /root/data를 container의 /data와 연결)
			
		-ps : docker ps [-a(stop상태포함)]
		-start : docker start {containerName 또는 ID}, 정지된 container를 다시 시작한다.(image가 아니라 container 임)
		-restart : docker restart hello, 컨테이너를 재 시작(os reboot과 유사)
		-attach : docker attach hello, 컨테이너로 접속 (bash 쉘 실행상태로 접속)
		-container 에서 나오기 : exit 또는 Ctrl+D (나오면서 stop), Ctrl+P and Q (실행상태로 나오기)
		-exec : docker exec hello apt-get install nano, 호스트 컴퓨터에서 container 내부로 명령어 보내기(실행 결과가 host 컴퓨터에 나옴, 안되는 명령어들도 있음)
		-stop : docker stop hello, container 정지
		-rm : docker rm hello, container 삭제 (메모리상에서 제거, 해당 container에서 작업한 모두 내용도 삭제 됨)
		-rmi : docker rmi ubuntu:latest, 이미지를 삭제한다.
		
	-docker file 생성 : 특정 base 이미지를 이용하여 새로운 이미지를 만들수 있는 파일 (ubuntu 베이스로 nginx가 설치된 이미지 생성)
		-Dockerfile(생성하기위한 스크립트 파일) : 파일은 원하는 위치 어디에든 만들수 있으나 파일명은 반드시 Dockerfile로 해야함
		-Dockerfile Command :
			-FROM : base 이미지				FROM ubuntu:14.04 
			-MAINTAINER : 작성자				MAINTAINER Foo Bar <foo@bar.com>

			-RUN : 스트립 실행					RUN apt-get update
											RUN apt-get install -y nginx
											RUN echo "\ndaemon off;" >> /etc/nginx/nginx.conf
											RUN chown -R www-data:www-data /var/lib/nginx

			-VOLUME : 공유 Dir				VOLUME ["/data", "/etc/nginx/site-enabled", "/var/log/nginx"]
			-WORKDIR : 시작시 실행될 명령어 위치 	WORKDIR /etc/nginx
			-CMD : 시작시 명령어 				CMD ["nginx"]

			-EXPOSE : 호스트와 연결 port			EXPOSE 80
											EXPOSE 443
											
			-ADD : Copy a file from the host machine to the new docker image ??
			-ENV : Define an environment variable. ??
			-ENTRYPOINT : Define the default command that will be executed when the container is running. ??
			-USER : Set the user or UID for the container created with the image. ??
			
		-Dockerfile Build : Dockerfile로 부터 image를 만든다.
			-docker build --tag mynewimage(이미지명):0.1(버전,디폴트 latest) ./(Dockerfile 위치) , 생성된 이미지 파일은 docker의 기본 위치로 들어간다.
			-docker run --name mynewimage -d -p 80:80 -v /root/data:/data mynewimage:0.1 , 해당 이미지 실행
				

	
[Virsion Control (VCS)]
SVN : Apache, Apache License 2.0, Central VCS 방식
	-ubuntu, apahche(web), svn : svn 클라이언트가 http 방식으로 svn에 연결할수 있도록 apache 설치 필요(일반적)
	-sudo apt install apache2 apache2-utils
	-sudo apt-get install subversion libapache2-mod-svn subversion-tools libsvn-dev
	-sudo(root)으로 설치, www-data 서비스 유저를 생성하여 관리
	-/etc/apache2/mods-enabled/dav_svn.conf 연결위한 설치 파일
	-svnadmin 명령을 통해 사용자 및 repository 생성(cli를 대체할 gui 툴이 있을듯)
	-http://, https://, file://, svn:// 여러 접속 방식 설정 가능
	
	-사용		
		-서버접속 : pc에서 TortoiseSVN 설치하여 서버 접속 (TortoiseSVN을 서버처럼 사용할수도 있는것 같음, create repository here 명령을 통해 폴더를 서버의 repo 처럼 사용가능, 잘은 모르겠음??) 
		-여러 사용자를 생성하여 각 repository 별 사용 권한을 주는 부분을 잘 모르겠음??	

Git : version control system, local에서 개발자 단독으로 사용가능, Distributed VCS 방식, 2005년 Linus Torvalds가 개발
	-빠른속도, 단순한 구조, 비선형적인 개발(수천개의 브랜치 동시 개발 가능), 완벽한 분산, 대형 프로젝트에서 검증(안정성)
	-SVN이 버전별 모든 소스코들 가지고 있다면 Git은 Base 버전과의 차이만을 가지고 있어 매우 가볍고 빠르다.
	-Git은 Github와 연동하기 전까진 많은 부분 local에서 개발자 본인을 위한 VCS 기능에 충실한 역할을 한다.
	-소스코드의 각 상태에 대한 스냅샷의 개념
	-repository에 들어간(commit) 데이터는 어떤한 경우에도 임의로 변경할수 없다 (SHA-1 해시를 사용하여 체크섬값을 갖는다.)
	
	-local에서의 코드 상태
		- working Directory : 실제 작업 디렉토리(수정되면 해당파일은 modified 상태가 됨)
		- staging Area(가상의 공간으로 index라고 부름) : 
		- git directory(Repository) : 수정된(새로생성된) 파일이 최종 commit 되어 해당 파일이 snapshot된 상태
	
	
	-git 설치
		-ubuntu : sudo apt install git-all, Source Code를 다운받아 설치도 가능(기능 수정이 필요하거나 특정 플러그인의 추가 삭제가 필요한 특별한 경우에 함)
			-기본설정 : ~/.gitconfig 또는 /etc/gitconfig 설정 (개인 설정이 우선함)
			-필수설정 : $git config --global user.name "John Doe" and $git config --global user.email johndoe@example.com
			-설정확인 : $git config --list
			
		-window : http://git-scm.com/download/win, git(git for window), cli 및 gui 환경을 제공하는 3rd party 제품 (여러 종류가 3rd party가 있는듯 함)
			-설정 : ubuntu 설정과 유사하게 하면된다.
			-GitHub Desktop
				-local에 새 git repo생성(git init 해주는 의미), 이미 존재하는 git repo를 툴에 로드, GitHub에서 clone 받아 local에 신규 git repo 생성
				-툴에 로딩되어 있는 repo에서 변경 사항이 발생시 확인할수(changes 리스트에서) 있음(바로 commit 가능, stage로 올리는 단계(add를 통해) 없이 바로 commit 하는것 같음??)				
				-툴에 로딩되어 있는 repo에 대한 commit결과를 확인할수(history 리스트에서) 있음(cli 통해 commit한 내용도 desktop에 실시간 반영됨)
				-GitHub로 push(Fetch), pull 가능 
				-툴을 GitHub 계정과 연동 가능(File>options) - GitHub에서 인증키 복사해서 사용했나??
				
			-GitHub GUI : repo 생성, 오픈, clone 기능 제공(별쓸모 없어 보임)			
			-Git CMD(deprecated) : cli를 사용할수 있도록 cmd 창을 열어줌(별쓸모 없어 보이며 deprecated 됨)
			-Git Bash : cli를 사용할수 있도록 bash 창을 열어줌 (linux command 사용해야 함)
			
			-Cit Command
				-git 처리 단계 : working Dir(빨강글씨) $git add [fileName] -> stage/index(녹색글씨) $git commit [fileName] -> Repository
				-git init : 새로운 git repo 생성, .git 디렉토리가 생성됨
				-git clone repo-url : 해당 git repo-url의 repo를 복제한다. (복제한 repo는 origin repo의 모든 이력을 포함하며 원본 repo가 해당 repo의 orgin repo가 된다.), 로컬 repo도 clone 가능??
				-git status [-s] : 해당 repo의 코드 상태 확인 (Untracked files>>새파일, modified>>수정, deleted:삭제파일)
				-git add [fileName] : 새파일 또는 변경된 파일을 stage/index 단계로 올려 준다
				-git commit [fileName] [-a(working 상태 모두)] [-m commitMessage] : stage/index 단계의 파일을 repo에 commit
				-git diff [--staged/--cached] : 수정 내용 확인
				-git rm [fileName] : 파일 삭제, 실제 working Directory 에서 삭제 가능
				-git mv oldFileName newFileName : 파일명 변경된
				-git reset fileName : staged 상태의 파일을 working 상태로 다시 내린다. (이번 커밋에서 제외가 필요할 경우)
				-git checkout -- fileName : 해당 파일을 최초 clone 했을때의 상태로 복구
				-git log [옵션이 많음] : 해당 repo의 history 확인 (Gui 툴을 쓰는게 날듯)				
				-git remote -v : 해당 repo의 origin remote 정보를 보여준다. (또한 해당 orign에 할수 있는 권한도 보여 준다(push/fetch)
				
			-Commit 수정(이미 commit된 것에 파일을 추가하고 하나의 커밋으로 보이도록 처리, 오류 커밋 직후 사용할것)
				-git add fileName : 추가할 파일을 stage/index 로 올린다.
				-git commit --amend : 직전 커밋과 하나로 만들어 준다
				
			-.gitIgnore
				-repo /(루트)에 위치해야 함, 표준 Glob 패턴을 사용한다, https://github.com/github/gitignore 참고
				
			(https://git-scm.com/book/ko/v2/Git%EC%9D%98-%EA%B8%B0%EC%B4%88-%EB%A6%AC%EB%AA%A8%ED%8A%B8-%EC%A0%80%EC%9E%A5%EC%86%8C)	
				
			-git pull and git merge : pull은 remote repo의 내용으로 local로 가져온다(complict이 날수 있음), git merge는 서로다른 브랜치의 코드를 합치는 작업

GitLap : web-based DevOps lifecycle tool that provides a Git-repository manager providing wiki, issue-tracking and CI/CD pipeline features
	-사용자 무제한 무료 (기술 서포트를 받기 위해서는 비용 지불 필요)
	-minimum requirement : 2core, 4GB (to support up to 100 users)
	-공식 사이트 : https://about.gitlab.com/update/#ubuntu
	
	-설치 : https://teamlab.github.io/jekyllDecent/blog/tutorials/%EB%82%98%EB%A7%8C%EC%9D%98-Git-%EC%84%9C%EB%B2%84-Gitlab-%EA%B5%AC%EC%B6%95
		-$sudo apt-get install curl openssh-server ca-certificates postfix : 필요한 부가 모듈 설치 (postfix=메일전송기능관련, openssh-내부적으로 필요)
		-$curl -sS https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.deb.sh | sudo bash : Gitlab 패키지 저장소 추가
		-$apt-get update : 저장소 업데이트
		-$sudo apt-get install gitlab-ce : Gitlab Community Edition 설치
		-$sudo gitlab-ctl reconfigure : 서버에 문제가 있거나 업데이트/설정 변경을 한경우 실행해 준다.
		-$sudo vi cd /etc/gitlab/gitlab.rb : 주요 설정 사항 변경
			-## external_url 'http://localhost' >> 'http(S)://localhost:9081' (port를 붙이지 않으면 80적용, ssl을 사용하기 위해서는 ip가 아닌 도메인 설정)
			-## gitlab_workhorse['auth_backend'] = "http://localhost:8080" >> "http(s)://localhost:9082" (external_url와 다른 포트를 사용해야 함)
			-## unicorn['port'] = 8080 >> 9082 (gitlab_workhorse와 동일 포트 사용해야 함)

		-$sudo gitlab-ctl reconfigure , $sudo gitlab-ctl restart , $sudo gitlab-ctl status : reconfigure 및 재 실행
		-gitlab web 접속 및 초기 설정 : root 계정의 비밀번호를 등록 한다.
		-SSL 접속 설정 : https 접속시 설정 (https://blog.lael.be/post/5476)
		
	-내부 사용 모듈 : nginx, openssh, postfix(mail), unicorn(DB??), redis ..
	-방화벽(TCP인바운드) 오픈 포트 : http(nginx=9081), https(nginx=443), ssh(openssh=22)
	
	-관리 : 
		-Backup : $sudo gitlab-rake gitlab:backup:create (환경 설정, 사용자 정보, 저장소 정보를 포함한 모든 gitlab 정보가 백업)
			-backup 위치 : /var/opt/gitlab/backups (/etc/gitlab/gitlab.rb 파일의 gitlab_rails[‘backup_path’] 에서 수정가능)
		-Recovery : 
			-/var/opt/gitlab/backups/ : 해당 위치에 백업할 tar 파일이 존재 해야함 (신규 서버에서 백업 파일을 복구할경우 이동해 준다.)
			-$sudo gitlab-ctl stop unicorn , sudo gitlab-ctl stop sidekiq : DB 관련 서비스 중지
			-$gitlab-rake gitlab:backup:restore BACKUP=1553573272_2019_03_26_11.9.0 : _gitlab_backup.tar을 제외한 백업날자 까지만 입력(확실한지 물으면 yes)
			-신규 서버로 복구시 : /etc/gitlab/gitlab-secrets.json 파일도 같이 이동 (gitlab에서 사용하는 암호화키 파일)
			-$gitlab-ctl restart : 서비스 재시작
			-$gitlab-rake gitlab:check SANITIZE=true : 복구된 체크 및 교정(해결될때까지 반복)		
		
	
Github :
BitBucket : 

Git command : 
	-merge revert : git revert 머지커밋번호(7자) -m 1 
	
Sourcetree : GIT 클라이언트 툴
	-repository 만들기 : 상단 + 탭을 이용하여 생성
		-Local : 기존에(이미) local pc에 존재하는(sourcetree에서 만들었던) reposity 목록을 보여 주고 선택시 해당 repository로 바로 연결해 준다. 
		-remote : 등록된 계정을 통해(gitlab 이든 github등) 해당 계정에 연결된 remote(계정이 있다는건 당연히 remote를 의미하겠지만)의 repository를 보여주고 clone 할수 있게 해준다.
		-clone : 이미 존재하는 (로컬이든 리모트든) repository에 접근하여 local로 clone(복제)후 연결해 준다.
		-add : 기존에(이미) local pc에 존재하는(sourcetree에서 만들었던 아니든) reposity 목록을 보여 주고 선택시 해당 repository로 바로 연결해 준다. 
		-create : 로컬에 새로운 repository를 만들어 준다.
		
	-존재하는 로컬 프로젝트를 로컬 repository로 만들고 서버 repository로 올리는 방법 :
		-create를 이용해 기존 프로젝트 폴더를 repository로 만든다. (기존 코드를 첫 커밋하기 전에 .gitignore 파일을 만들고 하는게 좋다)
			-해당 로컬 리포지토리를 서버 repository로 올리고 싶을때  :
				-서버에 Repository를 하나 먼저 만든다. 새파일(readme등)을 만들어 master 브랜치를 만든다.
					-로컬 리포지토리의 설정에 remote를 선택하여 해당 서버의 주소를 clone해서 붙여 넣는다. (fetch를 해보면 서버의 master 위치가 보임, 서로 연결고리는 없음)
						-서로 연결 고리가 없어서 pull, push, merge가 안됨
							-git command로 연결해 준다(연결성 없는 관계지만 pull 하는 옵션) : git pull origin master --allow-unrelated-histories
								-연결성이 생겼음으로 push 할 수 있게 된다.
					
	-참고: 
		-origin Branch로 local Branch로 생성 후 최초로 push 하기 위해서는 pull할 것이 없더라도 최초 origin으로 부터 pull을 한후 push 해야 한다.(최초 연결 고리가 없기 때문에 pull할께 있어도 모르기 때문)
		
		
		
		
		

[Spring]
-Spring Framework : 아래와 같은 주요 기능(Main Features)을 Dependency Injection 해줌
	-Spring JDBC
	-Spring MVC : Browser->DispatcherServlet->HandlerMapping->Controller(Bean, Model, Service, DAO, DB 이용)->DispatcherServlet->ViewResolver->View->DispatcherServlet->Browser
	-Spring Security
	-Spring AOP (aspect oriented programing) : 개발자가 핵심 로직에만 집중할수 있도록 공통 기능을 framework 에서 지원 (filter 처럼 선/후 처리를 지원하는 class 지정 가능)
	-Spring ORM (object relational mapping) : 하이버네이트, JPA 등을 이용해서 DAO 레이어를 구축하는 방식
	-Spring Test	

--Spring Boot Framework : Spring Framework의 확장형으로 설정과 관련한 편의성이 향상 되었다.
	-application configuration 이 간소해짐(xml이 사라지고 거의 모두 코드 레벨에서 어노테이션을 통해 이루어짐)
	-Tomcat 같은 서버가 Embedded 되어 패키징 됨(별도의 서버 설치나 deploy가 필요 없음)
	-Metrics, Helth check, and externalized configuration
	-Automatic config for Spring functionality – whenever possible

-Handler Interceptor : 인터셉터는 DispatcherServlet이 컨트롤러를 호출하기 전,후에 요청과 응답을 가로채서 가공할 수 있도록 해준다. 	
-HandlerMethodArgumentResolver : ??

-Spring Boot Resource : src/main/resources/static은 URL에서 Resource의 / 이다
	
-Spring Config : 		
	-WAS 설정 : WAS(tomcat)와 Spring의 연결 고리??
		-server.xml : 서버의 기본 설정, 포트, ssl, Context path 및 docBase 지정, (/tomcat/conf/..위치)
		-web.xml : 서블릿 배포 기술자(Deploment Descriptor), 서블릿의 배치, mine type 지정, welcom file 지정, error 페이지 지정, filter 지정, (/Webroot/WEB-INF/..에 또는 /tomcat/conf/..)
			-----------
			web.xml 파일에 spring 관련 context 파일의 위치를 알려준다. (서버 스타트시 같이 읽어 로딩한다.)
			-----------				
			//tomcat은 서블릿 컨테이너를 제공한는 웹서버로 자신의 기본 servlet(Catalina) Container를 이용할수도 있고 spring등 다른 컨테이너를 사용할 수도 있다.
			//사용할 container를 web.xml을 통해 설정할수 있고 동시에 여러 servlet container를 사용할 수도 있다.
			//DispatcherServlet 은 spring MVC용 서블릿인가??
			<servlet>
				<servlet-name>sungil-Servlet</servlet-name> 
				<servlet-class>org.springframework.web.servlet.DispatcherServlet</servlet-class> 
				<init-param> 
					<param-name>contextConfigLocation</param-name> 
					<param-value>/WEB-INF/config/*-servlet.xml</param-value> 
				</init-param> 
			</servlet> 
			
			<servlet-mapping> //.do 패턴은 sungil-Servlet 설정의 컨테이너에서 처리한다.
				<servlet-name>sungil-Servlet</servlet-name> 
				<url-pattern>*.do</url-pattern> 
			</servlet-mapping>				
			-----------
			
		-context.xml : ??, (/tomcat/conf/..위치)
		
		
	-Spring 내부 설정 : 예전방식(Boot 이전), 요즘은 Anotation으로 거의 처리 함
		-application-context.xml : spring 설정과 관련한 가장 상위 configuration (여러 형태의 XXX-contex.xml 파일로 쪼갤수 있다. 하나로도 뭉칠수도 있다)				
			-----------
			Datasource 관련 설정, apache의 BasicDataSource 클래스를 Bean으로 올리고 필요값들을 설정해 준다.
			-----------				
			<bean id="dataSource" class="org.apache.commons.dbcp.BasicDataSource" destroy-method="close">
				<property name="driverClassName" value="com.mysql.jdbc.Driver"/>
				<property name="url" value="jdbc:mysql://주소/스키마"/>
				<property name="username" value="아이디"/>
				<property name="password" value="비밀번호"/>
			</bean>
			-----------

			-----------
			Mybatis 관련 설정, mybatis의 SqlSessionFactoryBean, SqlSessionTemplate을 Bean으로 올려서 스프링과의 연결 고리를 만들어 준다.
			-----------
			<bean id="sqlSession" class="org.mybatis.spring.SqlSessionFactoryBean">
				<property name="dataSource" ref="dataSource" />								<!--사용할 Datasource-->
				<property name="mapperLocations" value="classpath:/mapper/**/*_SQL.xml" /> 	<!--SQL문의 위치-->
			</bean>				
			<bean id="sqlSessionTemplate" class="org.mybatis.spring.SqlSessionTemplate">
				<constructor-arg index="0" ref="sqlSession"/>
			</bean>
			-----------			

			-----------
			modelAndVew 관련 설정, controller 가 이 방식의 modelAndVew 를 쓰겠다는건 어떻게 알려주지??
			-----------
			//InternalResourceViewResolver, view.BeanNameViewResolver, MappingJacksonJsonView, UrlBasedViewResolver (여러 형태의 spring 제공 뷰가 있다)
			<bean class="org.springframework.web.servlet.view.InternalResourceViewResolver">
				<property name="prefix" value="/WEB-INF/views/" />
				<property name="suffix" value=".jsp" />
			</bean>
			-----------

			-----------
			Interceptor 관련 설정, url 페턴과 implement 클래스를 지정해 준다.
			-----------
			<mvc:interceptors>
				<mvc:interceptor>
					<mvc:mapping path="/**"/>
					<bean id="loggerInterceptor" class="com.sungil.common.logger.LoggerInterceptor"></bean>
				</mvc:interceptor>
			</mvc:interceptors>
			-----------

			-----------
			Mybatis 를 이용한 DAO 구성한다
			-----------
			public class myDAO {
				@Autowired 
				private SqlSessionTemplate sqlSessionTemplate;		//mybatis의 SqlSessionTemplate 주입

				result = sqlSessionTemplate.insert(queryId, params);		//insert	
				result = sqlSessionTemplate.update(queryId, params);		//update
				result = sqlSessionTemplate.delete(queryId, params);		//delete			
				result = sqlSessionTemplate.selectOne(queryId);				//여러 형태 select 들
				result = sqlSessionTemplate.selectOne(queryId, params);
				resultList = sqlSessionTemplate.selectList(queryId);
				resultList = sqlSessionTemplate.selectList(queryId,params);
			-----------
	
	-yaml-importer : Spring Framework 의 EnvironmentPostProcessor Cycle에 특정 path 의 Yaml 기반으로 Configure Property 를 로드하는 기능을 하는 모듈

-Spring Boot Config : server.xml, web.xml, application.xml 등을 사용하지 않고 주로 어노테이션을 사용하여 설정을 정한다.(스프링은 전체 클레스의 어노테이션 스캔을 통해 해당 클레스가 어떤역할을 위한 클레스인지를 알수 있다.)
	-@Configuration(extend WebMvcConfigurerAdapter) : spring 설정과 관련한 클레스임을 알린다. 
		-특히 WebMvcConfigurerAdapter 클래스를 상속 받아 server.xml, web.xml, application.xml 의 설정을 대신 할수 있다.
				
-Spring boot Filter(필터) : 스프링 필터 클레스를(여러형태가있음) 상속받아 @Component 어노테이션을 통해 만들수 있다.
	-필터가 적용되는 지점 : Filter, Interceptor, AOP (Filter는 Servlet 엔진(Servlet Context)에서 주관, Interceptor는 Spring(Application Context)에서 주관, 컨테이너 진입 전(후), AOP는 메소드 단위에 걸수 있다.	
	-필터 생성 : 
		-----------
		@Component
		@Order(1) //필터 적용 순서를 명시할 수 있다.
		public class MyFilter1 implements Filter {	//Spring은 여러 형태의 Filter 클레스를 제공한다. (Filter 클레스가 가장 기본)
			@Override
			public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException {
				HttpServletRequest req = (HttpServletRequest) request;
				//..하고싶은 코드 작성
				LOG.info("Starting a transaction for req : {}", req.getRequestURI()); //Spring 컨테이너로 진입 전 처리			
				chain.doFilter(request, response); //다음필더 적용(모든 필터가 처리되면 실제 컨트롤로 로직까지 처리된 후 복귀함)
				//..하고싶은 코드 작성
				LOG.info("Committing a transaction for req : {}", req.getRequestURI()); //후 추리
			}
		}
		
		@Component
		@Order(2)
		public class MyFilter2 implements Filter {	
		...
		-----------
	
	-필터 적용 :
		-----------
		@Configuration //config class 에서 AbstractFilterRegistrationBean을 상속받은 class를 bean으로 잡는것으로 처리 가능 
		public class MyConfiguration extends WebMvcConfigurerAdapter
			...
			
			@Bean //MyFilter1을 특정 url(/users/*)에만 적용하고 싶은 경우
			public FilterRegistrationBean<MyFilter2> loggingFilter(){
				FilterRegistrationBean<MyFilter2> registrationBean = new FilterRegistrationBean<>();					 
				registrationBean.setFilter(new MyFilter2());
				registrationBean.addUrlPatterns("/users/*");					 
				return registrationBean;    
			}	

			@Bean //MyFilter2는 특정 url(/produc/*)에만 적용하고 싶은 경우
			public FilterRegistrationBean<MyFilter2> loggingFilter(){
				FilterRegistrationBean<MyFilter2> registrationBean = new FilterRegistrationBean<>();					 
				registrationBean.setFilter(new MyFilter2());
				registrationBean.addUrlPatterns("/produc/*");					 
				return registrationBean;    
			}
		}
		-----------

-Spring boot Interceptor(인터셉터) : 스프링 인터셉터 클레스를(여러형태가있음) 상속받아 @Component 어노테이션을 통해 만들수 있다.
	-인터셉터 생성 : 
		-----------	
		@Component
		public class MyHandlerInterceptor1 extends HandlerInterceptorAdapter {
			@Override 
			public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler){
				//controller 진입 직전, return true시 controller 진입
				return true // true=다음 interceptor chain을 실행한다.
			}
			
			@Override 
			public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView){
				//controller 처리 후 view 진입 직전, modelAndView로 view로 데이터 전송 가능
			}

			@Override 
			public void afterComplete(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex)
				//view 랜더링 이후 
			}

			@Override 
			public void afterConcurrentHandlingStarted(HttpServletRequest request, HttpServletResponse response, Object handler){
				//servlet 3.0에서 지원, postHandle, afterComplete 대신 역할
			}
		}
		-----------	

	-인터셉터 적용 :
		-----------
		@Configuration //config class 에서 AbstractFilterRegistrationBean을 상속받은 addInterceptors(InterceptorRegistry registry)를 override 함
		public class MyConfiguration extends WebMvcConfigurerAdapter{
			@Autowired
			MyHandlerInterceptor1 myHandlerInterceptor1;

			@Autowired
			MyHandlerInterceptor2 MyHandlerInterceptor2

			@Autowired
			MyHandlerInterceptor3 MyHandlerInterceptor3
			...

			@Override
			public void addInterceptors(InterceptorRegistry registry) {
				//path 패턴의 같은 경우 등록 순서대로 적용됨
				registry.addInterceptor(myHandlerInterceptor1).addPathPatterns("/user/*.do");
				registry.addInterceptor(myHandlerInterceptor2).addPathPatterns("/user/*.do", "/produc/*.do"); //여러 path 등록 가능

				//path 패턴이 없는 경우 모든 경로에 적용됨
				registry.addInterceptor(myHandlerInterceptor2);
			}
		}
		-----------



	
-Annotation : https://gmlwjd9405.github.io/2018/12/02/spring-annotation-types.html
	-@SpringBootApplication : 완전한 하나의 web application으로 인식하게 한다.
		-----------
		@SpringBootApplication
		public class StartWebApplication {
			public static void main(String[] args) {
				SpringApplication.run(StartWebApplication.class, args); //이후 @Controller로 정의된 클레스를 찾아 동작
			}
		}
		-----------

	-@EnableWebMvc : DelegatingWebMvcConfiguration(Spring MVC 설정을 담당하는 객체)에게 MVC 새 설정 사항이 있음을 알린다. (보통 @Configuration, @Bean과 함께 사용)
	-@Bean : method-level의 어노테이션, 해당 메소드의 return 객체를 spring이 관리(인스턴스)한다. 개발자가 직접 만든 클래스가 아닌(직접 만들었다면 코드에 @Component를 붙였을거임)경우 사용됨(보통 @Configuration과 함께 사용)
	-@Configuration : 해당 클래스가 Spring에서 관리할 Bean(내가수정할수없는)을 정의했음을 알린다. @Bean 과 함께 사용하여 해당 메소드의 return 객채를 Spring의 Bean으로 올린다.
		-----------
		@Configuration
		public class ApplicationConfiguration {

		@Bean(name="demoService") //name을 넣지 않으면 Return Class명을 통해 찾는다.
		public DemoManager helloWorld(){
			return new DemoManagerImpl(); //Bean으로 올릴 Class를 리턴, 이 방식을 통해 Spring의 기본 Bean들을 수정거나 다른 클래스로 대치 할수 있다.(ex.ViewResolver)
		}
		-----------
		
		@AutoConfigureBefore(After)을 통해 해당 @Configuration 클래스가 읽히는 순서를 정할수 있다.
		-----------
		@Configuration
		@AutoConfigureBefore(Myclass.class) //해당 설정을 Myclass 보다 항상 먼저 읽는다.
		public class SpringAutoConfiguration {
		}		
		
		AnnotationConfigApplicationContext를 통해 Spring에 올라온 Bean을 가져올수 있다.
		-----------
		public static void main(String[] args){
			ApplicationContext context = new AnnotationConfigApplicationContext(ApplicationConfiguration.class);
			DemoManager  myDemoManager = (DemoManager) context.getBean("demoService");
		}	
		-----------
		
	-@Component : Spring에 의해 인스턴스가 관리 된다. 개발자가 직접 만든 클레스에 적용됨
		-@Controller : 해당 클래스가 Controller 임을 알림
		-@Service : 해당 클래스가 Service 임을 알림 (spring이 DB transaction을 지원)
		-@Repository : 해당 글래스가 DAO 임을 알림, (spring이 DB Exception Translation을 지원)
		
	-@RequestMapping
		-Class Level
			-----------
			@RequestMapping("/home")
			public class HomeController {
			-----------
			
		-Handler Level(Method)
			-----------			
			@RequestMapping(value = "/employees", method = RequestMethod.POST) //method 적시를 않하면 get, post.. 모두
			public String addEmployee(Employee employee) {
			-----------
			
	-@GetMapping("/home") : http://localhost:8080/home?index=1
		-@RequestParam
			-----------
			@GetMapping("/home")
			public String show(@RequestParam("index") int index) {
			-----------
			@GetMapping("/user/{userId}/invoices")
			public List<Invoice> listUsersInvoices(@PathVariable("userId") int user,@RequestParam(value = "date", required = false) Date dateOrNull) {
			-----------
			
		-@ModelAttribute : @RequestParam의 값들을 Object로 매핑해줌
			-----------
			@RequestMapping(value="/add" method = RequestMethod.POST)
			public String add(@ModelAttribute Myinfo myInfo, BindingResult result, Model model){ //Reqest param 값을 Myinfo로 매핑요청, BindingResult=매핑 유효성 체크??, Model=view로 전달할 데이터를 담을 Object??
				...
				return "redirect:/myInfo"; //return 되는 스트링값을 viewResolver가 받아 해당 처리
			}
			-----------
		
	
	-@PostMapping("/index/{idx}") : http post만 처리 가능
		-@pathVariable("idx") :
			-----------
			@PostMapping("/index/{idx}")
			public boolean deletePost(@PathVariable("idx") int postNum) {
			-----------
	
	-@ResponseBody : 메핑 메소드의 리턴 값을(class) json 문자열 형태로 반환한다. 
	-@RequestBody : http post 요청만 처리, request body의 값을 object(messageConverter)로 읽기 위해 사용 ??
	
	-@RestController : @Controller + @ResponseBody	
		-@ResponseBody : method의 반환 결과(class)를 jason 형태로 반환
		-@Controller 와 @RestController 의 차이 : 
			-@Controller : API 또는 view(웹화면)을 처리, 주로 view 리턴이 주목적
			-@RestController : view가 필요없는 API만 지원하는 경우 사용
		
	-@required : Boot에서 사용??, bean property xml 설정시 해당 클래스가 주입 받아야 하는 필수 class를 정의 한다.
	-@Autowired : Spring에게 해당 Bean의 주입을 요청 (생성자 (@AllArgsConstructor 사용) -> 권장방식)??
		-@Qualifier : Boot에서 사용??, @Autowired를 통해 주입 요청시 동일한 이름의 클래스가 두개 존재할 경우 특정 class를 지목하기 위해 사용, Qualifier값은 xml에 적용
			-----------
			@Autowired
			@Qualifier(value="noty") //-->"noty" 값은 bean을 설정하는 xml에 정의 되었었음, boot에서 사용??
			private Boy student;
			-----------
	-@Inject : @Autowired와 동일??
	-@Resource : @Autowired와 같이 Bean의 주입을 요청, (표준 어노테이션으로 특정 framework에 종속적이 않게 하기위해 권장함)

	-@Transactional : Exception 발생시 모든 DB 작업을 롤백하기 위해 사용 (비즈니스 로직과 DB 로직이 있는 Service 모듈에 보통 적용)
	
	-@Value("${welcome.message}") : application.properties(classpath 내부 존재, 보통 resource 폴더)의 값을 초기값으로 지정함
		-----------
		@Value("${welcome.message}")
		private String message;
		-----------
	
	-@PropertySource : Property 파일을 Environment로 로딩 (yml 파일은 읽을수 없다)
		-----------
		@PropertySource("classpath:/setting-dev.properties") //동일한 키값이 있는경우 override 됨
		//@PropertySource("classpath:/setting-${spring.profiles.active:default}.properties") //환경에 따라 적용 가능(변수를 사용하여)
		//@PropertySource(value = {"classpath:/properties/example.properties","file:/data/properties/example.properties"}) 보안상의 이유로 class path 외부에 위치 시킬수 있음
		public class MyClass {

			@Resource
			private Environment environment; //property가 자동으로 매핑 됨

			public void myMethod(){
				logger.info("my.value : {}" + environment.getProperty("my.value"));
			}
		-----------
		
	
	-Spring AOP(Aspect Oriented Programming) : 주로 공통작업을 처리하기 위해 (인증, 로깅 등)
		-@EnableAspectJAutoProxy : ??
		-@Aspect : 해당 클래스가 Aspect 클래스 임을 선언
		-@PointCut : ??
		-@Before : 어드바이스 타겟 메소드가 호출되기 전에 어드바이스 기능을 수행
		-@After : 타겟 메소드의 결과에 관계없이(즉 성공, 예외 관계없이) 타겟 메소드가 완료 되면 어드바이스 기능을 수행
		-@Around : 메소드 실행 전후, 어드바이스가 타겟 메소드를 감싸서 타겟 메소드 호출전과 후에 어드바이스 기능을 수행
		-@AfterReturning : 정상적 반환 이후, 타겟 메소드가 성공적으로 결과값을 반환 후에 어드바이스 기능을 수행
		-@AfterThrowing : 예외 발생 이후, 타겟 메소드가 수행 중 예외를 던지게 되면 어드바이스 기능을 수행			

			-----------				
			@Component //Bean으로 등록
			@Aspect    //해당 클래스가 Aspect 임을 선언
			public class PerfAspect {
				//어떤 클래스의 어떤 시점에 실행될지를 정함
				@Around("execution(* com.saelobi..*.EventService.*(..))") //특정 패키지 밑에 특정 클래스
				---
				@Around("bean(simpleEventService)") // 특정 Bean이름으로 지명 할수 있다.
				---
				@Around("@annotation(PerLogging)") //특정 어노테이션이 붙은 클래스
				---
				public Object logPerf(ProceedingJoinPoint pjp) throws Throwable{
					long begin = System.currentTimeMillis();
					Object retVal = pjp.proceed(); //---->실제 클라스가 실행될 위치
					System.out.println(System.currentTimeMillis() - begin);
					return retVal;
				}
			}
			-----------
			//어노테이션 생성
			@Target(ElementType.METHOD)
			@Retention(RetentionPolicy.CLASS)
				public @interface PerLogging {
			}
			-----------
			//생성된 어노테이션을 사용
			@Component
			public class SimpleEventService implements EventService {

				@PerLogging //특정 메소드에 생성한 어노테이션을 붙인다.(어노테이션 이름으로 Aspect를 걸수 있다)
				@Override
				public void createEvent() {
					System.out.println("Created an event");
				}

				@Override
				public void publishEvent() {
					System.out.println("Published an event");
				}

				@PerLogging
				@Override
				public void deleteEvent() {
					System.out.println("Delete an event");
				}
			}
			-----------
		
	-JPA
		-@Entity : DB의 테이블과 매칭될 클래스임을 선언. (DTO는 컨트롤러에서 사용되는 객체로 주로 request, response 데이터를 담는다, Entity는 DB 고유의 상태를 가져야 함으로 둘을 분리하는것이 좋다.)
		-@Table : @Table(name = "USER"), 엔티티 클래서에 매핑할 테이블을 나타낸다.
		-@ID : 테이블의 PK 필드를 나타낸다.
		-@GeneratedValue : PK의 생성규칙 (엔티티의 PK는 Long 타입의 Auto_increment를 추천)
		-@Column : @Column(name="username"), 테이블의 컬럼과 매핑됨을 선언한다. 컬럼명이 같은경우 자동 매핑됨
	
	-@Vaild : import javax.validation.Valid
		-@Size(max=10, min=2, message=”errMsg”) : ??
		-@Email(message=”errMsg”) : ??
		-@NotEmpty(message=”errMsg”) : ??
		
	-@Configuration
		-@EnableWebSecurity
		-@SpringBootApplication
		-@EnableWebMvc
		-@RestControllerAdvice
		-@ExceptionHandler
		-@ResponseStatus
		
	-Lombok
		-@NoArgsConstructor : 기본 생성자를 추가해 주고 생성자의 접근 권한을 protected로 제한한다. (Entity 클래스를 new해서 생성하는것은 막고 JPA에 생성하는 것은 허용하기 위해)??
		-@AllArgsConstructor : 모든 필드 값을 파라미터로 받는 생성자를 추가한다.
		-@requiredArgsConstructor : final 이나 @NonNull인 필드값만 파라미티터로 받는 생성자를 추가(final이 최초 할당되면 이후 변경 불가)
		-@Getter : 클래스 내 모든 필드의 Getter() 생성
		-@Setter : 클래스 내 모든 필드의 Setter() 생성규칙
		-@ToString : @ToString(Exclude="password"), toString 메소드를 생성하며 특정 필드를 제외 할수 있다.
		-@EqualsAndHashCod : @EqualsAndHashCode(callSuper = true), 클래스의 equals() 와 HashCode()를 생성한다. callSuper = false 시 해당 메소드를 구성할때 상속받은 클래스의 정보는 활용하지 않는다.
		-@Builder : 생성자와 유사하게 클래스 생성 시점에 값을 채워주는 역할을 한다. (어떤 필드에 어떤값을 채울지 명확히 인지 가능 ??)
		-@Data : Lombok 에서 제공하는 모든 필드 관련 코드를 생성해 준다.
		
	-Json
		-@JsonManagedReference : ??
		-@JsonBackReference : ??
		-@JsonProperty : ??
		-@JsonIgnore : ??
		
	-Jackson Property Inclusion Annotation
		-@JsonIgnoreProperties : 무시할 속성이나 속성 목록을 표시할 때 사용한다. ??
		-@JsonIgnore : 필드 레벨에서 무시할 속성을 표시할 때 사용한다. ??
		-@JsonIgnoreType : ?? 
		-@JsonInclude : 어노테이션 속성을 제외할 때 사용한다. @JsonInclude(JsonInclude.Include.NON_NULL)NON_NULL 사용 시 name이 null인 경우에 제외된다. ??
		-@JsonAutoDetect : @JsonAutoDetect(fieldVisibility = JsonAutoDetect.Visibility.ANY) ??			
	
	-@ConfigurationProperties : Config 클레스를 만들면서 properties 파일을 참조하여 초기값을 셋팅할수 있게함(yml 파일도 가능)
		-----------
		@Configuration //옵션?
		@PropertySource("classpath:configprops.properties") //위치 지정이 없다면 기본값으로 클레스 페스내 application.properties 을 로딩
		@ConfigurationProperties(prefix = "service.mydb") //prefix는 옵션, "service.mydb"만 써도 됨
		public class MyDataSource { 
			private String dbUrl;
			private int dbPort; 
			// standard getters and setters
		-----------
	
	-@EnableConfigurationProperties : 특정 Bean을 특정 property 값으로 초기화 해서 생성 할수 있다.
		-----------
		@SpringBootApplication //메인 클레스 생성 시점에서 적용할 수 있다.
		@EnableConfigurationProperties(MyDataSource.class) //MyDataSource클레스를 property 값으로 초기화 하여 Bean으로 로딩한다.
		public class MainApplication {		
		-----------
		@Configuration //Configuration 클레스 생성 시점에서 적용할 수 있다.
		@EnableConfigurationProperties(MyDataSource.class)
		public class MainApplication {		
		
		
		//실제 클래스에 @ConfigurationProperties가 적용되어 있어야 하낟.
		@ConfigurationProperties("service.mydb")
		public class MyDataSource {
		-----------
	
	-
	
	-기타
		-@EnableJpaAuditing : JPA Audditing을 활성화 한다. ??
		-@MappedSuperclass : JPA Entity 클래스들이 BaseTimeEntity을 상속할 경우 필드들(createdDate, modifiedDate)도 컬럼으로 인식하도록 한다 ??
		-@EntityListeners(AuditingEntityListener.class) : BaseTimeEntity 클래스에 Auditing 기능을 포함한다.
		-@CreatedDate : Entity가 생성되어 저장될 때 시간이 자동으로 저장된다.
		-@LastModifiedDate : 조회한 Entity의 값을 변경할 때 시간이 자동으로 저장된다.
		
		-@SuppressWarnings : warn 발생을 막음(IDE에서)
				
		
	-Spring Boot Profile :  개발(dev), 테스트(test), 운영(prod) 등으로 구동 환경을 세분화하여 서비스를 관리한다. 이런 식별 키워드를 바로 Profile이라고 부른다
		-환경 변수로 설정
			-윈도우 시스템 환경 변수: 
				-변수 이름: SPRING_PROFILES_ACTIVE 
				-변수 값 : prd, stg, ...
				
			-리눅스 환경 파일로 설정 :
				-환경 파일 : vi $HOME/.bashrc
				-설정 : export SPRING_PROFILES_ACTIVE=prd ...				
			
		-실행시 파라미터 : -D옵션(시스템의 property 값을 설정한다)		
			- java -Dspring.profiles.active=dev -jar project-이름.jar
		
		-코드상으로 저정 : 
			-System.setProperty("spring.profiles.active", "dev"); //프로파일 자체를 지정
			-System.setProperty("spring.config.location", "classpath:/application-dev.yml"); //원래는 프로파일에 의해 스프링 config가 자동 로드 되지만 특정 config를 지정 하고 싶을때
			
			-테스트시 지정?? : 테스트 클레스에 @ActiveProfiles(value={"develop"}) 직접 지정 가능
		
		-사용1 : 해당 Configuration 클레스는 Profile이 develop 일때만 적용되며 읽어올 property 파일은 클레스페스 내 develop/ 데렉토리것을 읽어라
			-----------
			@Configuration
			@Profile(value="develop")
			@PropertySource({"classpath:develop/application.properties"})
			public class ProfileDevelop {
			}
			-----------

-Application.properties : spring 관련 properties 읽어 온다
	-여러 클레스페스 내 여러 application.properties 가 존재할 경우 우선순위가 높은것을 읽는다.(application-[default, dev, prod].properties)
	
-ObjectMapper : json 데이터를 변형하기 위한 객체 (json String -> boject, object -> json String)
	-----------
	//Object to JSON in file, user 객체로 부터 json String 파일을 생성
	mapper.writeValue(new File("c:\\user.json"), user); 

	//Object to JSON in String, user 객체를 json 스트링으로 변환
	String jsonInString = mapper.writeValueAsString(user);

	//JSON from file to Object, json String 파일을 읽어 user 객체로 변환
	User user = mapper.readValue(new File("c:\\user.json"), User.class);

	//JSON from String to Object, json String으로 부터 user 객체 생성
	User user = mapper.readValue(jsonInString, User.class);
	-----------

-MessageSource : 다국어 처리 메커니즘을 지원해주는 class
	-메세지 파일 형식 : [파일이름]_[언어]_[국가].properties, class path내 위치, (요건의 맞는 파일을 찾을수 없는 경우 message.properties를 기본값으로 한다.)
	-----------
	# messages_en_US.properties	
	greeting={0} and {1} are friends.
	
	# messages_ko_KR.properties
	greeting={0} 와 {1} 는 친구이다.
	-----------
	
	@Autowired
	MessageSource messageSource;

	void messageCall(){
		System.out.println(messageSource.getMessage("greeting", new String[]{"Tom", "Jerry"}, Locale.KOREA));	
	}
	-----------
	
	//자동 reload 필요시 ReloadableResourceBundleMessageSource 사용
	ReloadableResourceBundleMessageSource messageSource = new ReloadableResourceBundleMessageSource();
	messageSource.setBasename("classpath:/messages");
	messageSource.setDefaultEncoding("UTF-8");
	messageSource.setCacheSeconds(10);
	return messageSource;
	-----------

-Spring Test :
	-테스트 코드 위치 : src/test/java/
		-----------
		@RunWith(SpringRunner.class)
		@SpringBootTest(webEnvironment = RANDOM_PORT)
		public class WebControllerTest {
			@Autowired
			private TestRestTemplate restTemplate;

			@Test
			public void 메인페이지_로딩() {
				//url "/"을 호출
				String body = this.restTemplate.getForObject("/", String.class);
				assertThat(body).contains("xxx"); //본문에 "xxx" 문자열이 있으면 테스트 통과
			}
		-----------
		
[DB]
-DBMS :
	-RDB : 
		-Mysql :
		-Maria :
		
	-NoSQL DB : Not Only SQL
		-MongoDB : MongoDB is a cross-platform document-oriented database program. Classified as a NoSQL database program, MongoDB uses JSON-like documents with schema. 
			-개요 :	
				-명칭 : 
					-Database : Database는 Collection들의 물리적인 컨테이너입니다. 각 Database는 파일시스템에 여러파일들로 저장됩니다.
					-Collection : 테이블과 유사한 개념으로 Collection 내부에 Document이 위치하고 있다.
					-Document : Record와 유사한 개념, Jason 형태, 같은 Collection(테이블)에 있는 Document들이 서로 다른 형태를 갖을 수 있다.
					-embeded Document : { a:'a', b:'b', c:[{c1:'c1', c2:'c2'..},{}..]} 또는 { a:'a', b:'b', c:['c1', 'c2'..]}
					
				-장점 :
					-정해진 스키마가 없으며 같은 Collection 안에 서로다른 스키마의 Document가 있을수 있다 (데이터의 형태를 매우 유연하게 가져갈수 있다, 그래서 더 모호한 느낌도 있음)
					-복잡한 JOIN이 없으며 단일 각 Collection 의 구조(의미)가 뚜렷하다.
					-Deep Query ability 를 통해 SQL만큼의 쿼리 성능을 제공한다.
					-application의 Object를 DB에 적용할때 Conversion/Mapping이 불필요하다. (DB 자체가 json 구조임)
		
				-ubuntu install : $ sudo apt-get update, $ sudo apt-get install -y mongodb-org, $ sudo service mongod start
					-log : $ cat /var/log/mongodb/mongod.log1
					-port : 27017(default) /etc/mongod.conf
					-connect : $ mongo (터미널을 통해 접속)
					
				-schema 고려 사항 : RDB 상에서 join 할 엔티티들을 하나의 엔티티로 구성한다. 
					-read할때 collection간 join을 하려하지 말고 embeded document를 이용하여 하나의 document로 구성한다.(생성때 join 의 형태로 구성)
					-collection간 join은 하지 않는다는 것을 전제로 한다.
				
				
			-쿼리 :
				-DB 관리
					-use mydbname :  해당 이름의 db로 switch 한다. 해당 이름의 db가 없는 경우 생성하고 스위치 한다.
					-db : 현재 사용중인 db 이름을 확인 한다.
					-show dbs : db 목록을 확인 한다. (db에 하나 이상의 collection이 있어야 목록에 보임)
					-db.dropDatabase(); : 사용중인(switched) db를 삭제한다.
					
				-Collection	관리
					-db.createCollection("myCollectionName") : myCollectionName으로 collection 생성 
						-옵션 : collection 생성시 옵션을 줄수도 있다. (최대용량적용여부(롤링됨), 자동인덱스필드추가여부, 최대용량적용시사이즈(byte), document최대저장갯수)
							-----------
							db.createCollection("book", {capped: true, autoIndex: true, size: 6142800, max: 10000})
							-----------
					
					-document를 만들면서 collection이 없으면 collection도 함께 생성됨 
						-----------
						db.book.insert({"name": "MongoDB Tutorial", "author": "velopert"}); : book이란 collection이 없다면 document 입력과 동시에 생성됨
						-----------
						
					-show collections : 생성된 collection 목록 확인
					-db.collectionName.drop() : 현재 switch 된 DB에서 collectionName을 제거 한다.
					
				-Document 관리
					-insert : db.collection.insert([{document},..] or {document});					
						-db.books.insert({"name": "NodeJS Guide", "author": "Velopert"}) : book collection에 하나의 document 추가
						-db.books.insert([{"name": "Book1", "author": "Velopert"}, {"name": "Book2", "author": "Velopert"}]); : 동시에 2개 추가
					
					-find : db.book.find({query 검색조건}, {projection 보여질 필드}).sort({}).skip().limit().pretty()					
						-db.books.find().pretty() : books collection 확인(모든 document의 모든 필드가 select 됨), .pretty()는 보기 좋게 보여줌
						-db.books.find({"name": "mybook"}) : name값 mybook인 document만 확인
						-db.books.find({"likes": {$lte:30}}).pretty() : 좋아요 수가 30 이하인 것만 조회. (less than or equal)
							-비교연산 : $eq, $gt, $gte, $lt, $lte, $ne, $in, $nin  
								-db.books.find({"writer":{$in:["Alpha", "Bravo"]}}).pretty()
								
							-논리연산 : $or, $and, $not, $nor
								-db.book.find({$or:[{"title":"article01"}, {"writer":"Alpha"}]})
							
							-정규식 : i대소문자 무시, m정규식에서 anchor(^)를 사용할 때 값에\n이 있다면 무력화, x	정규식 안에있는 whitespace를 모두 무시, s	dot(.)사용 할떄 \n을 포함해서 매치
								-db.book.find({"title":/article0[1-2]/}) : /정규식/
								
							-$where 연산자 : javascript expression 을 사용 할 수 있습니다.
								-db.book.find({$where:"this.comments.length == 0"})
								
							-$elemMatch 연산자 : Embedded Document가 배열 형태이고 그 값을 조건으로 할때
								-{.., comments:[{name, ..},{}]} : comment가 여러개(배열)일수 있는데.. comment 작성자명이 Charlie 인것 검색
									-db.book.find({"comments":{$elemMatch:{"name":"Charlie"}}})
								
							-Embedded Document가 배열 형태가 아닐 경우 
								-{.., comment:{name, ..}} : comment가 배열의 형태는 아닌경우
									-db.book.find({"comment.name":"Charlie"})
							
							-Embedded Document가 값으로만 된 배열인 경우
								-{.., comments:["", ""]}} : comment가 값으로만 구성된 배열인 경우
									-db.book.find({"comment":"Charlie"})
						
						-db.articles.find({"comments":{$elemMatch: { "name": "Charlie" }}}, {"title":true, "comments.name":true, "comments.message":true})
							-댖글 배열에서 작성자가 Charlie인 사람이 들어 있는 document에서 책의 title과 댖글 배열에서 이름과, 내용을 보여준다.(여러 사람 댖글이 다 나온다)

						-db.book.find({"comments":{$elemMatch:{"name":"Charlie"}}}, {"title":true, "comments":{$elemMatch:{"name":"Charlie"}}, "comments.name": true, "comments.message":true})
							-댖글 배열에서 작성자가 Charlie인 사람이 들어 있는 document에서 책의 title과 댖글 배열에서 오직 이름이 Charlie인 사람의 댖글의 이름과, 내용을 보여준다.(Charlie인 사람의 댖글만 나옴)
								
						-db.book.find().sort({"_id":1}) : id 값으로 정렬, 1=오름, -1=내림
						-db.book.find().sort({"amount":1, "_id":-1}), 2가지 정렬 조건으로 
						-db.book.find().limit(3) : 출력 갯수를 3개로 제한
						-db.book.find().skip(2) : 시작부분의 2개의 Document 제거 (paging 처리등에 사용)
							-db.book.find().sort({"_id":-1}).skip((page-1)*2).limit(2); :2개씩 페이징 예
					
					-update : db.collection.update({query}, {update}, {upsert:true}, {multi:true}, {writeConcern:true}})
						-db.people.update({name:"Abet"}, {$set:{age:20}}) : Abet의 나이를 20으로 변경
						-db.people.update({name:"Betty"}, {"name":"Betty 2nd", age:1}) : Betty의 document의 field 값을 바꾸는 것이 아니라 전체 document를 replace(기존값은 모두 사라지고 현재 값으로 샛팅)
						-db.people.update({name:"David"}, {$unset:{score:1}}) : David의 score필드를 삭제(값이 아니라 필드 자체를 제거함, 1의 이미는 ??)
						-db.people.update({name:"Elly"}, {name:"Elly", age:17}, {upsert:true}) : Elly의 존재하면 document를 replace, 없으면 insert
						-db.people.update({age:{$lte:20}}, {$set:{score:10}}, {multi:true}) : age가 20 이하인 여러 document를 모두 update 함
						-db.people.update({name:"Charlie"}, {$push:{skills:"angularjs"}}) : Charlie의 embeded document[a,..] 형태에 값 추가
						-db.people.update({name:"Charlie"}, {$push:{skills:{$each:["c++", "java"], $sort:1}}}) : Charlie의 embeded document[a,..] 형태에 여러 값을 넣고 정렬하여 저장함
						-db.people.update({name:"Charlie"}, {$pull:{skills:"mongodb"}}) : Charlie의 embeded document[a,..] 형태에 값 제거
						-db.people.update({name:"Charlie"}, {$pull:{skills:{$in:["angularjs", "java"]}}}) : Charlie의 embeded document[a,..] 형태에 여러 값 제거

					-index : db.COLLECTION.createIndex({인덱스할필드:1,..}, {PROPERTY:true}) : 인덱스의 속성(PROPERTY)
						-db.report.createIndex({score:1}) : score값에 대한 오름차순 인덱스 생성
						-db.report.createIndex({age:1, score:-1}) : age와 score에 대한 복합 인덱스 생성
						-db.userinfo.createIndex({email:1}, {unique:true}) : email 필드를 인덱스로 만들며 해당 값은 중복될수 없다.
						-db.userinfo.createIndex({firstName:1, lastName:1}, {unique:true}) : 복합 인덱스를 만들고 해당 값(쌍)은 중복될수 없다.
						-db.store.createIndex({name:1}, {partialFilterExpression:{visitors:{$gt:1000}}}) : name으로 인덱스를 만드는데 visitors값이 1000보다 큰경우의 document만 적용(속도와 저장공간 절약가능)
						-db.notifications.createIndex({"notifiedDate":1}, {expireAfterSeconds:3600}) : 3600초 후에 해당 인덱스 제거??
					
						-db.COLLECTION.getIndexes() : 해당 COLLECTION의 인덱스 조회
						-db.COLLECTION.dropIndex({KEY:1}) : 해당 COLLECTION의 해당 인덱스 제거
						
					

-Frameworks : 
	-JDBC : Java Database Connectivity, DB 접속 및 사용을 위한 java interface (개발자의 많은 코딩이 필요함)
	-Datasource : DB 접속을 위한 정보 set(url, userId, password..) 갖는 클래스 (그 정보 자체를 말하기도 한다.)
	
	-Persistence Framework : 미들웨어 소프트웨어의 성격으로 프로그램과 DB의(보통RDB) 연결 레이어로 작동한다.
		-Mybatis : 개발자의 코드와 sql들을 연결하고 결과 매핑을 도와주는 Persistence Framework, 일반적으로 스프링에서 Dao와 DB를 연결하는 하나의 방식으로 사용됨, JDBC로 처리할때의 많은 부분을 대신 처리해줌.
			-dependency : mybatis dependency를 추가해줘야 함(mybatis-x.x.jar)
			
		-Ibatis : ?
		
	-Hibernate : ??




[Logging]
-Logging : println를 이용 한다면 개발 이후에 다 지울꺼야? 보고 실을때도 있고 안보고 싶을때는??, 오픈소스에서 모든사람이 쓰는 방식이 다를텐데? 성능, 파일저장 등의 이슈도 있다.

-java.util.logging : logging을 위한 자바 기본 로깅 클래스, 실제 프로젝트에서는 잘 활용하지 않음(더 좋은걸 사용함)

-Logging Framework : 보통 로그를 처리하는 abstraction layer(Logger)와 실제 표현하는 implement부분(Appender)으로 구분되며 이러한 implement를 바인드 하여 사용한다. 로그 레벨 및 주기등의 설정을 appenader에 정의.
	-Logger : 코드상에서 로그를 발생시키는 주체, error, warn, info 다양한 로그를 발생시킨다. 발생한 로그는 실제 처리하는 Appender 클레스로 전달된다. Appender 클래스를 지정하지 않으면 Console로 처리됨
	-Appender : 발생된 로그를 처리(어디로, 어떻게 보낼지)하기 위한 주체, Logback, Log4j등 다양한 Logging Framewor에서 다양한 Appender를 제공한다. (Logback, Log4j를 쓰는 이유임)
	-log level : FATAL(사용안함), ERROR, WARN, INFO, DEBUG, TRACE
		
	-SLF4J : SLF4J(Simple Logging Facade for Java) is basically an abstraction layer (not implement), parameterized logging 지원
		-로그 처리를 위한 중간 layer로써의 표준같은(?) 역할을 함, logback-classic을 기본 implement로 가지고 있어 별도의 logging implement를 바인딩하지 않고도 사용할 수 있음(그럴경우 console에 찍힘)
		-logback 이나 log4j 등을 바인딩 하여 사용할 수 있음
		
			-----------
			import org.slf4j.Logger;
			import org.slf4j.LoggerFactory;
			-----------
			//로그의 시작인 LoggerFactory는 항상 slf4j에서 생성(??), 
			Logger logger = LoggerFactory.getLogger(MyClass.class); //MyClass.class의 의미는 logger의 name을 "com.sungil.MyClass"로 set, 실제 스트링 값으로 입력해도 무관함.
			String myName = "sungil";
			int myAge = 40;
				
				logger.info("Name : {}, age : {}.", myName, myAge); // parameterized logging, ({}에 어떤 object 도 대입 가능 함), +string 보다 빠르다. 로그 활용성이 좋아짐.
			} catch (Exception e) {
				logger.info("Name : {}, age : {}.", myName, myAge, e); //excepton 에 대해서는 대응되는 {} 가 없어도 적용 가능.
			}
			-----------
			14:21:49.500 [main]  INFO com.sungil.MyClass - Name : sungil, age : 40.			
			   호출시간     호출스레드  로그레벨      호출클래스             로깅내용(파라미터 값)
			-----------
		
		-Logger Context 의 hierarchy 구조 : LoggerFactory.getLogger("com.sungil.MyClass.class")를 통해 Logger의 name을 셋팅하고 그 이름의 "."을 기준으로 Logger Context를 hierarchy하게 갖음.
			-----------
			a=LoggerFactory.getLogger("a"), ab=LoggerFactory.getLogger("a.b"), c=LoggerFactory.getLogger("c")
			ab는 a의 하위 context를 갖음, a.setLevel(Level.INFO) 시 ab Logger 에도 적용됨. c는 적용되지 않음
			-----------
			
			
			
	-Logback : 크게 3개로 구분되어짐 (https://www.baeldung.com/logback#example)
		-logback-core : slf4j 처럼 abstraction layer의 역할을 함
		-logback-classic : slf4j에 native 되어 있음, slf4j, log4j등과 함께 사용될 수 있다.
		-logback-access : tomcat, jetty등 servlet container와 access log를 수집하는 기능을 함(잘 모르겠음??)	
		
			-----------
			import org.slf4j.LoggerFactory;
			importch.qos.logback.classic.Logger
			import ch.qos.logback.classic.LoggerContext; 
			import ch.qos.logback.core.util.StatusPrinter;
			-----------
			qos.logback.classic.Logger logger = (qos.logback.classic.Logger)LoggerFactory.getLogger(MyClass.class); //logback Logge를 사용하기로 함
			logger.info("Name : {}, age : {}.", "sungil", 40); //기본 사용법은 slf4j와 거의 동일(제품마다 고유 메소드가 제공됨 ex=setLevel) 
			
			LoggerContext lc = (LoggerContext) LoggerFactory.getILoggerFactory(); //logback의 configuration 상태를 확인.(logback은 클래스페스 내부를 모두 scan해서 자신의 설정파일을 스스로 찾음)
			StatusPrinter.print(lc);
			-----------
			15:10:25.985 [main] INFO com.sungil.MyClass - Name : sungil, age : 40.
			15:10:25,936 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback-test.xml]
			15:10:25,937 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback.groovy]
			15:10:25,938 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback.xml]
			15:10:25,947 |-INFO in ch.qos.logback.classic.BasicConfigurator@2437c6dc - Setting up default configuration.
			//위의 설정파일을 통해 ConsoleAppender 및 여러 형태의 Appender destination(console, files, Syslog, TCP Sockets, JMS and many more)을 설정 할수 있다.			
			
		-LogBack Configuration file
			-----------		
			logback.xml (classpath 어느 위치에 있어도 됨), logback-test.xml??, logback.groovy??
			-----------		
			<configuration debug="false" scan="fase" scanPeriod="15"> <!-- 디버깅용 으로 모든 정보가 다 보여지도록 일괄 설정됨 , 설정 파일을 15초마다 재스캔하여 로드함 -->
				<statusListener class="ch.qos.logback.core.status.OnConsoleStatusListener" /> <!-- Logback 설정 정보 및 에러, 경고를 시작때 알려 준다. -->
	
				<property name="LOG_DIR" value="C:/TESTLOG/" /> <!-- 내부 변수 설정 -->
				<property name="LOG_FILE_NAME" value="myLog" />
				<property name="LOG_FILE_NAME2" value="myLog2" />		

				<!-- appender1 : console로 찍히는 기본 -->
				<appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender">
					<encoder>
						<pattern>
							%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n
						</pattern>
					</encoder>
				</appender>		
				
				<!-- appender2 : 파일로 찍히며, 파일명 설정 -->
				<appender name="FILE1" class="ch.qos.logback.core.FileAppender">
					<file>${LOG_DIR}/${LOG_FILE_NAME}.log</file>
					<append>true</append>
					<encoder>
						<pattern>%-4relative [%thread] %-5level %logger{35} - %msg%n</pattern>
					</encoder>
				</appender>	
				
				<!-- appender3 : 파일로 찍히며, 파일명 및 롤링(day, size) 기준 설정 -->
				<appender name="FILE2" class="ch.qos.logback.core.rolling.RollingFileAppender">
					<file>${LOG_DIR}/${LOG_FILE_NAME2}.log</file>
					<rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
						<fileNamePattern>${LOG_FILE_NAME2}.%d{yyyy-MM-dd}.gz</fileNamePattern>				 
						<maxHistory>30</maxHistory>
						<totalSizeCap>3GB</totalSizeCap>
					</rollingPolicy>
					<encoder>
						<pattern>%-4relative [%thread] %-5level %logger{35} - %msg%n</pattern>
					</encoder>
				</appender> 
				
				<!-- 특정 로거의 레벨 지정 (해당 패키지 이하의 로거의 기본 레벨) -->
				<logger name="com.sungil" level="INFO" />

				<!-- 로거의 root 레벨 지정  -->	
				<root level="debug" additivity="true">
					<appender-ref ref="STDOUT" />
					<appender-ref ref="FILE1" />
					<appender-ref ref="FILE2" />
				</root>
			</configuration>			
			-----------		
	
	-Log4j2 : 크게 2개로 구분되어짐
		-log4j API : slf4j 처럼 abstraction layer의 역할을 함, logback등과 연동할수 있음, parameterized logging 지원, lsf4j보다 더많은 logging api를 제공, 람다 표현식 지원
		-log4j implement : abstraction layer에 바인딩되어 사용됨


[Front End]
-MVC frame work : model(도메인, DTO, VO), View(html, jsp, thymeleap), Controller(Spring Controller) 방식의 Web frame work

-ModelAndView : model(데이터set)과 view(html)을 포함하는 object로 spring mvc의 controller의 return object로 사용될수 있다.
	-----------	
	DispatcherServlet 의 controller 일부 내용
	-----------	
	{
		ModelAndView model = new ModelAndView("employeeDetails"); /employeeDetails는 html또는 jsp 파일명(Template Engine 설정에 따라)
		model.addObject("employeeObj", new EmployeeBean(123));
		model.addObject("employeeObj", new EmployeeBean(123));
		model.addObject("msg", "Employee information.");
		return model;
	}
	-----------	

-Spring View : 화면을 렌더링 하기위해 미리 정의되어 있는 페이지 객체? 이다. Template Engines을 통해 실행되며 보통 html 파일형태로 저장, EL표기법${}을 사용한다.

-Spring View Resolver : Controller 와 view 간의 바인딩 역할을 수행한다. View Resolver의 설정을 통해 동작할 Template Engines(JstlView, Thymeleaf)이 선택 된다.

-Text Template Engines : 
	-JSP : Java Server Page
	-Freemarker :
	-JSTL : html(jsp)에 포함되어 로직을 구성할수 있게해주는 표기법(기술)	
	
	-Thymeleaf : MVC based web application에서 view 레이어에 해당, servlet에서 xml, html의 template engine으로 동작함 (JSP를 대체함)
		-----------	
		<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter-web</artifactId>
		</dependency>
		<dependency>
		<groupId>org.springframework.boot</groupId>
		<artifactId>spring-boot-starter-thymeleaf</artifactId>
		</dependency>
		-----------	
		
		controller 클래스
		-----------	
		@GetMapping("/") //@RequestMapping(value="/", method = RequestMethod.GET) 동일
		public String main(Model model) {
			model.addAttribute("message", message);
			model.addAttribute("tasks", tasks);

			//Model object의 내용을 갖고 해당 view로 return 됨
			return "welcome"; //view (thymeleaf가 적용된 html 명)
		}
		-----------	
		
		thymeleaf 적용된 html 파일, EL표기법과 유사 (보통 src/main/resources/templates/ 에 위치)
		-----------	
		<h2><span th:text="'Hello, ' + ${message}"></span></h2>	
		-----------	

-Layout Template Engines : 
	-Tiles :
	-Sitemesh :


[Cloud]
-용어 :
	-SLA(Service Level Agreement) : 해당 서비스의 성능(?), API 호출수,  장애(?) 상황등에 대한 보장 이다
	
-Azure : 

-AWS :

-GCP :


[DevOps]
-ALM : Application Life cycle Management (요구사항관리, 프로젝트일정관리를위한 Task관리, 빌드환경및형상관리자동화, 테스트자동화 등 보통 4가지 요소를 포함한다)
	-ALM 조합 예시 : JIRA+Hudson+xUnit, JIRA+Confluence+Bamboo+xUnit, JIRA+Hudson+xUnit+Mantis, Confluence+Hudson+xUnit

-Azure DevOps : Plan smarter, collaborate better and ship faster with a set of modern dev services. (프로젝트 일정, 개발 항목 관리(Scrum지원) 및 관련 CICD 기능을 제공)
	-Organization : 계정별 프로젝트 관리의 가장 큰 단위 (Organization 단위 또는 프로젝트 단위의 팀원 관리(추가/삭제)는 어떻게 이루어 지지??)
		-project : 하나의 Organization에 여러개의 프로젝트를 갖을 수 있다. 
			-Overview : 프로젝트 전반에 대한 요약 정보를 제공한다.
				-Summary : 프로젝트 소개, 관련통계, 구성원 정보
				-Dashboards : 원하는 형태의 여러개의 데시보드를 만들수 있으며 선택적으로 switch 할수 있다
				-Wiki : 해당 프로젝트와 관련한 위키 페이지를 만들 수 있다. (각 페이지의 버전 관리가 이루어진다.)
				
			
			
			-Board : 애자일 방법론을 기반으로 프로젝트의 계획, 논의, 개발, 관리, 추적등 팀원간의 성공적 업무 환경을 제공한다.(https://docs.microsoft.com/en-us/azure/devops/boards/get-started/what-is-azure-boards?view=azure-devops&tabs=basic-process)
				Work item : 자신에게 할당된 아이템과 같은 특정 기준으로 item을 검색하기 쉽다.		
					-BASIC Work item :
						-Epic :
						-Issue :
						-Task :
						
					-SCRUM Work items : 
						-Bug :
						-Epic :
						-Feature :
						-Implement :
						-Product Backlog Item :
						-Task :
						-Test Case :
						
					-Agile Work items :
						-Bug :
						-Epic :
						-Feature :
						-Issue :
						-Task :
						-Test Case :
						-User Story : -main?
					
					-CMMI Work items : 
						-Bug :
						-Change Request :
						-Epic :
						-Feature :
						-Issue :
						-Requirement :
						-Review :
						-Risk :
						-Task :
						-Test Case :
					
					

				-Board : kanban 형태의 보드로 item 의 현재 상태를 파악하고 관리하기 쉽다.
				-Backlogs : item 목록을 보여주며 plan 기능을 이용하여 item 그룹을 만들거나 조직화 할수 있다.
				-Sprints : Sprint를 생성하고 Sprint에 item을 할당해 줄수 있다
				-Queries : item들을 자기가 만든 필터를 적용하여 리스팅 할수 있다 
				
			
			-Repos : 프로젝트를 위한 Git 방식의 Private Repository를 제공해 준다.
				-Files :
				-Commits :
				-Pushes :
				-Branches :
				-Tags :
				-Pull requests :
				
			
			-Pipelines : 여러 개발언어 및 타 플랫폼(Github..)과 연동하여 빌드, 테스트, 배포 등 CICD 역할을 수행한다.
				-Builds :
				-Library :
				-Task groups :
				-Deployment groups :
				
			
			-Test Plans : 개발한 앱에 대한 기능, 성능, 부하 등 다양한 측면의 테스트가 가능한 tool을 제공한다.
				-Test plans :
				-Parameters :
				-Configurations :
				-Runs :
				-Load test :
				
			
			-Artifacts : 연계성(Library) 패키지를 생성 관리하여 간단한 방법으로 다른 Pipeline과 공유할 수 있는 방법을 제공한다. 

-Bitbucket :
-IBM Jazz

[development principles]
-Waterfall : old 스타일 개발 방법론으로 모든 프로젝트 일정이 종료되어야 product를 볼수 있음, 후반으로 갈수록 부담이 커지고 고객(요구자)의 변화된 요구 사항을 반영하기 어렵다.
-Agile : Waterfall 방식의 개선을 위해 탄생?, 주기적인(2w) Iteration을 통해 product를 개선해 나간다. 매 Iteration(=sprint) 마다 실행 가능한 결과물이 빌드되야 한다.
	
	-Scrum : Agile 방법론을 구체화 시킴
		-Backlog : 해당 프로덕트를 만들기 위해 해야할 것들 (기능정의, 출시일자, 우선순위 등 포함)
		-Sprint : 프로덕트가 완성되기 까지 일정한 기간을 두고 주기적으로 이루어지는 개발 및 빌드 기간(분석,설계,디자인 포함됨) 
		-Sprint Backlog : 해당 스프린트에 진행하기로한 Backlog.
		-Task : Sprint Backlog를 좀더 상세히 쪼개놓은 것으로 우선순위, 요구설명, 예상시간, 진행자를 명시한다.(1 테스크는 1일 작업량을 넘지 않게하며 팀원이 직접 쪼개는것을 권장)
		-기본적 Workflow : Commitment Point -> Todo -> in progress -> Done -> Delivery Point (보통 cycle기간을 Lead time 이라함)
		-WIP(work in progress) Limit : 각 단계별 진행중인 상태에 단계를 둘수 있다 (ex. in progress 상태에 2개 이상의 테스크를 동시에 둘수 없는 제약)
		
		-담당자
			-product 관련자(고객) : 고객사 또는 서비스 사용자등
			-product owner : 회사의 임원 또는 전략 기획 및 영업 담당자로 고객과 함께 프로덕트의 기능정의, 출시일자, 기능별 우선순위를 정한다. 
			-scrum master : scrum 방법론의 전반적 관리자
				-Sprint 계획 : owner와 함께 이번 sprint에 포함될 backlog를 선정하고 팀원과 함께  
				-Team 관리 : 협의, 외부간섭, 장애 제거등 scrum팀의 생산적 활동을 보장해 준며 팀원의 scrum 프로세스 준수를 관리한다.
				-일일 스크럼 미팅 : 매일 15분정도의 스크럼 미팅을 통해 진행사항을 확인하고 장애제거를 돕는다.
				-스프린트 리뷰 및 회고 : 스프린트 종료시 고객,오너,팀원 모두 모여 리뷰 미팅을 진행, 팀원만 모여 회고 미팅 진행
			-scrum team : 해당 스프린트를 직접 진행할 담당자(기획, 설계, 디자인, 개발, 테스트 모두 포함 가능), 5-9명 적정
			-Agile 코치 : 외부 또는 전사적으로 애자일을 코칭해줄수 있는 전문가?
	
		-Rule
			-마스터는 매 스프린트 시작전 팀원의 휴일 및 잡업무를 고려하여 명확한 업무가능 시간을 도출해야 한다. (하루 4시간을 실질적인 코딩 가능 시간으로 봐야함)
			-스프린터가 잘 진행되기 위해서는 각 task에 대한 정확한 분석(업무량 및 소요시간)이 필요하며 불확실한 요소를 최대한 줄여야 한다.
			-스프린트 기간에는 선정된 backlog를 변경하지 않는것을 원친으로 한다.(긴급한 요구사항은 가능한 다음 sprint에 추가하고 sprit 기간을 1w으로 잡을수 있다)
			-스프린트 기간은 같은 길이(2w)을 유지하고 연속적으로 이루어져야 하며 정해진 시간에 끝내는 것을 원칙으로 한다.

-Kanban board : Scrum 방법론을 관리 보안해 줄수 있는 툴로 여겨진다. 프로젝트의 현재 흐름을 비주얼하게 보여주며 Scrum 방식의 룰을 조금 유연하게 적용한다.




[Develop Dependencys]
-spring-boot-devtools : 웹 캐시 기능을 제거하여 개발시 변경확인에 편리 (hot swapping, disable cache for template, enable live reload)
	-----------
	<dependency>
		<groupId>org.springframework.boot</groupId>
		<artifactId>spring-boot-devtools</artifactId>
		<optional>true</optional>
	</dependency>
	-----------



[REST]
-GraphQL : GraphQL was developed to cope with the need for more flexibility and efficiency! It solves many of the shortcomings and inefficiencies that developers experience when interacting with REST APIs.
	-REST API의 유연성 부족의 한계를 해결해 준다 (Front End 화면은 매번 쉽게 변경되는데(필요한 데이터도 변경).. API 수정이 따라 가질 못함
	-GraphQL : API 의 스키마를 정의 하기 위한 자체 언어(SDL)
		-----------
		Person을 표현하기 위한 example SDL
		-----------
		type Person {
			name: String! //(!=필수항목의 의미)
			age: Int!
		}
		-----------
	


[TEST]
-Junit 4 : JUnit is a unit testing framework for the Java programming language. JUnit has been important in the development of test-driven development.
	-동작방식 : class path 내부의 junit jar 가 명시된 어노테이션을 확인하여 동작한다.
	-실행 : A 클레스의 a1 메소드 테스트시 보통 ATest 클래스를 만들고 a1메소드를 작성후 @Test 어노테이션을 붙여 동작시킨다. (Run as 에서 Junit Test 로 실행)
	-test Class : src/main/java/A.class를 테스트 하는 경우 src/test/java/ATest.java 형태로 테스트 클래스를 만든다. (관례적)
	-test 메소드 실행 순서 : JUnit 4부터 랜던이 아니다.(이전에는 실행시마다 테스트 메소드가 실행되는 순서가 달랐다). 메소드 내임의 hash 값의 순서대로 호출된다.(호출 순서를 바꿀수 있는 설정이 존재함)
		-----------
		@FixMethodOrder(MethodSorters.DEFAULT) //내부 테스트 클래스의 호출 순서를 정의 할수 있다. (default는 메소드 내임 헤시값 순)
		public class ATest {
		...
		
		@Test
		public void a1(){
			A a = new A();
			int result = a.a1(10);
			assertEquals(5, result); //a1 메소드의 결과 값이 5이면 테스트 통과
		}
		-----------
	
	-Annotations : 
		-@FixMethodOrder(MethodSorters.DEFAULT), 클래스 어노테이션 : 테스트 클래스의 테스트 메소드 호출 순서를 정함 (필수 요소는 아님, 작성을 안할시는 Default로 메소드 네임 헤시값 순)
		-@BeforeClass : 해당클레스 시작시 한번 실행된다. (JUnit5 에서는 @BeforeAll 로 변경)
		-@Before : 각 @Test 메소드 실행전 매번 호출 됨 (JUnit5 에서는 @BeforeEach 로 변경)
		-@Test : 테스트 메소드 임을 선언한다.
		-@After : 각 @Test 메소드 실행후 매번 호출 됨 
		-@AfterClass : 해당클레스 종료시 한번 실행된다.
		
	
-Junit 5 : 







Template Engine
-Mustache :

-Handlebar : html에 data를 바인딩함
	-spring 설정 : handlebars-spring-boot-starter 라이브러리가 있으므로 특별한 설정을 요구하지 않음	
		-----------
		@GetMapping("/")
		public String main() {
			return "main"; //(기본 설정에 의해 prefix: src/main/resources/templates, suffix: .hbs 적용하여 해당 view를 찾는다.)
		}
		-----------
		

	-jsfiddle(js피들) : HTML, CSS, 자바스크립트(jquery, handlebars, react..)등 코드 스니펫을 테스트하고 결과를 볼수 있는 웹사이트	

	-template : html 과 데이터 바인드를 위한 핸들바 expression, 논리적 처리를 위한 헬퍼 코드로 구성됨
		-선언 : <script id="entry-template" type="text/x-handlebars-template">
		-데이터 : {{XXX}} 형태가 기본
		-주석 : {{!-- --}}
		-partial한 template 삽입 : {{#> positionName}} 삽입 실패시 default 내용 {{/positionName}}
		
		-helper : if, unless 등 기본적 헬퍼를 제공하여 로직 처리를 포함하게 해준다.(custom helper도 지원)
			-loop : {{#users}} 와 {{/users}} 를 통해 반복 ( 또는 {{#each users}} 와 {{#each}} )
			-if :
				-----------
				{{#if @first}}
					<td>첫 아이템 ({{@key}} 번째 요소)</td>
				{{else if @last}}
					<td>마지막 아이템 ({{@key}} 번째 요소)</td>
				{{else}}
					<td>중간 아이템 ({{@key}} 번째 요소)</td>
				{{/if}}
				-----------
	
			-custom helper
				-----------
				//js내 email 함수를 호출하며 id값를 인자로 넘김
				<td><a href="mailto:{{email id}}">{{email id}}</a></td> 
				-----------					
			
	-template 와 데이터를 바인드 해주는 js 파일 : 뭐라 명명하지 ???
		-----------	
		//조각 템플릿 가져오기
		var partial = $("#partial-template").html();

		//메인 템플릿 가져오기
		var source = $("#entry-template").html();

		//메인 템플릿 컴파일
		var template = Handlebars.compile(source); 

		//메인 템플릿에 바인딩할 데이터
		var data = {
				users: [
					{ name: "홍길동1", id: "aaa1" },
					{ name: "홍길동2", id: "aaa2" },
					{ name: "홍길동3", id: "aaa3" },
					{ name: "홍길동4", id: "aaa4" },
					{ name: "홍길동5", id: "aaa5" }
				]
		}; 

		//조각 템플릿 partial을 메인 템플랫의 'commonHeader' 위치에 삽입
		Handlebars.registerPartial('commonHeader', partial);

		//커스텀 헬퍼 등록 (id를 인자로 받아서 전체 이메일 주소를 반환)
		Handlebars.registerHelper('email', function (id) {
		  return id + "@daum.net";
		});

		//메인 템플릿에 데이터를 바인딩 및 HTML 생성
		var html = template(data);

		//생성된 HTML을 DOM에 주입
		$('body').append(html);
		-----------	
	
 




[파일]
-svg : Scalable Vector Graphics, 확대 축소시 안깨짐
-PNG : Portable Network Graphics, gif 파일 라이선스 문제를 해결하기 위한 대안으로 나옴





[디버깅]
-로딩속도 향상 : head가 다 실행되고 body가 실행 되므로 head의 내용을 최소화 (css는 header에, js 파일을 body 하단에 둔다)
-js lib간 순서 : bootstrap.js는 jquery가 있어야 함으로 jquery가 먼저 선언 되야함
-DTO는 Entity를 사용해도 되지만, Entity는 DTO에 대해 전혀 모르게 코드를 구성해야합니다.


[JS, javascript]
-함수 변수: 여러 js 파일에서 함수 명이 겹쳐서 발생한느 문제를 해결하기 위해 
	-----------
	var main = {
		init : function () {
			var _this = this;
			$('#btn-save').on('click', function () {
				_this.save();
			});
		},
		save : function () {
			var data = {
				title: $('#title').val(),
				author: $('#author').val(),
				content: $('#content').val()
			};
		}
	};		
	//호출시
	main.init();
	main.save();
	-----------
	


[윈도우]
-system 관련 인증서 및 자격증 관리 (git 포함) : 제어판\사용자 계정\자격 증명 관리자
-리소스 모니터 : 사용중인 포트의 프로세스 확인 가능 (프로세스 확인 후 종료 처리 가능)




[모바일, 안드로이드, IOS]
-딥링크(deep link) : 모웹에서 사용하는 테그 형태로 앱을 깨우거나 모앱의 특정 페이지를 오픈 할 수 있는 메커니즘 (!! 경우에 따라 딥링크, 앱링크, 유니버셜 링크의 이름으로 혼영하여 사용, URL 스킴 방식을 보통 일커름)
	-URL 스킴 방식 : goodoc:// 형태의 링크로 구성, 앱내 특정 위치로 이동가능, 앱 미설치시 아무 동작 안함, 같은 스킴을 사용하는 앱이 여럿 일을경우 사용자가 선택하게 함, 초기 버전의 링크로 Universal Link로 진화
		-스킴 ex : <myappSk://events?key=value>
	
	-Universal Link : (!!안드로이드의 경우 보통 앱링크라는 이름으로 불려 진다.)
		-스킴 방식과 차이 및 특징 : 
			-앱 미설치시 스토어로 이동해 준다.(URL 스킴 방식을 보안하여 형태가 https://도메인 임으로 고유성(앱간중복방지)을 갖는다)
			-사용자의 트리거(클릭)에 의해서만 동작한다 (스크립트에서 자동으로 동작하게 하는 경우 앱이 설치되어 있어도 웹 URL로 동작되는 브라우저가 많음)
			-각각의 장단점으로 인해 스킴방식과 혼용해서 사용	
			
		-os별 구분 :		
			-앱링크 : 안드로이드쪽에 사용하는 명칭, 			
			-유니버셜 링크 : IOS에서 사용하는 명칭, 
	
-디퍼드(deferred) 딥링크 : Universal Link와 같으나 앱이 설치되지 않은 경우 앱설치 페이지로 이동 후 앱이 설치 되면 앱에서 원래 가려던 페이지로 이동해 준다(유니버셜링크의 경우 앱 설치후 앱의 메인으로 오픈됨)
	-단점 : 안드로이드, IOS 각각의 디퍼트딥링크가 존재해서 개발을 두벌씩 해야 하는 번거럼이 있음, 해결을 위해 Firebase 사의 Dynamic Link, Appsflyer사의 One Link 가 생겨남
		-Firebase : 모바일 앱, 웹어플리케이션 앱 플랫폼 개발 회사로 google에서 인수, 앱 개발시 제공하는 SDK를 추가하여 개발하는 방식
			-메인 솔루션 : 
				-Cloud Firestore(NoSQL) : web, Aos, Ios 사용가능
				-Dynamic Link :
			
		-Appsflyer(앱스플라이어) : a SaaS mobile marketing analytics and attribution platform, facebook 등의 마케팅 파트너사,  앱 개발시 제공하는 SDK를 추가하여 개발하는 방식
			-메인 솔루션 :
				-
				-One Link : 

-organic install : 특별한 마케팅 링크(디퍼드 딥링크 같은)가 걸리지 않음 순수 스토어를 통한 인스톨



[하이브리드 앱]
-function call :
	-android :		
		-javascript -> native :
			-네이티브에 웹뷰 생성 : WebView web; 
			-네이티브에 app 라는 이름으로 스크립트 인터페이스 생성 : web.addJavascriptInterface(new MainJsInterface(getApplicationContext()), "app"); 
			-네이티브에 스크립트에서 호출될 실제 펑션 구현, public void recordEvent(String name, String json){...} , !! 리턴값을 줄수도 있음			
			-스크립트에서 네이티브의 펑션 호출 : <script>abc.recordEvent(eventName, eventParams);</script> !! 리턴값도 받을 수 있음
			
		-native -> javascript :
		     -네이티브 버튼에 특정 스크립트 펑션을 걸수 있다. : public void onClick(View v) {webView.loadUrl("javascript:getValue()");}
				-getValue() 내부에서는 스크립트 -> 네이티브 방식으로 값을 다시 native 쪽으로 넘겨주게 처리 해야 한다. : function getValue(){MyAndroid.receiveValueFromJs(val);}
					-getValue() 내부에 스크립트 -> 네이티브 방식을 구현하지 않고 그냥 return val 형식으로 바로 리턴해서 네이티브로 값을 전달 할 순 없다.!!
					-변칙적으로 특정 값을 가져오기 ?? : (확실히 가능한지는 확인 필요!!)
						-public void onClick(View v) {webView.loadUrl("javascript:MyAndroid.receiveValueFromJs(document.myform.xxx.value)");}
					
					-기타 참고 :
						-네이티브에서 webview 어느 url을 로딩하는지 알수 있다.
						-webview 로딩이 끝나는 시점을 캐치해서 이벤트를 걸수 있다.			
		
	-ios :
		-javascript -> native :
			-네이티브 view controller에 메시지 수신코드 추가 : 
			-(void)userContentController:(WKUserContentController *)userContentController 
			didReceiveScriptMessage:(WKScriptMessage *)message {..구현..};
			
			-스크립트에서 네이티브의 펑션 호출 : <script>webkit.messageHandlers.event.postMessage(eventName + "+" + eventParams);</script> 
				-펑션 호출이라기 보단 네이티브의 메시지 핸들러로 메시지를 전달하는 형식 (메시지를 파싱해서 value로 사용 하는듯.. 당연히 네이트브로 부터 리턴도 못 받겠지??)
				
		-native -> javascript :
	




[publishing platform]
-개념 : 웹사이트를 만들기 위한 플랫폼 (툴?)
-주요 상품 : 
	-wordpress : 전세계 30 쇼핑몰이 wordpress 기반, opensource 기반으로 각정 플러그인 및 테마를 제공함
		-서비스 임대형, 설치형 등 다양한 조건으로 지원
	-wix.com : 
		


[SEO]
-SEO : search engine optimization
-최적화 :
	-https 사용
	-robots.txt 사용 : https:xx;com/robots.txt 에 위치 시킴 (서치엔치이 크롤링 함)
		-접근할수 없는 url path 구현 (로그인이 필요한 마이페이지, 장바구니, 결제 페이지 등..)
	-sitemap.xml 
		-robots.txt 파일을 통해 정의 할수 있음
		-보여주고 싶은 페이지에 대한 정의 
		
	-SEO를 위한 타이틀 및 디스크립션 테그 적용
		-<title></title>
		-meta tags : 
			-<meta name="title" content="">
			-<meta name="description" content="">
			-<meta name="keyword" content="">
		-robots meta tags :
			-<meta name="robots" content="noindex, nofollow" />
		-이미지 테그의 alt text 활용
		-Canonical tag : 사이트에 거의 동일한 페이지가 존재할경우 정본?? 페이지로 링크될수 있게 할수 있다. 또는 타 사이트의 내용을 따온 경우 원본? 페이지로 링크될 수 있게 할수 있다.
			-<link rel="canonical" href="http://example.com/" />
		-기타 sns tag : og tags...
		
-ASO : app store optimization (모바일 스토어에서 최적화)




[SNS]
-페이지 공유 :
	-참고 :
		-og(Open Graph) Tag : 페이스북에서 만든 규약으로 지금은 페이지 공유를 하는 많은 사이트의 표준 처럼 사용 됨(카카오, 블러그, SNS 서비스 들이 함께 사용하고 있음, 자체 테그를 추가하기도 함)
			-html head에 메타 테그로 들어가며 서버사이드에서 wirte 되어 내려와야 함 (js에 의해 값이 변경되는 것은 크롤러가 감지하지 못함), 크롤러에게 해당 페이지의 정체를 설명하는 테그들임
			-페이지를 공유하면 공유받은 서비스의 크롤러가 해당 페이지를 읽어 들여 og tag를 확인 후 화면상에 어떻게 보여 줄지를 정함
			-기본적으로는 실제 공유될 페이지에 해당 테그가 존재해야 함 (꼼수로 실제 랜딩 페이지와 다른곳에서 메타 테그를 제공 할수 있긴 함)
		
		-주요 og Tags :
			-og:url : 특정된 파람이 붙지 않은 해당 페이지 고유의 url, 해당 페이지의 유니크한 id이며 좋아요, 싫어요 카운트 키값으로도 사용됨, 넣지 않아도 됨(넣지 않으면 자기 자신의 url로 인식 되는듯??)
			-og:title : 제목
			-og:description : 설명
			-og:image : 대표 이미지
			-fb:app_id : 페이스북의 인사이트를 사용하는 업체의 경우 해당 앱 ip를 추가하면 대시보드를 통해 트래픽 정보를 받을 수 있음
			-og:type : 문서의 타입으로 기본은 website
			-og:locale : 해당 문서의 언어
		
	-facebook :
		-링크 팝업 예시 : popupUrl = '//www.facebook.com/sharer/sharer.php?u=' + originUrl;
		-참고 :
			-기본적으로 originUrl쪽 페이지에 og테그들이 있고 링크도 originUrl로 가야 하나 
			-만약에 og:url이 originUrl과 다르게 설정되면 크롤러가 og:url쪽으로 이동하여 og테그를 읽고 최종 링크는 originUrl로 랜딩 되는 듯 함(??)
			-클롤러는 페이지 내에 있는 js 스크립트에는 영향을 받지 않는듯 함
				-최종 링크되는 페이지에서 og테그를 지원 할수 없는 경우 originUrl을 https://my.com/productDetail?isShared=true 형태로 주고 productDetail 페이지 내 메타테그를 쓰고
				-로딩되는 시점에 스크립트를 통해 isShared 가 true인 경우 location을 다른 곳으로 이동처리하는 방식이 가능하다 (크롤러는 js 스크립트를 무시하기 때문인듯..)

		-og tag에 대한 확인 테스트 가능 : https://developers.facebook.com/tools/debug/


[Chrome]
-속도 개선 :
	-request 횟수를 최소화 : webpack, parcel 같은 모듈 번들러 사용
	-작은 이미지들은 html에 데이터를 포함시켜서 data-uri로 표현
	-불필요한 request 제거
	-이미지에 대한 lazy loading 처리
	-브라우저 랜더링 시간 절약 : 순처적으로 불러와 지는 js가 dom, cssom 의 개입을 최소화
	-haed 태그에는 필수 css, js만 적용 (가능하면 body태그 마지막에 js를 넣는다)
	-dom 제어와 관련이 있는 스크립트는 defer attribute를 이용
	-Google Analytics 같이 의존성이 없는 스크립트는 async를 이용	
	-webpack, parcel : 모듈번들러
	-lazy loading
	
-develop tool :
	-network :
		-initial connection : 연결 설정 시간(tcp handshake, ssl 협상)
		-TTFB(time to first byte) : 서버로 요청후 첫 byte를 받은 시간(서버의 처리 시간)
		-content Downloaded : 서버로 부터 데이터를 다 받는데 걸린 시간 (개선을 위해 minify, gzip, tree shake 등을 고려)

	-Application :
		-Storage :
			-Cookies : 현재 열려 있는 페이지에서 생성한 cookie 정보를 보여줌, 해당 페이지를 랜더링 하면서 타 사이트를 참조했다면 해당 타 사이트의 cookie 정보도 함께 보여 줌


[인증]
-Token Based Authentication : 
	-web 전통 방식 인증 : id/pw 입력후 유효하면 session 및 cookie를 생성하여 다음 요청시 사용
	-단점 : 
		-web base가 아닌 Mo 앱등 cookie를 사용할 수 없는 환경에서 한계가 있음, 어떠한 형태의 client의 요청에도 인증하기 위해 token 방식이 이용됨
		-서버 세션등의 사용은 서버의 리소스 증가를 발생시키며 Stateful 서버의 형태로 dependency가 생긴다.
	

-Token Based Authentication : (token 스트링 값을 통해 인증)
	-장점 : 
		-전통 방식의 한계 극복, web 서비스(브라우저 base)가 아닌 경우에도 이용 가능
		-redis 등으로 session 관리하여 확장성 및 stateless 서버 형태를 구현할수 있는 추세지만 기본적으로 클라이언테에 token 관리를 넘김으로서 서버는 항시 stateless 상태 유지 가능(실제는 안그런듯?)
		-다른 app간 토큰을 공유하여 사용 가능
	-단점 :
		-토큰 방식은 보안성 측면에서 더 강화된 방식이라 볼 수 없다
		-서버의 Stateless, Scalability, Extensibility 관점에서 의미를 갖는다.
		-token 유출 및 관리자에 의한 해당 사용자의 상태 변화시 대응을 위해서 https를 사용하고 timestemp를 갖고 주기적으로(내부적으로) 재 인증을 하게 하거나 하는 보완이 필요
		
	-관련 스팩(?) 및 기술 : OAuth,
	-절차 : https 를 사용하여 id/pw(hashed) 서버 전송 -> 인증 -> (access)Token 생성(JWT방식)및 반환 (header? body?) -> 다음 요청시 header에 Authentication : Bearer 값 전송하여 인증
		-http 해더 ex: Authorization: Bearer eyJhbGciOiJSU...
	
	-token을 만드는 방식	
		-의미 없는 고유키값을 토큰으로 사용하는 방식 : face북등의 OAuth의 경우 그저 유니크한 토큰을 발급 (해당 토큰을 통해 원하는 정보를 lookup 해야 함, lookup을 위한 리소스 낭비 발생)
		-token 자체에 필요한 정보를 담는 방식 : id, 권한, 롤 등 기타 필요 정보를 담음 (서버가 해당 토큰을 까서 직접 필요한 정보를 얻을 수 있다)
			
		-토큰 생성 스팩 : 
			-JWT(Json Web Token) : 정보를 담는 인증 토큰을 만들기 위한 포맷, 
				-구성요소 : Header, Payload, Signature
				-Header : 토큰 타입과 암호화 방법을 정의 (Base-64 인코딩됨) =>B-64({typ:'JWT', alg:'HS256'})
				-Payload : 필요한 정보 (유저 및 기타 상품 정보 등, Base-64 인코딩됨) =>B-64({name:'sungil', grade:'admin'})
				-Signature : 유효성을 체크하기 위한 값 => HMACSHA256(B-64(header)+','+B-64(payload)+','+secret_key), secret_key는 서버에 안전하게 보관되야 함
				-token값 : Header + '.' + Payload + '.' + Signature
		
	-기본 system 아키텍쳐 : client, Load-Balancer, 인증서버, API서버
		-흐름1 : client 인증요청(id/pw) -> Load-Balancer 적절한 인증서버로 요청 -> 인증서버는 id/pw 확인하여 Token 값 생성하여 반환 (id/pw 오류시 에러 페이지로 redirect)
		-흐름2 : client API 요청(token 값을 Bearer 값으로 사용하여 요청) Load-Balancer 적절한 인증서버로 요청 -> bearer값이 유효한 경우 적절한 API 서버로 redirect (인증오류시 403)
		
		
-SSO (single sign on) : 한번의 인증(로그인)으로 여러 사이트 인증
	-서비스 형태 별 구분 :
		-클라이언트 기반 : 개인 PC에서 각 사이트에 대한 계정 정보를 가지고 있다가 자동으로 로그인 시켜줌 (윈도우나 브라우저의 계정 저장 기능과 유사)
		-서비스 기반 : 인증만을 처리해 주는 서비스 (ex : MS passport)	
		-서버 기반 : 인증 서버를 두고 처리하는 방식	
			-서버 기반 구현 모델: (개념적으로 설명)
				-인증 대행 모델(delegation 방식) : 사용자 -> 인증서버 -> 각각의 모든 서버에 접속하여 해당 사용자를 인증 상태로 만들어 논는다(사용자를 대신해서 모든 사이트에 대신 로그인 해줌(상태를 만듬))
					-특징 : 각 서비스가 수정하기가 어려운 경우 사용됨 
					
				-인증 정보 전달 모델(propagation 방식) : 사용자 -> 인증서버 인증토큰 발급 -> 사용자 (인증토큰을 이용하여 각 사이트 접속) -> 각사이트 (인증토큰이 유효한시 매번(?) 인증서버에 확인)
					-특징 : 인증 서버의 신뢰가 높고 각각의 서비스가 수정이 용이한 경우 (같은 도메인 영역을 사용할 경우 인증 토큰을 cookie로 생성하여 처리 가능)
			
	-주요 개발 형태 별 구분 : 
		-OAuth 2.0 : 표준으로 정립, 2.0부터 OAuth로 명명, SSO의 개념보다는 API 서버 인증, 인가용으로 많이 사용(?), 웹, 모바일, 데스크탑, IoT 장비에 확장성이 좋음, 개발적 인증 절차에서 표준이 된것에 의미가 큼
		-wiki 정의 일부 : Generally, OAuth provides clients a "secure delegated access" to server resources on behalf of a resource owner. It specifies a process 
						for resource owners to authorize third-party access to their server resources without sharing their credentials.
						-!! 위 정의에 따르면 자원소유자패스워드승인 방식은 credential이 오픈되는 문제가 있어 보임
		
			-주요개념(용어) : facebook 예시
				-자원서버(Resource Server) : 실제 고객의 컨텐츠 정보를 가지고 있는 facebook 서버 (API 서버)
				-자원소유자(Resource Owner) : 페이스북 유저
				-인가서버(Authorization Server): 클라이언트가 API를 사용할수 있도록 access token을 발행하는 서버(facebook 소유의 서버)
				-클라이언트(Client) : facebook API를 통해 서버가 뭔가 서비스를 제공하는 제3의 서버,웹서버,앱 등등
				-사용자에이전트(User Agent) : 일반적으로는 브라우저가 될수 있으나 반드시 그런것은 아님, 앱의 경우 에이전트 없이 앱 자체가 에이전트의 역할을 할수도 있음
					-참고 : 클라이언트와 에이전트를 구분짓는 이유는 에이전트는 보통 오픈된 형태의 도구 즉 브라우저등을 의미, 보안이 상대적으로 취약할수 있는 구간을 설명하기 위해 구분 짓는 듯(?)
					
			-상황별 시스템 구성
				-인가코드승인(Authorization Code Grant) : OAuth가 가질수 있는 full stack(?), 보안성 높음,  클라이언트가 웹서버(Auth code를 받아서 서버로 리다이렉트 해야 함으로?)인 케이스
					-로그인시도 > 클라이언트가 에이전트로 Auth 서버 주소로 리다이렉트 시켜줌 (클라이언트id, state, 인증후 리다이렉트로 돌아올 returnUrl과 함께)
						-에이전트는 Auth 서버로 리다이렉트 되어 사용자가 credentials(id/pw)을 입력하여 전송하면 Auth 서버가 인증/인가 확인 후 Authorization Code + state 값을 내림
							-정확히는 Auth 서버가 에이전트로 Authorization Code + state 값을 주면서 클라이언트쪽의 returnUrl로 바로 리다이렉트 시켜 버림
							-!! 바로 access 코드를 내려 주지 않는 이유 : 실제 resource 서버로 접속가능한 access 토큰이 agent까지 내려간다면 보안상 취약점이 발생할 수 있기에??
							-!! state를 달고 다니는 이유 : 제3의 서비스를 통해 후킹한 Authorization Code를 이용하여 타 서비스로 접근하는 시도를 막기위해 정상적인 요청인지 한번더 체크??
							
								-클라이언트는 전달받은 state 값이 자신이 발행한 유효값인지 확인후 Authorization Code + client crdential 이용하여 Auth 서버로 최종 access Token을 요청
									-응답받은 access 토큰은 에이전트로 내려가지 않고 클라이언트(클라이언트는 앱이될수도 서버가 될수도 있다)에서만 관리되어 짐
									-!! client 입장에서의 자체 로그인 처리(session 생성등)는 어느 시점? : Auth 서버로 부터 정상적인 access 토큰이 발급되는 이 시점에 처리하면 되지 않을까??
								
				-암시적승인(Implicit Grant) : 중간 웹서버가 없이 브라우저(js)를 이용하는 앱으로 구성된 경우, Auth code를 가지고 리다이렉트 할수 없음으로 에이전트로 엑세스토콘을 바로 내림(상대적으로 보안 취약)
					-!! 앱스킴값을 이용하여 리다이렉트 할수 있지도 않을까??
					-로그인시도 > 클라이언트가 에이전트로 Auth 서버 주소를 내려줌 (클라이언트id, state값 과 함께)
						-에이전트는 전달 받은 auth 주소로 접속하여 사용자가 credentials(id/pw)을 입력하여 전송하면 Auth 서버가 인증/인가 확인 후 에이전트로 바로 엑세스토큰 + state 값을 내림
							-에이전트는 받은 엑세스 코드를 클라이언트로 전달
							-!! 클라이언트 id 가 앱 형태의 어플에 존재하기 때문에 디컴파일등으로 인한 노출 우려가 있음, 이를 위해 실시간으로 클라이언트 id를 생성해내는 방식이 있다는데.. 잘은 모르겠음??
							
				-자원소유자패스워드승인(Resource Owner Password Grant) : 사용자가 자신의 클라이언트로 직접 credentials(id/pw)을 입력함 클라이언트에 크리덴셜이 노출됨 (보안 취약, Oauth라 볼수 있나??)
					-사용자가 클라이언트 (보통 앱일듯)에 직접 개인 크리덴셜을 입력
						-클라이언트는 클라이언트id와 개인 크리덴셜을 갖고 auth 서버로 인증 요청
							-auth 서버는 바로 엑세스 토큰을 클라이언트로 내림
							-!! 개인 크리덴셜이 제3의 클라이언트로 바로 노출됨으로 보안이 취약함, 다른 유형의 승인 방식을 사용할 수 없는 경우에만 사용
							
				-클라이언트인증정보승인(Client Credentials Grant) : 클라이언트가 자원의 소유자이거나 자원 소유자가 이미 클라이언트에 접근 위임을 받은 경우 (회사가 자기 직원 정보를 턴키로 위임 받은 케이스??)
					-사용자 크리덴셜을 입력 받지 않는다 
						-클라이언트는 인가서버로 클라이언트id 만을 가지고 엑세스 코드를 발급 받는다
						-!! 해당 엑세스 코드는 해당 클라이언트와 관련된 모든 자원 소유자의 정보에 엑세스 가능??
						
			-보안 고려 사항 : 
				-Oauth 스팩에 Bearer 토큰을 쿼리 파라미터로 전달하는 방법이 있지만 이러한 방식으로 엑세스 토큰이 노출되지 않게 해야함
				-엑세스 토큰이 log 파일등에 남아서는 안된다.
				-auth 서버가 엑세스 토큰을 DB 등으로 관리할때 plain 텍스트가 아닌 암호화해서 저장해 둬야 한다.
				-auth 코드는 한번 access 코드를 발급하면 더이상 사용 할수 없도록 해야 하며 동일한 auth 코드로 요청이 들어오면 기존 해당 auth 코드로 발급된 엑세스 코드도 패기 처리하는게 좋다
				-리다이렉트 url은 client id를 발급해 줄때 미리 받아서 등록되어 있는 return url로만 내려주게 해야 하고 return url은 패턴 형식보다 명확히 픽스된 형태의 uri로 등록되게 해야 좋다
					-등록된 url과 다른 scope의 url이 넘어올경우 400오류를 발생하는것이 좋다
					
				
				
					
				
								
					
		
		-SAML(Security Assertion Markup Language) :  
	
	
	
[REST API (Representational safe transfer)]
-인증	
	-API key 방식 : API포털(개발자사이트)를 통해 특정 스트링 형태의 키를 발급받아 API 호출시 함께 전송 (서버는 키값을 통해 사용자를 확인), 가장 초기적인 방식 이며 특정 표준이 없다.
		-문제점 : api 키값이 노출시 보안에 문제 발생이 쉽다.
		
	-API Token 방식 : id/pw를 이용하여 인증후 토큰값을(사용기간등 유효한) 내려 받아 api 호출시 id/pw 대신 api 토큰을 전송하여 인증 받는 방식
		-장점 : 매 api 호출시 id/pw를 보내는 이유는 문제 발생시 pw는 변경이 가능하고 매번 id/pw를 넘기는 것 보다 보안에 유리하다.
		-주요 방식 예시 :
			-HTTP Basic Auth :
			-Digest access Authentication :
			-클라이언트 인증 추가 :
				-클라이언트에도 자체 id(client id)와 pw(client secret)을 추가하여 클라이언트 인증 후 id, pw 를 추가 인증 함(조금더 개선된 정도)
				
			-제3자 인증 방식 : google 이나 facebook 계정을 이용하여 서비스 서버는 사용자의 pw를 공유 받지 않지만 해당 사용자가 google이나 페이스북의 사용자임만 확인 받는다.
				-주요!! : API 서버가 제3의(페이스북 같은) 서버의 API를 이용해야 하는 경우 사용하는 용도로 봐야 겠지?? 단순히 회원가입을 하지 않기 위한 인증용으로만 활용할 수도 있지만
				-인증을 위해 페이스북이 입력 받는 기본 항목 : 페이스북 developr portal에 등록 하는 주요 항목		
					-서비스명 :
					-시비스 url :
					-callback url : 인증이 성공 했을때 인증 정보를 받는 url (인증 정보는 보통 client id, client secret)
					
				-OAuth 방식 : OAuth Provider부터 인증을 받아 OAuth 토큰을 받고 API 호출시 OAuth 토큰을 함께 전송, API키 방식보다 높은 보안 및 OAuth 인증 표준이 존재함 (개발 난이도가 조금 있음)
				
	-Bi-diretional Certification : 가장 높은 수준의 인증, 서버/클라이언트 양방향 SSL을 제공, 메시지까지 암호함으로 인중 수준이 높다.(개발이 어렵고 특정 서비스에서 사용)
	
-메시지 암호화 : 
	-https : 데이터 암호화를 위해 주로 사용(RSA)
		-문제점 : 
			-Man in middle attack : Client 와 서버가 Handshke 시점에 해커가 서버의 인증서를 갈취 후 client에는 자신의 인증서를 내려줌
				-client는 해커의 인증서로 암호화 하여 데이터 전송, 해커는 중간에 갈취하여 자신이 열어본 후 다시 진짜 서버의 인증서로 재 암호화 하여 실재 서버로 전송 (계속 하여 데이터 갈취 가능)
			
	-데이터 레벨의 암호화 : 보안이 필요한 특정 데이터만 암호화 하여 전송
		-주로 대칭키 기반의 암호화 알고리즘 사용
			-종료 : DES, Triple DES, Blowfish-256, AES-128, AES-256, RC4-256
				-각 암호화 종류마다 보안성 및 처리속도가 다름
				
-무결성 보장 : 암호화는 데이터를 몰래 볼수 없도록 하기위한 처리라면 무결성은 데이터가 중간에 변경되지 않았는지를 보장하기 위한 조치
	-주요 알고리즘 : HMAC 알고리즘
		-방식 : 클라이언트는 서버와 미리 공유된 key 값을 통해 전송할려는 데이터의 Hash값을 추출하여 전송할 데이터와 함께 전송 한다, 서버는 전송받은 데이터를 공유된 키값으로 해쉬하여 전달 받은 해쉬값과 같은지 본다.
			-문제점 : 해커가 데이터를 변조하지 않고 탈취한 데이터를 그대로 서버로 요청시 요청이 성공됨
			-해결책 : 전송할 데이터에 API 요청 시간을 포함하여 해쉬 값을 만든다. 서버는 해쉬값을 확인하여 변조가 없다면 요청된 시간도 확인하여 +- 몇분(5분?)의 요청만 유효한 요청으로 인정 한다

-FM 정석 : REST API는 완전한 객체 형태로 구성해야 한다.
	-http 메서드 : Post=create, Get=select, Put=update, Delete=delete
		-이게 실제로 지키기가 어렵다.. 이렇게 명확히 구분 짓기 위해서는 모든 API의 기능을 쪼개야 하고 쪼개진 API를 클라이언트가 쪼개서 호출해야 하는데.. 현실에서는 쉽지 않은듯..
		-GET을 제외하고 post, put, delete 모두 request body를 전송 가능하다. (get에 request body를 붙이면 실제로 넘어갈때는 post 메서드로 변경되서 넘어가는듯...?)
	-url :
		-create : HTTP Post, http://myweb/users/, body={"name":"terry", "address":"seoul"}
		-update : HTTP Put, http://myweb/users/, body={"name":"terry", "address":"suwon"}
		-select : HTTP Get, http://myweb/users/terry
		-delete : HTTP Delete, http://myweb/users/terry

	-http method를 명확히 구분하여 사용시 장점
		-http 기존 웹 표준의 인프라를 그대로 사용 가능 : 웹캐싱 등..
		-계층형 구조로 구성이 용이(Layered System) : 
			-Authentication, 암호화(SSL), 로드밸런싱을 api gateway나, 간단한 기능의 경우에는 HA Proxy나 Apache와 같은 Reverse Proxy를 이용해서 구현하는 경우가 많다.

	-하지 말아야 하는 실수
		-Get/Post를 이용한 터널링 :
			-update : HTTP Get, http://myweb/users?method=update&id=terry (http get 메소드를 이용해서 실제로는 update를 구현)
			-select : HTTP Post, HTTP POST, http://myweb/users/, body={"getuser":{"id":"terry",}} (http post 메소드를 이용해서 실제로는 select를 구현)
			-이런식의 사용은 기존 http 인프라(웹케싱 기능등...)을 사용할 수 없게 만든다
			
		-result Code 값을 임의로 정의 : result 코드값은 http 해더에 기존 http result 코드 값을 최대한 사용해야 한다.










[http]
-보안
	-Access-Control-Allow-Origin : (옵션 : *, 특정 도메인)
		-CORS (Cross Origin Resource Sharing) : 다른 서버(도메인, 포트)의 리소스를 사용하는 매커니즘 (HTTP는 기본적으로 CORS를 허용했음, 지금도 html에서 img, css, js, 비디오파일은 기본으로 허용?)
			-CORS 인하여 사용자의 정보 보안 이슈 및 타 사이트가 무분별하게 타 사이트의 리소스를 사용하는 상황이 생겨 이를 위한 정책이 생김 
				-same-origin policy : 브라우저에서 <script></script> 내부의 코드가 외부 서버로 request를 요청할때 reponse를 브라우저 단에서 차단하는 매커니즘 (js엔진표준스팩으로 브라우저들이 채택하고 있음)
				-ajax 통한 API 호출이 많은 추세에서 same-origin policy 가 문제가 있어 해결책을 제시함
				-해결책 :
					- Simple Request : 각 request 한번에 하나의 response를 주고 받는 것(매 request/response 마다 반복적으로 처리 되야 함)
						-요청시 GET, HEAD, POST 중 한가지만 사용
						-요청시 커스텀 해더를 사용하지 말것
						-Post 방식일때 Response의 Content-type은 application/x-www-form-unlencoded, multipart/form-data, text/plain 만 가능
						-응답 해더에 Access-Control-Allow-Origin:* 포함 (이것을 보고 브라우저가 판단하여 해당 response를 차단 하지 않는다. *대신 요청한 도메인을 넣어 준다)
							-API 서버가 Access-Control-Allow-Origin:* 를 항상 내려 주게 설정되어 있다면 이것이 브라우저 사용자의 보안 문제를 해결하기 위한 조치로 볼수 있을까???
					
					-Preflight Request : 예비 요청과 본 요청으로 나뉘어서 처리 (프로그램으로 절차를 만드는 것이 아니라 Header 값 조정을 통해 처리)
					-Request with Credential :
					-Request without Credential :
					
	-Set-Cookie: SESSION=1f5487cd-bbc5-43e6-b5bf-d476871fbd3a; Path=/kr/ko/; Secure; HttpOnly; SameSite=None
		-CSRF(cross-site request forgery) 또는 XSRF : 웹사이트 취약점 공격의 하나로, 사용자가 자신의 의지와는 무관하게 공격자가 의도한 행위(수정, 삭제, 등록 등)를 특정 웹사이트에 요청하게 하는 공격
			-흔한 예시 : A사이트에 게시판에 가짜 링크를 만들어 사용자 몰래 B사이트로 request 날리도록 속임
				-B사이트의 request가 회원 탈퇴 요청 API일 경우 B사이트는 단지 로그인 여부로만 처리를 한다고 하면 만약 사용자가 A사이트 전에 B사이트에 로그인 한 이력이 있고 세션 cookie 가 살아 있다면
				-cookie의 특성상 B사이트로 request 요청시 해당 B사이트의 cookie 값을 그대로 물고 감으로 자신도 모르게 회원 탈퇴 될수 있음
				-하여 브라우저에서 타 사이트 페이지 내에서 타 사이트로 request를 요청시 cookie 값을 넘겨주지 않도록 처리가 필요하게 됨
					-서버에서 Cookie 쿠키 생성하여 내려줄때 옵션에 SameSite=None 으로 되어 있다면 타사이트로 Cookie를 넘어가도록 허락한 것임 
						-옵션:None(A사이트로 B 요청시 B사이트의 쿠키가 있다면 cookie도 전송), Strict(전송 불가), Lax(Strict에서 GET, a href, link href 일때 예외로 허용)
					-기타 : secure(https 일때만 쿠키 생성), httpOnly(도큐먼트의 자바스크립트 코드에서 해당 쿠키에 접속하는 것을 막음, 오직 http 요청에 의해서만 자동으로 주고 받음)
						
				-해당 옵션이 설정 되지 않은 경우의 동작 
					-기존 chrome 80버전 이전에서는 None으로 동작, 80버전 이후에서는 Lax로 동작
					

-해더					
	-Client Cookie &  Server Cookie : 생성하는 위치에 따른 차이, 서버에서 생성하느냐 바라우저에서 js 스크립트에 의해 성성 되느냐의 차이
		-공통점 : 어느 cookie든 해당 url에 대한 request 시 자동으로 모두 request 해더에 포함되어 올라감
		
	-keep-alive : http는 리소스 낭비를 줄이기 위해 response후 접속을 끊는 속성이 있는데 keep-alive 동안 접속을 끊지않고 기다려 커넥션을 재활용함 (내부적으로는 TCP 커넥션이 되겠지? http1.1에서 디폴토 기능)
	-content-Type : request 또는 response 하는 데이터의 형식을 알려 준다 
		-보통 request때는 www-url-form-encoded, multipart/form-data, application/json
		-보통 response때는 text/html;charset=UTF-8, application/json;charset=UTF-8 
		
	-Accept : request 전용 해더로 respose 받고자 하는 데이터 형식을 알려주는 것 (REST 서버에 요청시 xml, json, text 등 클라이언트가 선호하는 데이터 형식을 알려 줄수 있다, 요청데로 응답하는 것은 아님)
	-Accept-Charset : utf-8
	-Accept-Language : ko, en-US
	-Accept-Encoding : br, gzip, deflate
	-Origin : 서버로 request를 보내는 현재 페이지의 주소 (요청 받은 서버가 Origin 값을 확인했을때 자신의 페이지에서 요청된것이 아니면 CORS 를 발생 시킬수 있다. Agent에서 채워주는 값인가?)
	-Referer : 서버로 request를 보내는 현재 페이지의 이전 주소
		
	-X-abc : X- 로 시작하는 해더는 custom headers들로 많이 알려진 X-Forwarded-For, X-Forwarded-Host, X-Forwarded-Proto, X-Powered-By 등이 있지만 사용을 권장하지 않음
		
	

	
	
	
	
[API 서버 플랫폼]
-정의 : API 서비스를 운영할 수 있도록 구축에 필요한 기반(공통) 기능을 제공(판매)하는 시스템(서비스)
	-구성 :
		-API G/W : 진입 포인트
		-API 포털 : 개발자를 위한 문서 및 샘플 코드를 제공
		-API 모니터링 : 서비스 상황 및 관리 기능 제공
	
-서비스 플로우 : 
	-API 인증 : 인증된 API 호출인지 판단하기 위한 Authentication 기능, (API키 또는 OAuth 기반의 인증), Admin 웹을 사용하기 위한 인증도 포함
	-SLA management(Service Level Agreement) : 해당 서비스의 성능(?), API 호출수,  장애(?) 상황등에 대한 보장 이다
	-Mediation : 요청된 API에 대한 변형을 가하는 것					
		-라우팅 : 
			-요청된 해더의 API버전에 따라 라우팅 처리..
			-요청된 해더의 국가 코드에 따라 라우팅 처리..
			
		-Function adding : 기존 클라이언트나 서버 변동 없이 처리 가능
			-주문API에 포인트 적립 API를 추가한다든지.. 
	
		-Message Transformation : request 메시지를 변경해 준다.
			-XML을 Json으로 변경 하거나, Json 형태나 필드명을 수정하거나..
			
	-모니터링 : 현황 체크를 위한 어드민 기능 제공
	-Monetization : 유료화 하기 위한 API 과금 정책, 호출 건수 등등 처리 (그를 위한 기로 로그 데이터 수집)
	-포털 : 개발 문서 및 관련 가이드 제공 사이트
		-Swagger 가 대표적 오픈 소스
			-API 메뉴얼 자동 생성, 테스트 사이트 생성 기능 제공, API 테스트 request 기능 등 제공
	
	-API Governance : API 개발 부서들 간에 규격에 대한 표준이 없어서 발생하는 문제를 해결하기 위해 통제성을 확보
		-어느 부서는 버전을 해더에 넣고 어느 부서는 url 에 넣고 하는 등의...




[암호화]
-Hash : 데이터를 고정된 길이의 문자열로 변환하는 역할, 복호화 불가, 해당 데이터의 검증용으로 사용
	-알고리즘 : MD5, SHA1, SHA2(256~512bit), SHA3(신형? 좀 내용이 다름)..
	-활용 : 
		-비밀번호 확인용 (비밀번호는 노출되지 않지만 동일한지는 확인 가능)
		-데이터 무결성(인증) 확인용 : 통신구간에서 데이터의 유실이 없는지(정확한 원본이 맞는지) 데이터의 해쉬값을 함께 보내 재 확인해 볼수 있다.
			-문제점 : 해커등에 의해 데이터가 위변조 되고 해쉬값까지 새로생성하여 전달된다면 수신자는 위변조 사실을 알수 없다.
				-해결점 : 송신자가 데이터를 해쉬할때 수신자와 공유한 비밀키를 포함하여 해쉬한 후 비밀키를 제외한 "실데이터" + "실데이터+비밀키의 해쉬코드" 를 보내는 방식으로 처리 가능 (수신자는 공유된 비밀키를 추가해서 해쉬후 비교해 본다)
					-문제점 : 데이터를 위변조 하지는 않았지만 부정하게 동일한 데이터를 수신자에게 전달할수 있다.
						-해결점 : 데이터에(해더에??) timestamp를 추가하여 오래된(+-1분??) 요청은 무시하도록 처리 할수 있다.
						
	-코드 : 각 해쉬 클레스를 사용하여 해쉬 코드를 생성 후 16진수로 리턴해 준다. 알고리즘에 따라 최종 해쉬값의 길이는 항상 일정
		MD5 : MessageDigest md = MessageDigest.getInstance("MD5");
		SHA-256 : MessageDigest md = MessageDigest.getInstance("SHA-256");


	

-Encryption : 데이터를 알아볼수 없도록 변환, 복호화 가능, 해당 데이터의 내용을 보호하는데 사용
	-대칭형 알고리즘 : DES, SEED(한국 KISA), AES(128~256)..
		장단점 : 상대적으로 속도가 빠르다, 그래서 장문의 데이터를 암호화 하는데 유리, 하나의 키만 존재함으로 전달된 비밀키가 노출되면 누구나 복호화 될수 있다.		
		코드 : 시크릿 키값(맘대로설정)으로 바이트어레이를 만들어 암호화에 이용, 16byte면 AES128, 32byte면 AES256이 된다. 암호화된 데이터를 Base64인코딩(디코딩)하여 리턴(웹에서 주로 사용해서 그런가??)
			AES256 :

	-비대칭형 알고리즘: RSA(SSL, TLS), Rabin..
		장단점 : 상대적으로 속도가 느리다, 그래서 짧은 데이터를 암호화 하는데 유리, 비밀키가 쌍(public, private) 으로 존해함 그래서 전달된 public 키가 노출되어도 복호화 되지 않고 public 키를 갖은 서버만 가능
		코드 : KeyPair 클레스를 이용하여 한상의 키를 만들어 낸다. 암호화할때는 public키로 하고 복호화할때는 private 키를 이용한다. 암호화된 데이터를 Base64인코딩(디코딩)하여 리턴(웹에서 주로 사용해서 그런가??)
			RSA : KeyPair keyPair = gen.genKeyPair();


		
	









[tomcat]
-서버 프로파일 설정 :
	-위치 : tomcatHome/bin/setenv.sh
	-내용 : JAVA_OPTS="$JAVA_OPTS -Dspring.profiles.active={profile_name}"

	-application-XenvVallueX.yml : 기본이 되는 yml 파일로 해당 프로파일에서 프로퍼티를 못 찾을 경우 application.yml 파일에서 찾게 되있다.
		-ex : env 가 stg 일경우 
			-application-stg.yml에서 환경 프로퍼티를 찾게 되있음 만약 해당 yml에서 찾을 수 없는 경우 기본 파일인 application.yml 에서 찾게 됨

		

[CDN]
-CDN은 원본서버로부터 전송받아 전달해 주고 캐시하는 역할을 합니다. 
	-기본적으로 중간 캐시 서버로써 원본 서버에서 에러가 발생한 url의 경우도 CDN에서도 그 에러 상태 그대로를 캐시하여 내려주는 것이지 별도의 처리를 하지 않는다.


[Node.js & NPM]
-설치 :
	-node.js 홈페이지를 통해 node.js 설치가 가능하며 보통 node.js를 설치하면 npm이 함께 설치됨. (node -v : 설치된 node.js 버전 확인, npm -v : 설치된 npm 버전 확인)

-node.js : 
	-개념 : 
		-As an asynchronous event-driven JavaScript runtime, Node.js is designed to build scalable network applications
		-Chrome V8 JavaScript 엔진으로 빌드된 JavaScript 런타임입니다. Node.js는 이벤트 기반, Non 블로킹 I/O 모델을 사용해 가볍고 효율적입니다. (chrome을 기반으로 한 jvm의 개념과 유사한 런타임 환경)
		-chrome base의 태생으로 실시간 웹 어플리케이션을 만들기에 적합하고 lock과 직접적인 i/o를 수행하지 않기 때문에 쉽게 확장 가능한 서비스가 개발 가능하다.
		-특정 js 파일을 실행할 수도 있고 특정 스크립트를 입력하여 실행할 수도 있는 cl 클라이언트를 제공한다. (일종의 컴파일러의 개념도 있어 보인다)
		
	-command : 
		-node : 직접 스크립트를 작성하여 테스트 해볼수 있는 cl 환경을 제공한다.
		-node abc.js : abc.js 파일을 실행해 준다.
-npm : 
	-개념 : 
		-Node Package Manager, 리눅스의 apt와 유사한 개념으로 javascript 모듈의 완성도를 확인 하여 storege에 올리는 관리 주체로서 사용자는 cl 클라이언트를 이용하여 다운 및 인스톨이 가능하다.
		-npm 을 통해 관리되는 패키지들은 브라우저 및 node.js 환경 (또는 그러한 개발환경)에서 사용하는 라이브러리, 컴포넌트 개념이다.
		-본인이 원하는 패키지를 직접 만들수 있도록 프로젝트(?) 개념을 제공하고 있는듯 (package.json 파일이 프로젝트 파일??), 
		
	-package.json : 패키지를 정의 하는 메타파일(프로젝트 파일??)		
		
	-package-lock.json : 패키지의 내부 dependency(그 dependency 마다 내부에 또 있구..) 마다 버전들이 있는데 그 하위 버전들까지 최상이 패키지는 알기 어렵다, 
		-그리고 그 버전도 특정 버전이 아니고 범위로 지정되는 경우도 많아서 현재 나의 패키지를 위해 하위 패키지들이 어떤 버전으로 설치되어 있는지 알기 어려움, 
		-그러한 일련의 모든 패키지 디펜던시 트리를 제공해 주는 역할을 한다. package.json 파일이 변경되는 시점에 변경된 내용을 기반으로 현재 설치된 정보를 재 정리 하게됨
		-depency 모듈을 함게 배포하지 않는 경우 반드시 해당 파일도 같이 배포되야 해야 안정적임, (package-lock.json 파일도 git을 통해 관리 할것)
		
	-command : 
		-npm init -y : 해당 폴더에 package.json을 생성해줘서 패키지를 구성할 수 있는 토대를 만들어 줌. 추가로 패키지를 인스톨하게 되면 node_modules(설치된 추가 패키지 저장 폴더) 및 package-lock가 생성
		-npm install mocha --save-dev : mocha라는 디팬던시를 설치해 주고 package.json에 반영해줌, --save(패당 패키지에서만 유효함) -dev(프로덕션 빌드시 포함안됨, 개발할때만 쓰겠다는..)
		-npm install mocha -g : mocha를 전역 install하겠다는 의미(사용자경로/AppData/Roaming/npm에 설치됨), 링크를 통해 특정 패키지에서 끌어 쓸수 있음
		-npm link mocha : 전역 설치된 패키지를 끌어다 현재 패키지에 적용할 수 있음
		
		-npm list : 현재 패키지에 구성된 트리
		-npm list -g : 글로벌 패키지 구성 트리
		-npm list -depth=0 : 1 댑스 까지만
		
	
	



[프로젝트 관리 툴]
-jira : 아틀라시안 에서 만든 프로젝트 관리 툴로 이슈 및 버그 추적, 칸반 보드등을 지원 한다.
	-구성요소 :
		-프로젝트 :
			-데이터 형식 :
				-이슈 :
				
			-뷰여 형식 :
				-백로그 :
				-작업중인 스프린트 :
				-배포 :
				-보고서 :
				-이슈 :
				-컴포넌트
				-WBS Gantt-Chart : 
			
		-보드 : 프로젝트의 뷰어 형식의 구성 요소 이기도 하면서 프로젝트를 초월하여 구성도 가능하다.
			-대시보드 : 
				-시스템 대시보드 : 기본으로 제공되는 대시보드로 프로젝트 목록 및 나에게 할된된 이슈등을 보여준다.
				-개인 대시보드 : 대시보도 관리를 위해 본인이 원하는 항목으로 구성된 대시보드를 만들 수 있다.
			-개인보드 : 직접 구성한 보드 
			
			-WBS Gantt-Chart : 
			
				

	-용어 : 
		-scrum :
		-scrum team : 이러한 조직
		-product owner : 제품 책임자
			-product backlog : product owner 가 관리하는 해야할 일 목록
		-sprint : 특정 사이즈의 업무 주기
			-sprint backlog : sprint 마다 해야할 일 목록
		-increment : 매 sprint 마다의 결과물
		-scrum master : 팀이 과제를 완수할 수 있도록 지원 및 인도
			
		
