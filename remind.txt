[IDE]
-sts : spring(boot) 연동 강점
	-java project(pojo) : pojo 프로젝트를 구성한다. new>project>java>java project
	-web project(tomcat base) : tomcat을 통한 기본 서블릿 구성. new>project>web>dynamic web project
	-svn project : svn에서 checkout 받아 프로젝트 구성. new>project>SVN>checkout projects from SVN>기본 연결된 repo에서 가져올지 새 repo를 연동해서 가져올지 정함

	-maven project
		-maven project(new) : new>project>Maven>Maven Project>quickstart>
			-group id : local/remote repo(.m2)에 위치하는 경로(?), 코드의 pakage와는 무관하지만 pakage 경로와 통일성 있게 쓰기도 함
			-artifact id : project 이름으로 사용되며 패키징 파일(jar,war)의 이름이 됨
			-version : pakage 파일(jar,war)의 초기 버전 설정, 실제 repo에 가보면 group-id(경로)>artifact명>virsion 순으로 저장됨
			-package : code상의 class pakage 경로

		-maven project(exist) : import>Maven>Check out Maven Project from SCM(git등 연동), Existing Maven Project(로컬파일)

		-Add Dependency : project에 필요한 lib를 추가 할수 있음(직접 pom 파일을 건들지 않는게 좋음)
			-project(클릭)>maven>Add Dependency>필요한 lib 검색 후 선택 (Enter groupid, artifact.. 입력란에서 검색해 봄. ex) log4로 검색해봄> 검색된 리스트에서 선택하면 pom에 적용됨
				-Scope : 해당 lib(dependency가 적용되는 범위, 테스트때만 필요한건지 최종 패키징에도 포함될지 말지..)
					-compile : ??
					-provided : ??
					-runtime : ??
					-test : ??
					-system : ??
		-Add Plugin : dependency와 동일한 개념으로 필요한 maven plugin(빌드 또는 deploy 하는 과정에서 필요로 하는 plugin등)을 추가 할수 있음
			-project(클릭)>maven>Add Plugin>필요한 Plugin 검색 후 선택, ex) deploy로 검색해봄

	-git project :

	-spring boot project :
		-import Spring Getting Started Content : Spring starter가 제공하는 project 유형별 샘플을 통해 프로젝트 구성. new>project>spring Boot>import Spring Getting Started Content>프로젝트 유형 및 빌드타입(maven/gradle)선택
		-Spring Starter Project : Spring starter가 제공하는 주요 dependency를 추가하여 프로젝트 구성. new>project>spring Boot>Spring starter Project>빌드타입(maven/gradle) 및 dependency 선택.

	-Eclipse plugin : 개발관련 IDE 플러그인 추가
		-Eclipse Marketplae :
			-ANSI Escape in Console
			-Buildship Gradle Integration 3.0
			-Darkest Dark Theme with DevStyle CI 2019.6.17
			-Eclipse Marketplace Client 1.7.7
			-Eclipse XML Editors and Tools 3.14
			-EGradle Editor 2.6.1
			-Enhanced Class Decompiler 3.1.1
			-Enide(Studio)2015
			-Enide.p2f
			-Gradle IDE pack 3.8.x
			-Minimalist Gradle Editor 1.0.1
			-Multiproperties 1.4.0
			-Nodeclipse/Enide Gradle for Eclipse 0.17
			-pmd-eclipse-plugin 4.6.0
			-Quick Search for Eclipse 3.9.9.RELEASE
			-Spring Tools 4
			-Subclipse 4.3.0

	-shortcut Keys
		-CTRL+SHIFT+T : class 찾기
		-CTRL+SHIFT+R : 파일 찾기
		-CTRL+E : 열려진 파일 목록
		-CTRL+F7 : view 목록

		-CTRL+M : 창 확대
		-CTRL+SHift+{ : 한파일 분할해 보기

		-CTRL+I : indentation 교정
		-CTRL+SHIFT+O : import 정리
		-CTRL+1 : fix 제안
		-ALT+Left/Right Arrow : 최근 작업 파일 이동
		-CTRL+k : 다음 찾기
		-CTRL+SHIFT+K : 이전 찾기

		-프로젝트 선택후 -> Source -> Organize imports : 프로젝트 전체 대상 import 정리
		-파일 선택 후 -> Source -> Generate toString() : 해당 클래스에 대한 toString() 함수를 생성해 줌
		-ALT+SHIFT+Z : Surround With (for, while, try 등 블륵 어시던트 기능)
		-CTRL+SHIFT+f : 자동 인던테이션

		-CTRL+SHIFT+x : 대문자로 변환
		-CTRL+SHIFT+y : 소문자로 변환

	-문제 해결
		-red-x icon : java 에러가 파일에 반영이 되지 않는 경우 확인, project->build automatically 확인
		-Hangs when building project : copying resources to output folder

	-편리 기능
		-bookmark : 원하는 위치에서 코드 라이 맨 앞에서 오픈쪽 마우스 클릭 -> add bookmark ->bookmarks(general) view에서 확인 가능
		-task : 원하는 위치에서 코드 라이 맨 앞에서 오픈쪽 마우스 클릭 -> add task ->tasks(general) view에서 확인 가능


	-디버깅 :
		-디버깅 perspective 로 전환 : 디버깅하기에 용이한 화면 구성으로 전환 하는 의미 (안해도 됨)
		-디버그 모드로 실행

		-디버깅 관련 view :
			-Debug : 디버깅 실행 시점부터 생성되는 쓰레드들과 그들의 연관 관계를 보여 준다.
				-!!각 쓰레드 별로 실행되고 있는 메모리에 올라와 있는 스텍(메소드??) 정보를 함께 보여 준다. spring과 같은 프레임워크의 내부 동작을 이해하는데 큰 도움이 될 수 있다.


			-Breakpoints : 잡혀 있는 break 포인트 목록을 보여준다
				-포인트 활성/비활성/삭제 가능


			-Variables : 포인트가 잡혀있는 현 상황에서 확인 가능한 변수의 value를 보여 주며 다른 값으로 수정 할 수 있다.
				-하나의 스텍으로 진입 하게 되면 해당 스텍에서 접근 가능한 변수만 보여 주고 있는듯.. !!컴퓨터의 동작 구성상 그럴수 밖에 없을 듯
				-화면 레이아웃 및 컬럼(보통 name, variableType, value) 추가/삭제 가능
				-Value 값은 해당 변수(객체)를 toString() 했을때의 값으로 경우에 따라 읽기 쉽지 않을 수 있다


				-화면구성 :
					-맨윗줄 : 바로 직전 실행된 코드의 return 값을 보여 줌 (retrun 값이 있을수 없는 코드인 경우 null로 나옴)
					-this : 해당 클래스!! 선택하여 내리면 해당 클레스의 멤버 변수를 보여줌
					-그아래 : 해당 메소드의 멤버 변수를 보여줌 (현재 stek 내의 메모리???)

			-Expressions : ???

		-디버그 포인트 설정 및 해제 : 코드 실행을 멈추기 위한 위치 선정 (해당 라인에서 멈출때 해당 라인은 실행되지 않음 시점), 코드라인 앞을 클릭해 선정(토글형식), 실행 중에도 추가/제거가 가능
		-skip all breakpoints : 모든 디버그 포인드 일괄 헤제
		-resume(F8) : 다음 포인트로 이동
		-suspend :
		-terminate : 디버깅 실행 종료 (실행 종료)
		-step into(F5) : 현재 라인이 메소드인 경우 메소드 내부로 들어간다.
		-step over(F6) : 현재 라인을 실행 시키고 다음 라인(논리적으로 다음 라인, 현재 메소드 내부에 한에서, !!그러나 호출된 외부 메소드 안에 브레이크 포인트가 있으면 그곳으로 이동)으로 내려 간다.
		-step return/out(F7) : 현재 메소드에서 리턴 한다 !!그러나 현재 메소드에 브레이크 포인트가 남아 있다면 그곳으로 이동
		-drop to Frame : 현재 스택(메소드)의 진입점 부터 다시 시작.
			-현재 스텍에서 이미 버러진 일이 없어지는 건 아니다. 하지만 해당 스텍이 처음 부터 다시 돌아 간다면 다시 변경된 값으로 덮어 써질꺼임..
			-주의!!
				-해당 스텍에서 쓰레드를 생성했거나 또는 변경한 값이(내 클레스든 타 클레스든) 이미 다른 쓰레드에서 읽어 가서 활용됐다면.. 타 쓰레드가 이미 행한 부분은 도릴킬수 없다.
				-현재 스텍의 첨으로 재 실행되더라도 해당 스텍에서 쓰레드를 만들었다면 해당 쓰레드는 여전히 돌게 됨 (기존 쓰레드는 계속 있고 새 쓰레드가 또 생김, 자기가 죽기 전까진)
				-!!drop to Frame이 안되는 스택이 있음 바로 JVM이나 TOMCAT(??) 과 같이 해당 스텍이 다른 프로세스?? 다른쓰레드?? 에서 호출된 첫번째 스택인 경우이다. (정확한 확인 필요하다.)
					-이러한 스텍은 java app의 메인 메서드 또는 Servelet의 컨트럴러 (uri 매핑되어 호출되는 메서드) 이다. 시스템이 첫 호출해 주는 스택????
					-이러한 스텍에서의 수정은 수정이 이루어져도 실제 반영되지 않는다.(이게 반영된다는 것은 내가 컨트롤할수 없는 타 쓰레드? 프로세스?에게 나를 다시 호출하라는 것이라 IDE의 권한 밖인듯...???!!!)

		-suspend : 특정 쓰레드의 동작을 정지시키는 의미 (해당스레드가 동작하지 않겠지?? 정확한것 확인 필요)

		-instruction steping mode : ????
		-setp until a message is received : ????
		-use step filters : ????


		-Hotswap(핫스왑) Bug Fixing : JVM 1.4 이상부터 지원하는 기능으로 Java Platform Debugger Architecture (JPDA)를 이용하여 구현됨.
			-코드를 수정하여 리컴파일이 이루어 지더라도 기존의 스텍 구성을 그대로 활용하여 디버깅을 이어서 진행할수 있다.(stop 또는 terminate 후 재시작하게 되면 기존 스텍을 모두 잃고 첨부터 재 시장됨)
			-파일 수정 저장하여 자동 리컴파일 현 디버깅 상태에서 resume을 통해 이어서 진행이 가능하다.
			-디버깅 시점까지 들어가기가 까다로운 케이스의 경우 도움이 될수 있다.

			-주의!!:
				-현재 잡혀있는 BP(breakpoint)가 속한 메스드는 해당 어플리케이션의 최상단 스텍이라 볼수 있다. (해당 쓰레드 기준으로 그럴수 밖에 없겠지??)
				-Hotswap을 하게 되면 현재 메소드(스택)의 첨부터 다시 시작됨 (drop to Frame 한것 처럼)
					-!! Hotswap이 동작하지 않는 스텍이 있음, drop to Frame의 내용을 참고!!!!

				-web 어플의 경우 핫스왑시 브라우저의 커넥션이 끊어지기 때문에 완전한 연속적 테스트는 불가능 하다.(연결 했었던 커넥션을 사용하는 코드를 만나기 전까진 진행 할수 있겠찌??)
					-브라우저가 핫스왑시 커넥션이 끊어지면 이후에 브라우저 자체 기능으로 리커넥션을 하는듯 하다.. 리커넥션되어 디버깅 혼선이 잇을수 있으므로 핫스왑중 해당 브러우저를 꺼버리는것도 방법이다.



-atom : git 연동 강점, 특정 language에 제한되지 않는다. (editplus 같이 가벼운 느낌임)



[JAVA]
-error :
	-compile error : 언어 syntat상 오류 및 코딩 중 잘못된 구문에 의해 발생하는 에러(서로 다른 타입의 케스팅 및 어싸인 등)로 보통 개발 tool에 의해 컴파일 전 에러가 걸러 진다.
	-runtime error : 실행중간에 논리적 오류에 의해 발생 (아직 null인 상태의 객체의 메서드를 사용하거나 하는 등)

-class 실행 : java -cp target/classesName
	-java : 해당 클레스를 콘솔 모드로 실행 (콘솔로그 확인 가능, 콘솔을 닫으면 종료)
	-javaw : 해당 클레스를 윈도우 모드로 실행 (콘솔 로그를 확인 할수 없음, 콘솔을 닫아도 종료되지 않음)
	

-class & JavaBean
	-java 코드로 작성된 클레스 파일임에서 동일하나 javaBean이 되기 위해서는 해당 클레스가 몇가지 표준을 지켜야 한다.
		-java.io.Serializable 를 implements 하여 직렬화가 가능하도록 하여야 한다.(단순히 해당 글레스에 implements java.io.Serializable 만해주면 됨)
		-아규먼트가 없는 public 형태의 생성자(constructor)를 가지고 있어야 한다.
		-모든 필드들을은 private로 구성하며 setter, getter로 접근할수 있도록 구성해야 한다.
		-필요한 이벤트 처리 메소드를 가지고 있어야 한다.(당연한 소리겠지?)
		
	-그럼 왜 JavaBean으로 명명하고 위의 제약을 만들었을까?
		-보통 jaavaBean은 특정 프레임워크(servlet engine등)등에 언쳐저서 동작하는 일종의 3rd 파티 클레스의(기능을 확정해주는 lib?) 역할을 하게 된다. 이러한 환경속에서 동작하기 위한 최소한의 규칙을 정의한것 이라고 보면 됨
			-ex : Spring의 IoC Container(=DI Container)를 통해 해당 객체의 생성 및 관리를 맞길수 있도록 하기위해 
		
	
-Data Object : 데이터를 담기위한 object로 고유의 개념적 특성 및 제약을 갖는다. 그런데 그러한 개념적 특성이 모든 상황에서 공유되기보다는(기본적으론공유되지만) 어떤 아키텍쳐 또는 방법론에서 논의 되는지에 따라 좀더 구체적인 특성 및 제약을 갖는다

	-Value Object(VO) : 
		-일반적 관점 :
			-생성될때 값이 정해지면(생성자에의해) 변경되지 않는 객체, 생성된 값을 유지하고 있는 하나의 데이터 셋이다. setter를 갖지 않고(immutable 특성을 갖음) getter만 같는다.
			-프로그램에서 상수의 의미처럼 해당 값을 갖는 하나의변수적(그안에는 여러값이 있을수 있다) 의미로 봐야한다. (ex: 지패VO-> 얼마짜리, 통화($,원))
			-java의 Enum 객체와도 유사함을 갖는다, lifespan(수정되거나하지않음으로)을 갖지 않으며 변경이 필요하면 삭제하고 새로 생성한다.
			-쉽게 복사 해서 사용할 수 있도록(값까지 동일한 해당 객체를 생성) Cloneable 인터페이스를 상속받아 구현하기도 함
		
		-Domain-driven design(DDD)에서의 관점 : DDD는 객체를 어떻게 나눌지가 Domain 관점에서 고려된다. 도메인은 해당 모듈의 활용?(사용자,목적)에 따라 달라진다.
			-DDD 개념에서 주로 언급되는 객체이다. DDD에서 Entity는 identity를 갖는 객체가 대상이 되면 Entity안에 properties의 개념이 필요한 경우 VO로 정의 한다.
				-사람(Entity: 주번(pk), name, address(VO), 갖은돈List[지패(VO)]), address(VO: 국가, zipcode등 선택할수 있는 attributes를 갖는다), 지패(VO: 얼마짜리, 통화)
					-사람의 관점(Domain)에서 본다면 지패는 하나의 VO에 불과 하지만 자금흐름의관점(Domain)에서 본다면 지패에 일련번호(pk)가 추가되게 되고 지패가 하나의 Entity가 될수 있다.
						-DDD에서 Entity는 pk를 정보를 포함하고 있는 Data Object로 여긴다.
		
		
	-Data Transfer Object(DTO) : 
		-일반적 관점 :
			-아키텍쳐상 또는 object간 데이터를 주고 받기 위한 데이터 set으로 구성된 객체 이다. setter, getter을 모두 갖는다.
			-특별한 제약 조건을 갖지 않고 명칭의 의미데로 데이터를 주고받는 용도로 활용한다.
		
	-Entity :
		-일반적 관점 : 
			-OOP에서 바라보는 객체의 관점과 유사하다, identity를 갖고 있는 대상
		
		-Domain-driven design(DDD)에서의 관점 :
			-고유의 정체성을 갖은 객체가 대상이 된다. 보당 해당 대상은 고유의 값을 갖는다(pk)
			-고유의 lifespan을 갖는다 다시말해 값을 수정하고 저장할수 있다
			-고유의 table이 보통 존재한다.
			-value object를 참조할 수 있다.
			-어떤 도메인의 관점에서 보느냐에 따라 달라 질수 있다.
			
		-Java Persistence API(JPA)에서의 관점 :
			-DB 테이블상의 row를 표한하는 객채이다.
			-보통 플랫폼 상에서 @Entity 어노테이션을 사용하여 JPA가 알수 있게 하며 IoC를 위해 final로 만들어서는 안되고 no-args 생성자와 primary key를 갖어야 한다.
		
	-Model :
		-일반적 관점 :
			-application의 데이터를 담기위한 container 역할을 하는 객체
			
		-MVC 관점 :
			-controller와 view 계층간 데이터를 주고 받기 위한 bridge 역할을 하는 객체 또는 레이어(추상적)
			-Spring의 경우 controll에서 param을 통해 model 인터페이스를 상속박은 객체를 얻을 수 있고 해당 object를 통해 데이터를 남아 view 단으로 내려 줄수 있다. 
			

Markup language and DOM : 
	-Markup language : 마크업 언어란 태그를 이용하여 문서나 데이터의 구조를 명기해논! 언어
		-주요 마크업언어 : 
			-SGML(Standard Generalized Markup Language) : 마크업 언어를 정의하기 위한 메타 언어 (다소 복잡하여 작은 규모에 적용시 번거롭다, 오래된 규격?? )
				-XML(Extensible Markup Language) : SGML을 단순화하여 파생된 언어이다. 데이터를 명기한 문서 자체로도 사용하나 다른 마크업 언어를 정의하는데 그 문법 형식이 상용되기도 한다.
					-xml의 큰 구분 
						-well-formed xml : xml의 기본 syntax가 허용하는 모든 구성을 갖는 문서, syntax는 엄수해야 하지만 아래서 계속 설명될 XSD, DTD 등으로 문서의 구조가 디파인되진 않는 문서다. 일반적으로 개발자들이 임의로 정의하는 xml 문서가 해당된다.
						-valid xml : 당연히 xml syntax가 엄수되야 하며 더불어 XSD, DTD 등으로 부터 그 문서의 구조가 디파인되는 문서
				
					-XSD(XML Schema Definition) : W3C 권고를 만족하는 첫 번째 XML 스키마 전용 언어
						-XML 문서가 그 스키마에 대하여 '유효'한 것으로 여겨지기 위해 반드시 지켜야 하는 규칙들의 집합을 표현하는 데 쓰인다. 다시말해 해당 xml이 약속대로 만들어지도록 하기 위한 규칙 모음이다.
						-유효성 검증 엔진을 통해 작성된마크업문서(instance Document)를 XSD통해 검증 할수 있다.
						-스키마가 정의하는 요소 : element 항목, attribute 항목, 각 값에 대한 선택지(들어올수 있는 값의 보기를 한정), 값에 대한 type 정의(기본형 부터 사용자가 별도 정의 가능, 이 기능이 DTD와 비교했을때 우월? 하다)
						-기타 : name space기능?을 사용할수 있다, 프로그램을 통해 XSD 문서를 통해 자동으로 XML을 생성해 낼수도 있다(이를 XML 바인딩 이라 한다.)
							-Name Space : 하나의 문서에 동일한 이름의 엘레먼트가(이름은 같지만 의미는 다른)존재하여 name confilic가 발생하는 것을 막기위한 방법이다.
								-여러 xml을 조합하여 하나의 xml을 만들어야 하는 경우가 있을수 있는데(구매xml을 만들때 고객xml의 고객id와 상품 xml의 상품id가 둘다 id를 사용할 수 있음) 이때 그저 문서상에 element나 attribute 명칭이 같지 않도록 하는 방법
								-특별한 의미가 있는것이 아니라.. 문서상 xmlns=xxuri 또는 xmlsn:xx(줄임단어,prefix)="XXuri" 형식으로 정의하고 하단의 element또는 attribute 에 prefix값을 붙여서 <xx:id>sungilry</xx:id> 와 같은식으로 사용한다.
								-name pace의 값으로 사용한 uri의 경우 특별한 기능적 의미는 없다(실제 그 uri에 뭐가 올라와 있어야 하는 것이 아니라 그냥 유니크한 스트링이 필요해 uri 형태를 구성한 것 뿐이다. 이에 대해 논란도 있다)
								-Name Space 구성은 xml 내부 같은 파일에 구성할 수도 있고 별도의 XSD에 구성할수도 있는것 같은데.. 그 문법과 방식이 너무나 다양하고 헷갈리는 부분이 있어서 잘 정리가 안된다!! 잘사용되지 않으니 개념적으로만 알아둬도 될듯!! 
								
								-Name Space의 코드레벨 의의 :
									-프로그램적으로 parser에 의해 처리될때 name pace값을 활용할 수 있다(물론 언어의 파서가 지원해야 겠지만) 특정 name space의 엘레먼트만 가져온다든지!!
						-XSD의 코드레벨 의의 :
							-?? 확인 필요
							
						-----
						XSD 예
						-----
							<?xml version="1.0" encoding="utf-8"?>
							<xs:schema elementFormDefault="qualified" xmlns:xs="http://www.w3.org/2001/XMLSchema">
								<xs:element name="Address">
									<xs:complexType>
										<xs:sequence>
											<xs:element name="Recipient" type="xs:string" />
											<xs:element name="House" type="xs:string" />
											<xs:element name="Street" type="xs:string" />
											<xs:element name="Town" type="xs:string" />
											<xs:element name="County" type="xs:string" minOccurs="0" />
											<xs:element name="PostCode" type="xs:string" />
											<xs:element name="Country" minOccurs="0">
												<xs:simpleType>
													<xs:restriction base="xs:string">
														<xs:enumeration value="IN" />
														<xs:enumeration value="DE" />
														<xs:enumeration value="ES" />
														<xs:enumeration value="UK" />
														<xs:enumeration value="US" />
													</xs:restriction>
												</xs:simpleType>
											</xs:element>
										</xs:sequence>
									</xs:complexType>
								</xs:element>
							</xs:schema>
						-----
												
					-DTD(Document Type Definition) : XSD와 목적이 거의 같다, 하지만 DTD의 D(Document)가 의미하듯 xml 문서뿐 아니라 모든 마크업 문서를 형식을 정의하기 위한용으로 범위가 넓고 그러다 보니 세밀함이 적다. SGML표기법을 따르며 조금 어렵다.
						-XSD에 비해 name space 와 값들의 data type 설정을 지원하지 않는다.
						-DTD도 XSD와 마찮가지로 그 문법과 방식이 너무나 다양하고 헷갈리는 부분이 있어서 잘 정리가 안된다!! 잘사용되지 않으니 개념적으로만 알아둬도 될듯!! 
						-----
						DTD 예
						-----
							<!DOCTYPE TVSCHEDULE [

							<!ELEMENT TVSCHEDULE (CHANNEL+)>
							<!ELEMENT CHANNEL (BANNER,DAY+)>
							<!ELEMENT BANNER (#PCDATA)>
							<!ELEMENT DAY (DATE,(HOLIDAY|PROGRAMSLOT+)+)>
							<!ELEMENT HOLIDAY (#PCDATA)>
							<!ELEMENT DATE (#PCDATA)>
							<!ELEMENT PROGRAMSLOT (TIME,TITLE,DESCRIPTION?)>
							<!ELEMENT TIME (#PCDATA)>
							<!ELEMENT TITLE (#PCDATA)> 
							<!ELEMENT DESCRIPTION (#PCDATA)>

							<!ATTLIST TVSCHEDULE NAME CDATA #REQUIRED>
							<!ATTLIST CHANNEL CHAN CDATA #REQUIRED>
							<!ATTLIST PROGRAMSLOT VTR CDATA #IMPLIED>
							<!ATTLIST TITLE RATING CDATA #IMPLIED>
							<!ATTLIST TITLE LANGUAGE CDATA #IMPLIED>
							]>				
						-----
						
					-XSL(eXtensible Stylesheet Language) : XML을 위한 스타일링 언어이다, html의 css와 같은 존재이다. 
						-스타일을 만든다는 것에서 알수있다 어디서 보여질지가 중요한데 보통의 경우 xml 문서와 xsl 문서의 조합으로 브라우저에서 보여지는 용도를 쓰였다. (지금은 이게 쓰일까?)
						-MVC 개념에서 View 단의 개념과 유사하며 View Resolver 역할의 JSTL 등의 로직 문법과 유사하다.
						-----
						XSL 예
						-----
						<?xml version="1.0" encoding="UTF-8"?>
						<catalog>
							<cd>
								<title>Empire Burlesque</title>
								<artist>Bob Dylan</artist>
								<country>USA</country>
								<company>Columbia</company>
								<price>10.90</price>
								<year>1985</year>
							</cd>
						.
						.
						</catalog>
						
						위 같이 xml 문서가 있고 아래와 같이 XSL 문서가 있을때 
						
						<?xml version="1.0" encoding="UTF-8"?>

						<xsl:stylesheet version="1.0"
						xmlns:xsl="http://www.w3.org/1999/XSL/Transform">

						<xsl:template match="/">
							<html>
							<body>
							<h2>My CD Collection</h2>
							<table border="1">
								<tr bgcolor="#9acd32">
									<th>Title</th>
									<th>Artist</th>
								</tr>
								<xsl:for-each select="catalog/cd">  ----->논리적인 로직(JSTL 같은 느낌)
								<tr>
									<td><xsl:value-of select="title"/></td>
									<td><xsl:value-of select="artist"/></td>
								</tr>
								</xsl:for-each>
							</table>
							</body>
							</html>
						</xsl:template>

						</xsl:stylesheet>						

						xml 문서에 XSL을 연결해 주고 브라우저에서 확인해 보면 새로운 형태의 모양을 확인 할수 있다.  ex : https://www.w3schools.com/xml/tryxslt.asp?xmlfile=cdcatalog&xsltfile=cdcatalog
						<?xml version="1.0" encoding="UTF-8"?>
						<?xml-stylesheet type="text/xsl" href="cdcatalog.xsl"?>  ---> XSL 결합
						<catalog>
							<cd>
								<title>Empire Burlesque</title>
								<artist>Bob Dylan</artist>
								<country>USA</country>
								<company>Columbia</company>
								<price>10.90</price>
								<year>1985</year>
							</cd>
						.
						.
						</catalog>
						-----
					
					-XPath :
						-Xpath는 xml 문서의 노드를 정의하기 위해 생성한 경로식? 이며 이 경로식을 통해 문서상의 특정값을 빠르게 찾을 수 있다, 프로그램에서 경로의 값을 찾을때도 사용되며, XSL등에서도 xml의 특정값을 찾기 위해서도 사용된다.
						-----
						XPath 예
						-----
						<?xml version="1.0" encoding="utf-8"?>
						<wikimedia>
							<projects>
								<project name="Wikipedia" launch="2001-01-05">
									<editions>
										<edition language="English">en.wikipedia.org</edition>
										<edition language="German">de.wikipedia.org</edition>
										<edition language="French">fr.wikipedia.org</edition>
										<edition language="Polish">pl.wikipedia.org</edition>
									</editions>
								</project>
								<project name="Wiktionary" launch="2002-12-12">
									<editions>
										<edition language="English">en.wiktionary.org</edition>
										<edition language="French">fr.wiktionary.org</edition>
										<edition language="Vietnamese">vi.wiktionary.org</edition>
										<edition language="Turkish">tr.wiktionary.org</edition>
									</editions>
								</project>
							</projects>
						</wikimedia>
						위와 같은 xml이 있을때 아래의 Xpath 경로식을 통해서 특정 경로의 값을 표현 할수 있다.
						-/wikimedia/projects/project/@name
						-/wikimedia/projects/project/editions/edition[@language="English"]/text()
						-/wikimedia/projects/project[@name="Wikipedia"]/editions/edition/text()
						-----						
						
					
					-XHTML(Extensible Hypertext Markup Language) : HTML이 SGMK에서 파생된것 처럼 XHTML은 XML에서 영향을 받아 파생 되었다. (HTML의 후속 버전이 아니라 다른 표준, 그러나 거의모든 브라우저에서 HTML, XHTML모두 호환됨)
						-기존 HTML이 엄격하지 않은 이유로 부정확한 html을 지원하기 낭비되는 리소스가 많았음(기타 디바이스 환경에서는 이러한 리소스가 부족함), 하여 DTD를 이용할 수 있는 XML기반의 XHTML을 만들어 정확한 문서를 만들수 있게 규정함.
					
				-HTML(Standard Generalized Markup Language) : SGML에서 영향을 받아 파생되었다. 브라우저에 특화된 마크업언어이다.
					-HTML5 : HTML4.01 의 차세대 표준안으로 확정, 몇몇 UI적 요소가 추가 되었으며, 멀티미디어(audio, video, canvas)를 별도의 플로그인(엑티브X) 없이 재생할수 있는것을 목적으로 함
	
	-DOM(Document Object Model) : 마크업 언어로 작성된 문서를 구조화된 오브젝트로 만들어 프로그램 영역으로 가져오기 위한 인터페이스(모델법)이다. 마크업 언어로 작성된 텍스트를 object 객체로 변형한 인스턴스라 볼수 있다.
		-DOM이 문서를 객체화한 인스턴스라 했을때 해당 객체의 구조를 노드트리라 표현한다.
		-!! DOM에 대해 설명할때 document의 종류와 parser 또는 viewer의 종류에 따라 설명이 달라질 수 있다
			-Html에서의 DOM :
				-DOM과 HTML은 항상 일치하는 것이 아니다 : html에 오류가 있을때 parser는 오류를 적절히 수정하여 dom을 구성하기 때문, 또한 Html에서 javascript를 만나서 동적인 내용이 추가되면 dom은 그에따라 변경됨(html은 당연 변경안됨)
				-DOM은 브라우저에서 보여지는 내용이 아니다 : 브라우저(뷰포트)에서 보여지는 내용은 랜더트리가 담당하고 있다 랜더트리는 DOM과 css(CSSSOM)의 조합으로 구성된다. 일예로 css에 의해 hidden된 항목은 랜더트리에는 포함되지 않는다.

		
			



-jar 실행 : java -jar target/jarFileName.jar MainClassFileName (실행가능 jar파일로 패키징 되어 있어야 함)


-System property : JVM에서 set, get 하여 사용할 수 있는 프로퍼티, (특정 프로퍼티는 직접 설정하지 않아도 이미 설정된 내용을 가져 올수 있다.)
	-특정 프로퍼티 예 :
		-System.getProperty("java.vm.version") //시스템상의 vm 버전을 알수 있다.

	- 코드 상에서 추가 : 클레스페스 내부의 yml 파일을 프로퍼티로 올림
		-----------
		System.setProperty("spring.config.location", "classpath:/application-rstg.yml"); //스프링에서 사용할 spring config 파일 위치 설정, 특정 프로파일 이름은 spring에서 직접 사용함
		System.getProperty("spring.config.location", "default value"); //해당 프로퍼티 값이 없을 경우 default 값을 설정 할수 있다.
		-----------
	- JVM 구동시 param으로 전달 가능 : -D my.id=sungil


-Handler and Listener : Handler는 어떤 역할을 담당하기 위한 클레스, Listener는 어떤 객체를 모니터링(상태 체크)하기 위한 클레스
	-doxxx(method) : Handler에서 보통 사용되는 method 이름
	-xxxCreated, xxxDestroyed(method) : Listener에서 보통 사용되는 method 이름


-ThreadLocal : 동일한 스레드에서만 공유되는 일종의 전역적 변수입니다.
	-웹 서비스에서 Request는 스레드기반이므로 동일 요청에서 호출된 메서드에서는 동일한 ThreadLocal 변수를 참조할 수 있습니다.(일반적인 WAS 서버가 Thread Pool 방식을 사용하기 때문에 재사용시 반드시 remove를 통해 초기화 필요)
	- InheritableThreadLocal : 하위 Thread에서 변수를 공유하기 위해서는 InheritableThreadLocal 로 생성해야 함


-Instance initializer block(IIB) : 클레스 내부에 {}으로 처리된 영역, 생성자와 유사한 의미를 갖으며 여러 생상자가 있는경우(param 값이 다른) 각 생성자에서 공통으로 처리되는 내용을 넣을때 활용될 수 있다.
	------
	class A{  
		A(){System.out.println("parent");}  
	}  
		
	class B3 extends A{  
		B3(){super(); System.out.println("child with 1");}  
			
		B3(int a){super(); System.out.println("child with " + a);}  
			
		{System.out.println("IIB");} //---> IIB 블럭은 각 생성자가 실행될때 super(); 문구 다음 순서로 처리된다. (내부적으로는 컴파일시 IIB 블럭이 생성자 않으로 들어가서 컴파일 되는듯)
			
		public static void main(String args[]){  
			B3 b1=new B3();  
			B3 b2=new B3(2);  
		}  
	}  
	---------
	결과 : 
		parent, IIB, child 1 
		parent, IIB, child 2 
	---------


-this and this() :
	-this : 자신의 클레스 변수를 의미
		-----------
		private int myValue = 10;

		void myMethod(int value){
			this.myValue = value;
		}
		-----------

	-this([params]) : 생성자가 여러개 있는 클레스의 경우 생성자 메서드 내에서 다른 생성자를 호출하는 의미
		-----------
		Class MyClass {
			private initValue;

			void MyClass(){
				this("default"); // 다른 생성자 메소드를 호출하는 방식
			}
			void MyClass(String value){
				this.initValue = value;
			}
		-----------


-Thread and Runable : Thread를 만들기 위한 class and implement
	-----------
	class MyThread extends Thread{
		public void run(){ //overwirte
			for(int i=0; i<1-; i++) System.out.println(i);
		}
	}

	class MyRunable implements Runable{
		public void run(){ //overwirte
			for(int i=0; i<1-; i++) system.out.println(i);
		}
	}

	class MyMain{
		public static void main(String args[]){
			Thread myThread = new MyThread();
			myThread.start();

			MyRunable myRunable = new MyRunable();
			Thread myRunalbeThread1 = new Thread(myRunable);
			Thread myRunalbeThread2 = new Thread(myRunable); //myRunable 객체를 재활용 할수 있다(메모리 이점)
			myRunalbeThread1.start();
			myRunalbeThread2.start();

			//Thread myRunalbeThread = new Thread(()->{System.out.println();}); 람다로 작성할수도 있음
		}
	}
	-----------
	-Runable 장점 : Thread에 비해 장점을 갖음
		-extends 하지 않으므로 extends가 필요한 경우 사용할수 있다.
		-Thread 객체와 동작 메소드(run)를 구분하여 클래스를 생성 할수 있다. 이경우 메서드를 여러게 만든다면 runalble 객체를 재활용(공유)하여 사용할수 있다. (메모리 이점이 생긴다)
		-일회성 클래스의 경우 람다 또는 instance class를 생성하여 코드 작성을 간단히 할수 있다.


-Thread and join() : 해당 Thread가 작업을 완료할때 까지 호출자 클래스가 wait 함 (Thread 안에서 Thread를 생성하면 APP 전체는 멀티쓰레드로 동작하면서 필요에 따라 하위 Thread가 종료될때까지 상위 Thread를 대기 시킬수 있다)
	-----------
	Thread myThread = new Thread();
	myThread.start();

	try {
		myThread.join(); //이 지점에서 콜러 쓰레드는 myThread가 작업을 종료할때까지 wait하게 됨, myThread.join(5000); 최대 wait 시간을 설정할 수도 있다.
	} catch (InterruptedException e) {
		System.out.println(t1.getName() + " interrupted");
	}

	System.out.println("end");
	-----------


-enum (class): class 와 유사한 형태의 열거체, 이름과 값을 동시에 사용할수 있다(boolean 의 true/false, 0/1, 특정 스트링값 처럼) index 번호도 알수 있음
	-선언 :
		-별도 class 형태 : 별도의 자바 파일로 생성
			-----------
			enum Rainbow {
			  RED, ORANGE, YELLOW, GREEN, BLUE, INDIGO, VIOLET //선언 끝에 ;(세미콜론) 없음
			}

		-class 내부 형태 : class 파일 내부에 inner class 형태로 생성
			-----------
			//int 형인 경우
			public class Myclass{
				...
				enum Rainbow {
					//()를 통해 상수에 값을 할당 할수 있음 (boolean 의 True=1 과 같은 의미)
					RED(3), ORANGE(10), YELLOW(21), GREEN(5), BLUE(1), INDIGO(-1), VIOLET(-11); //내부 선언시 끝에 ; 있음

					//상수에 값을 할당 했으면 값을 가져오기 위한 생성자 및 메소드를 enum 내부에 구현 해야함
					private final int myValue;
					Rainbow(int value) {
						this.myValue = value;
					}
					public int getMyValue() {
						return myValue;
					}
				}
			}

			//String 형인 경우
			public enum MylogLogLevel {
				FATAL("fatal"), ERROR("error"), WARN("warn"), INFO("info"), DEBUG("debug"), TRACE("trace"), NA("");
				private final String myValue;

				MonlogLogLevel(String value) {
					this.myValue = value;
				}

				private String getValue() {
					return myValue;
				}
			}
			-----------

	-사용 :
		-----------
		//기본 사용
		public void myTest() {
			Rainbow myRainbow = Rainbow.RED;
			Rainbow yourRainbow = Rainbow.BLUE;

			if(myRainbow.compareTo(yourRainbow) < 0) {
				System.out.println(myRainbow);
				System.out.println(myRainbow.name());
				System.out.println(myRainbow.getMyValue());

				for(Rainbow rainbow : Rainbow.values()) {
					System.out.println(rainbow);
				}
			}
		}

		//응용 사용 (특정 함수에 특정한 값만 들어가기 위해서 특정 값만 갖은 enum을 생성하여 선택적으로 사용 가능)
		MyLogger.log(MylogLogLevel.ERROR, "메시지.."); 로그레벨 파람을 특정 값으로만 받고 싶은경우
		//MyLogger 함수 내에서는 MylogLogLevel.ERROR.getValue()로 실제 값을 가져올수 있다.
		-----------


-Static Import : 자주 사용하게될 static 클레스에 대해 import를 static하게 하면 사용할때마다 매번 모든 경로를 쓰지 않아도 된다.
	---
	import static java.lang.System.*; ->static import해 논는다.
	class StaticImportExample{  
		public static void main(String args[]){  
			 
		 out.println("Hello"); //매번 System.out하지 않아도 된다.
		 out.println("Java");  
		
	 }   
	} 	


-Varargs (Variable Argument) : 메소드의 파람을 가변적(0개부터 n개)으로 받아들일수 있는 구조이다
	---
	void display(String... values){ ->타입에 ...을 표기하여 적용한다, 기존에도 void display(String[] args) 이렇게 유사히 할수 있었지만..훨씬 개선? 된듯.
		for(String s:values){  ->내부에서는 Enhanced For Loop를 이용해서 활면 하면 된다.
			System.out.println(s);  
		}
	}
	
	display(); ->파람이 있던 없던 모두 동일한 메소드를 호출한다.
	display("1");
	display("1", "2"); 
	
	-기본룰: 가변변수는 메소드에 하나만 존재해야 하며 반드시 마지막 파람에만 적용 가능하다.
		---
		void display(Aclass aclass, int intvalue, String... values){} ->aclass, intvalue는 고정된 파람이며 마지막 values만 가변 변수이다.

	
-Enhanced For Loop : []array 및 collection 객체에 대해 loop를 쉽게 처리하게 해준다.
	-기본형태 : for(data_type variable : array | collection){ ... }
	-[](array) : int arr[] = {12,13,14,44};  for(int i:arr){ ... }
	-collection류 : ArrayList<String> list = new ArrayList<String>(); ... for(String s:list){ ... }
	
	
-Assertion : 간단한 테스트를 하기 위한 목적으로 사용되는 구문?이다.(자바 기본 문법이라 보긴 이상함) 
	-기본형식 : assert 조건 : 에러 메시지;
	-기본 예 : assert Myvalue>=18:" Not valid";  ->assert를 따로 생성하고 하는것이 없음, 값이 19면 Exception in thread "main" java.lang.AssertionError: Not valid 에러를 발생 시킨다.
	-기본 룰 : 
		-퍼블리 메소드의 아규먼트를 체크하는 용도로는 사용하지 말것을 권고? (아규먼트에서 에러가 나는것은 원래 해당 runtime에러로 처리하는게 맞다는 의미로 보임)
		-런타임시에도 해당 구문을 동작시키기 위해서는 java -ea Myclass 와 같이 -ea 또는 -enableassertions 옵션을 주고 실행해야함 (원래 목적이 테스트임으로 기본 런타임에서는 실행하지 않는게 맞다고 보는 듯)
		
		
Numeric Literals with Underscore : 우리가 읽기 쉬우라고(헷갈리지않게) 긴숫자에 , 찍듯이 _ 구분자를 쓸수 있게 하고 있다. 약간의 룰이 있기는 한데 특별히 중요해 보이진 않음
	-int a = 1_000_000; ->1000000 과 같음
	-float b = 10.5_123f; ->10.5123 과 같음
	
-->여기가지

-call by value & reference
	-call by value : 기본 type(int, long, String..), 값만 복사해서 넘어감
	-call by reference : 기본 타입이 아닌 클래스, 해당 클레스의 "주소변수"를 복사해서 새로운 "주소변수"를 넘김(두개의 "주소변수"에서 "가리키는" 실제값의 주소는 동일함)

		-----------
		String a = "a", b = "b";
		public void mytest1(String c, String d) { //내부에서 하는 어떤 행위도 origin 값에 영향을 못준다.
		-----------
		Myclass c = new Myclass()
		Myclass d = new Myclass()
		public void mytest1(Myclass c, Myclass d) { //위의 c,d 와 메소드 네의 c,d는 동일한 실제값의 주소를 가리키지만 해당 4개의 주소 변수는 모두 각각임
			c.setName(d.getName); //주소를 통해 실제 object의 값을 변경했으므로 origin 값이 바뀐다.
			c = d;                //메소드 내의 c는 메소드 밖의 c와 다른 변수임으로(실제값의 같은 주소를 보기하지만) 메소드내의 c의 주소값을 변경해도 메소드 밖의 c에 주소값에는 영향이 없다
		-----------
		
		
-new(생성자)의 의미 및 기본 자료형 : 		
	-Primitive Types Variables (기본형 변수) : byte, short, int, long, float, double, boolean, char 이들은 확정된 크기의 데이터 타입으로 해당 변수에는 실제 값의 데이터(literal)가 들어감
		-다른 변수(class 변수)들은 해당 클레스의 실제 데이터가 저장된 위치의 시작 주소가 들어감. 그래서 이러한 클레스를 생성할때는 ClassXX classXX = new ClassXX(); 처럼 new를 사용하여 실제 공간을 생성하고 new는 해당 공간의 시작 주소를 리턴하게 된다.
		-그러나 기본 변수들은 정해진 크기의 영역으로 해당 변수에 해당 데이터의 주소가 들어가는것이 아니라 실제 데이터 값(literal)이 들어가기 때문에 new 를 사용하지 않고 int int intVal = 10; 이렇게 할당 할수 있는 거임
		
		-String의 경우는 조금 특별한 케이스로 String stValr = "aaa"; 라고 했을때 String이라는 객체는 이미 시스템에 존재해 있고 그 객체의 String pool 에 해당 값을 넣는 형태임(물론 해당 공용? String 객체는 Thread 별로 존재함)
			-string pool에는 동일한 값이 있는 경우는 추가로 추가되지 않고 pool에 있는 동일한 주소를 바라봄 그래서 Strig a = "abc"; String b = "abc"; if(a==b) 했을때 true가 됨(==는 주소값을 비교), spring pool은 일종의 상수목록 처럼 동작
			-그래서 String a = new String("abc"); String b = new String("abc"); if(a==b) 하면 false가 됨, 이경우는 공용 String pool을 사용한것이 아니라 별도의 String 객체를 생성하여 pool에 넣었기 때문에 주소가 서로 달라지는 것
			-이렇게 동작하는 이유는 String의 경우 그 value 값이 매우 길어질수도 짧아질수 하는 등의 가변적이기 때문에 특정 싸이즈의 메모리 공간을 바로 할당 할수 없기 때문으로 보임(시스템 리소를 아끼는 측면과 더블어..)
			-유사한 케이스로 Integer.parseInt("1"); 과 같이 기본 변수형 클레스의 메소드를 static하게 불러 쓸수 있는데 이또한 공용 String 객체가 있는것 같이 공요 Integer 클레스가 존재하기 때문임, int.parseInt("1"); 이렇게는 불가
			

		-Wrapper class :  8개의 기본 타입에 해당하는 데이터를 객체로 포장해 주는 클래스를 래퍼 클래스를 말한다. (이것의 이점은 해당 기본 자료형과 관련해 필요한 부가 메서드들을 사용할 수 있게 해준다.)
			----
			Integer num1 = new Integer(7); //박싱
			int int1 = num1.intValue(); // 언박싱
			----
		
	-new의 의미 : new는 기본 자료형(literal 형태)이 아닌 클레스를 생성(클레스가 들어갈 메모리 공간을 확보하여)하여 해당 메모리 공간의 시작 주소를 리턴해 준다.
		-!!! 그럼 int a = 10; int b = a; 코드에서 a안에는 실제값인 10이 들어 있는데 그럼 b=a 할때 시스템은 a의 메모리 위치를 어떻게 찾아 a안의 실제값을 b에 어떻게 널까?? (사실 XXclass xxClass = new XXclass(); 형태도 마찮가지임)
			-!!! 코딩 로직상에서 변수 안에 데이터값(literal) 또는 클레스 주소가 들어가는 문제와 실제 시스템이 b=a 했을경우 a의 메모리 위치를 찾는 부분은 전혀 다른 의미이다. 그건 코딩 영역을 떠난 VM 또는 시스템 상의 처리가 있을 것이다.)
			-!!! 다시말해 xxClass xc; 이렇게 클레스 변수가 선언되면 해당 클래스의 인스턴스의 주소(인스턴스의 구성에따라 여러 주소를 갖을수 있겠지?)를 담을수 있는 공간이 할당되고 이 공간에 대한 주소는 아마도 VM 또는 시스템이 관리할듯
			-!!! VM이 관리를 하는것 같고 그 영역은 Code 영역의 메모리일것 같다.(Code 영역이란게 실제 text 형태가 아니라... 연산비트와 주소비트들의 내용일 것으로 생각되기 때문)
				-!!constant poll : ??
				-!!Runtime Constant Pool : 위에 각 변수 및 인스턴트들을 참조하는 영역으로 보여짐, 변수?와 물리적 주소의 메핑 테이블 형태로 보임
	
	
-java(사실 모든 언어 공통 사항 일듯)의 메모리 관리 형식 :
	-Code 영역 : 개발자가 작성한 소스코드가 로딩되는 영역으로 텍스트 영역이라고도 함, 프로그램의 함수내용, 제어문, 상수(변화지않는 값임으로 code 취급 되는듯) 데이터가 저장된다.
	-Data 영역 : 코드상의 전역변수 및 static변수가 저장되는 영역, 프로그램 종료시 소멸된다.
	-Stack 영역 : 프로그램이 동작하며 로직상의 처리과정에서 발생되는 데이터를 저장하는 임시 메모리 영역이다, 코드의 흐름(사용자의동작)에 따라 동적으로 추가되고 소멸되고를 반복한다. 
		-쓰레드를 시작으로 하나의 스텍이 생기고 거기서 함수 호출시 해당 스텍안에 하나의 스텍이 추가됨(하이라키한 구조가됨), 해당 함수에서 사용되는 지역변수 및 매개변수가 저장되는 영역이며 함수가 종료(return) 되면 소멸된다.
		
	-Heap 영역 : 클레스가 생성되었을때 해당 클레스의 실제 데이터 영역이다. 해당 클레스의 주소를 갖는 변수는 Data영역, Stack영역에 생성되겠지만 그 주소가 가리키는 실제 데이터의 영역은 Heap 영역에 존재한다.
		-프로그램이 동작하면서 동적으로 늘어다 줄었다 하게 된다.(java에서는 해당 메모리를 명시적으로 릴리즈 해주지 않기 때문에 GC가 해당 주소를 어떤 변수도 참조하고 있지 않은 경우 알아서 가비지컬렉션을 해준다)
		
	-!!! Stack 및 Heap 영역의 크기는 VM 또는 시스템이 정하게 되는데(셋팅도 가능하겠지?) 연속된 메모리상에 존재하기 때문에 너무 많은 데이터를 요구하는 상황에서 오류가 발생될 수 있다.
		-Heap Over Flow (out of memory) : 정해진 heap 메모리 영역이 초과되는 경우 발생, Heap의 용도에서 예측 할수 있듯 너무 많은 객체가 생성되거나 너무 큰 자료(file, 이미지등)등이 로딩된 경우에 발생 함.
		-Stack Over Flow : 정해진 stack 메모리 영역이 초과되는 경우 발생, Stack의 용도에서 예측 할수 있듯 너무 많은 함수 호출이 일어나는 경우에 발생 함.(무한 루프에 빠져 콜스텍이 무한 늘어나는 경우) 
				
	
-access Modifiers (access specifiers or access visibility) : public > protected > default > private
	-Top level access modifiers : classes, interfaces, enums, annotations
		-public : 어느 패키지의 클레스에서나 생성, 접근이 가능하다 (제약이 없음)
		-default : 같은 패키지의 클레스에서만 생성되고 접근이 가능하다 , 상속도 같은 패키지에서만 가능 하다.
		
	-Member level access modifiers : fields(변수), constructors, methods 
		-!!! 위 Top level access modifier가 default이면 내부의 public, protected는 의미가 없음(에러는 안남) 		
			-public : 어느 패키지의 클레스에서나 필드의 접근 및 메소드 호출이 가능하다 (제약이 없음)
			-protected : 같은 패키지의 클레스에서만 필드의 접근 및 메소드 호출이 가능하다, 다만 다른 패키지에서는 해당 클레스를 상속 받아서 direct한 방식(super.xxx) 으로는 접근 가능(default보단 느슨함)
			-default : 같은 패키지의 클레스에서만 필드의 접근 및 메소드 호출이 가능하다
			-private : 자신 클레스 내부에서만 필드의 접근 및 메소드 호출이 가능하다
		
	-결론 : 가능하면 defalt로 이하로만 작성한다.??
	
-variables (java 변수 종류) : 변수의 종류에 대한 명칭 정리
	-instance variable : 해당 class가 생성될때 생성 및 할당
	-static variable : 해당 class가 생성될때 할당, 동일 클레스가 여러개 생성되더라도 해당 변수는 오직 한개만 생성됨
	-local variable : 해당 메쏘드가 호출될때 생성, 메소드가 종료되면 사라짐 (stack 영역에 생성)
		-----------
		class A{  
			int data=50;//instance variable
			static int m=100;//static variable 
			void method(){  
			int n=90;//local variable
			}  
		}
		-----------
	
	
-static 키워드 정리 : static 키워드는 해당 클래스의 인스턴스(new)와 무관하게 해당 클레스가 로딩되는 시점에 해당 영역이 생성된다.(로딩시점이기 때문에 딱 한번이겠지..)

	-static variable : 변수를 static으로 선언 : 해당 변수는 해당 클래스가 여럿 생성되더라도 모두 하나의 메모리를 참조 하게됨(공통으로 확인되야할 변수 또는 어차피 모두 동일함 값을 갖게될 변수의 경우 메모리 절약 차원에서 활용될수 있음)
		-static 변수는 static, nonStatic 메쏘드 모두에서 값을 확인(?)할수 있지만 static 변수값의 변경은 static 메쏘드에서만 가능함
		
	-static method : static 메쏘드는 해당 인스턴스(object) 종속된다기 보단 해당 class에 종속되어 있음 그래서 해당 class를 인스턴스 생성(new)하지 않고도 사용할 수 있음(ex:ClassName.classMetho()) 
		-static 변수의 변경을 위해 사용할 수 있다 (!!! 만약 nonStaic 메쏘드에서 변경이 가능하게 했다면 인스턴스마다 static변수를 바꾸려 할때 예상치 못한 문제가 발생 했겠지??)
		
	-static block : 코드상에 static{...} 처리된 블럭을 말한다.
		-IIB와 유사함, IIB는 클래스의 인스턴스가 생성(new)시 매번(갖고있는 모든 생성자에 앞서 시행(공통역역?)) 실행되지만 static block은 해당 클래스가 로딩되는 시점에(클레스가 생성이 아님) 딱 한번 실행된다.
		-해당 클레스와 관련해서 유일하게 한번만 처리되야 하는 코드가 들어갈수 있다. 또한 static 블럭으로 되어 있어 static 변수를 초기화 하는 용도로도 사용 할수 있다.


-synchronized 키워드 정리 : 크리티컬 세션에 대해 동시에 여러 쓰레드가 엑세스 하지 못하도록 하기 위한 방법
	-synchronized 메소드 :
		-public int synchronized myAdd(){ 형태로 해당 메쏘드 전체를 synchronized 한다 
		-모든 쓰레드는 !공유된 !인스턴스의 해당 메쏘드를 경쟁적으로 사용할수 없다(선점한 쓰레드의 처리가 끝나야 다른 쓰레드에 해당 메소드 사용권한이 넘어간다)
		-특정 메소드 전체를 synchronized한 방식으로 비 효율적일수 있다(메쏘드에서 공유되도 상관없는 부분까지 모두 블락되어 쓰레드간의 대기 시간이 길어 질수 있다.)
		-synchronize param이 없는 방식이기 때문에 오직 해당 메쏘드만 단독적으로 synchronized가 이루어 진다.(메쏘드1을 특정 쓰레드가 사용하고 있을때 메쏘드2도 다른 쓰레드에서 사용하지 못하게 하고 싶을수 있다, 이방법으론 구현 불가)
		
	-synchronized 블럭 :
		-synchronized(this) { ....} 형태로 해당 메쏘드의 특정 영역만 synchronized 한다.
		-모든 쓰레드는 !공유된 !인스턴스의 특정 메쏘드의 특정 영역을 경쟁적으로 사용할수 없다(선점한 쓰레드의 처리가 끝나야 다른 쓰레드에 해당 메소드 사용권한이 넘어간다)
		-메쏘드 전체가 아니라 메쏘드의 특정 영역만 synchronized한 방식이기 때문에 더 효율적일수 있다(다만.. 그 영역을 잘 골라내야 하겠지?)
		-synchronize param이 있는 방식으로(위에서는 this를 파람으로 주고 있다.) 같은 param을 사용하는 따른 메쏘드의 synchronize 블럭과 연결되어 동작하게 할수 있다.
			-메쏘드 myAdd(){ synchronized(this) {..}} 와 메쏘드 myTotal(){ synchronized(this) {..}} 이 동일한 파람(this)을 사용하고 있기 때문에 특정 쓰레드가 한쪽 블럭을 점유하고 있다면 다른 쓰레드는 동일 파람(this)를을 사용하는 모든 블락을 사용할 수 없다.
				-synchronize param은 클래스 변수? 어느것이나 상관없음(null은 안되며 String, this 나 모두 그저 하나의 synchronized 위한 플레그 변수로 참조되는 듯 하다.. 그래서 관용적으로 this를 사용하는 듯)
				-this가 관용적 변수이기는 하나 synchronized 블락이 여러곳에 있을때 모두 this를 사용하게 되면 한곳이 선점되면 모두 대기 상태가 됨으로 적절히 변수를 분할해서 사용해야 할 것이다
			
	-!!! 공유된 인스턴스의 국한하여 메쏘드 또는 블럭을 synchronized하는 것이 아니라 해당 클래스를 사용하는 모든 인스턴스에 대해서도 synchronized를 구현 할 수 있다.
		-synchronized 메소드의 경우는 public static synchronized int myAdd(){ 형태로 해당 synchronized 메쏘드를 static으로 구성하는 방법이 있다.
		-synchronized 블럭의 경우는 myTotal(){ synchronized(MyClass.flagV) {..}} 형태로 param 클레스를 static 변수로 생성하여 할당하는 방법이 있다.
			-??? 그런데 막상 테스트 해보면 this의 경우는 공유된 인스턴스에만 씽크가 되는것 같고 일반 클래스 파람의 경우 static이 아니더라도 해당 클레스의 모든 인스턴스에서 씽크되는것 같기도 함... 애매함, 좀더 확인 필요?


-JAVA Collection (java collections framework) : JCF는 java가 제공하는 데이터를 담을수 있는 객체?(structures)와 그 활용에 사용되는 유용한 메서드?를 제공하는 class와 interface의 모음이다.
	-collections는 말그데로 데이터(오브젝트)?를 모아서 관리하는 클레스!로 프레임워크라 명명되지만 실제 활용되는 방식은 하나의 라이브러리와 같다(초기 자바는 collections를 제공하지 않았기 때문에 이 역할을 하는 외부 lib를 사용하곤 했다)
	-자바 초기에는 collections라곤 할순 없는 data structure 클레스(array, vector, hashtable)를 제공했다 
		-특히 array의 경우 해당 object 크기에 맞게 생성시 정해진 싸이즈의 메모리를 확보하여 넣어주는 역할만 했고 vector, hashtable 또한 표준 인터페이스가 없었기 때문에 확장이 쉽지 않았다
	
	-초기 자바의 data structure 클레스의 한계를 넘고자 여러 종류의 collections이 만들어졌고 여러 인터페이스와 구현체가 추가되면서 collections가 관리하는 object에 대한 유용한 표준이 생겼다(구현체포함, 확장하고 싶으면 직접 확장가능)
		-현재 collections가 갖고 있는 필수? 메소드는 java.util.Collection(public interface Collection<E> extends Iterable<E>)인터페이스를 구현해 놓았다 (add, remove, containsAll, addAll, removeAll...)
		-collection이 generic 타입을 채용함으로써 개발자는 관리대상 object가 무었이든간에(개발자가만든 object든 모든) 각 자료구조(Set, List, Queue, Deque) 특성에 맞는 메쏘드를을 이용할 수 있다.
		-java collections 는 thread-safe implementation 인것도 있고 아닌것도 있으니 잘 확인해서 사용해야 한다.
		
		-collections의 상속 계층 구조는 아래와 같으며 활용에 있어 크게 3가지 류로 구분된다. 
			-Iterable(if): hasNext, next, remove
				-Collection(if): add, addAll, remove, removeAll, removeIf, retainAll, size, clear, contains, containsAll, iterator, toArray, stream, spliterator, hashCode ...
					
					-List(if): 순서있음, 데이터중복가능, null포함 불가능, !!특정위치삽입가능, (기존 array와 비슷한 특징의 interface이다, 객체 생성시 아래 implement 클레스를 이용해서 생성해야 한다.)
						
						-ArrayList: 내부적으로 array와 같은 형태를 취함, 그런데 array는 할수 없는 동적으로(자동)으로 크기를 늘렸다 줄였다가 가능함(array는 생성때 크기를 설정해야함)
							-array는 하지 못하는 데이터(object)의 순서 지정이 가능한데 이를 위해 내부적으로 array를 임시로 카피하여 순서를 위해 옮겼다 복사하기로 처리 된다 이러한 이유로 데이터의 추가/삭제가 상대적으로 느리다
							-하지만 항상 정렬된 array를 유지함으로 검색의 경우는 상대적으로 빠르다.(map처럼 키가 없어서 검색이라는 느낌이 없지만 contains같은 것도 검색에 기반을 두기 때문이다, 검색이 중요하다면 ArrayList를 사용하도록 한다)
						-LinkedList: 기능적인 면에서 ArrayList와 거의 동일하다 다만 순서를 만들어내기 위한 방식이 데이터 임시 카피 복사가 아니라 각데이터가 자신의 뒤 정보의 주소를 갖고 있는 방식이다.
							-이러한 내부 방식으로 인해 ArrayList와 반대로 추가/삭제가 빠르지만 검색 속도는 상대적으로 느리다.(추가/삭제가 많다면 linkedList를 사용)
						-Vector: java 초기 버전에서 ArrayList의 역할을 했던 클레스로 내부 동작이 ArrayList와 거의 같다. 
							-다만 크기를 자동으로 늘릴때 현재 크기의 2배씩 늘리는 방식을 취하며 synchronized를 취하기 때문에 장점도 있지만 synchronized 가 필요없는 케이스의 경우는 상대적으로 속도에서 손해를봄 (요즘은 잘 안쓰고 ArrayList를 씀)
						-Stack: Vector의 서브 클레스로 vector의 모두 기능을 갖고 있으면서도 stack의 특징인(last-in-first-out)을 위한 push, peek, pop 등의 특색있는 기능을 제공한다. (stack 이지만 중간에 삽입도 가능)
						
					-Queue(if): 순서있음, 데이터중복가능, null포함 불가능, !!특정위치삽입 불가능 (queue의 특징인 first-in-first-out을 위한 기능을 제공)
						
						-PriorityQueue: queue 인터페이스를 구현한 클레스로 que 기능을 사용할 수 있게 해준다.
						-Deque(if): queue 인터페이스와 유사하나 양쪽 끝단을 통해서 remove, add를 할수 있는 장점이 있다.
							-ArrayDeque: deque 인터페이스를 구현한 클레스이다.
						
					-Set(if): 순서있음, 데이터중복 불가능, null포함가능, !!특정위치삽입 불가능  
						
						-HashSet:	set의 구현체로 HashMap 처럼 hash 테이블을 이용하기 때문에 검색에 장점이 있다(map처럼 키가 없어서 검색이라는 느낌이 없지만 contains같은 것도 검색에 기반을 두기 때문이다)
						-LinkedHashSet: set의 구현체로 LinkedList 처럼 구현되어 추가/삭제에 장점이 있다
						-SortedSet(if):
							-TreeSet: set의 구현체로 TreeMap 처럼 구현되어 값이 정렬된 현태로 저장된다, 그런점에서 검색에 장점을 가지며 TreeMap과 같은 방식으로 subSet의 활용이 가능하다.
			
	-Map : key/value 조합으로 데이터를 저장하고 찾기위한 자료구조이다. Map은 이러한 구현체(HashMap, LinkedHashMap, TreeMap)를 위한 공통을 정의한 인터페이스로 JCF의 일부로 보기도 하고 collect이 아니라고도 하는듯..??
		-종류 : 
			-HashMap : 키값의 hash 값(보통숫자로구성됨)을 해시테이블로 관리하여 검색 속도를 향상 시켜 놓은 Map이다 해시값을 기준으로 검색하기 때문에 동일 키값의 데이터가 중복으로 들어갈수 없다(간혹 동일키값 또는 null을 허용하는 Map도 있는듯)
				-Map의 데이터는 실제 put한 순서와 상관없이 적체된다.(해시값순), 전체 print시 입력순서와 상의함, 또 검색을 위한 해시테이블이 추가되기 때문에 방대한 데이터 또는 무한정 늘어날수 있는 데이터를 관리하면 메모리적 측면에서 손해를 보내된다.
				
			-LinkedHashMap : 기본적으로 HashMap과 유사하나 put한 순서로 데이터를 가져올 수 있다, 전체 print시 put한 순서대로 출력됨
			
			-TreeMap : 내부적으로 이진 트리구조로 데이터가 저장된다. 다시말해 key값의 순서로 저장된다. 보통 키값의 숫자, 알파벳순으로 정렬되어 저장되며 compare()를 구현하여 정렬순서 로직을 직접 구현할 수 있다.
				-별도의 hash 테이블이 존재하지 않기 대량의 데이터를 다룰때 메모리 측면에서 유리하다, 그러나 hash 값으로 검색하지 않기 때문에 hashMap에 비해 검색 속도가 느리다.
				-TreeMap의 가장 큰 장점은 이미 특정 조건으로 정렬되어 저장되 있음으로 key값 XXX 부터 YYYY 사이의 값을 모두 가져올수 있는 subMap의 활용이 가능하다.
					-treeMap.subMap("XXX", true,"YYY",true) : 키값 XXX 부터 YYY 사이의 데이터를 서브맵으로 구성 할수 있다.
			
		-Entry class : Entry클레스를 통해서 반복문을 처리할 수 있다.
			-------
			for (Map.Entry mapElement : tm.entrySet()) {
				int key = mapElement.getKey();
				String value = (String)mapElement.getValue();
			}
			------
		
		
		

-class Loader : -->여기

-Java Regex([레게스, 레귤러익스프레션]): 자바 정규식, string 의 특정 문자(문자열)을 검색하거나 조정하기 위한 API 이다.
	-특정 문자열에 있어 특정 문자 패턴을 확인하거나 input 값에 대한 vaildation을 처리하기 위한 용도로 활용 할수 있다.
	-관련 클레스: 외우기 어려울듯.. 필요할때 확인 필요
		-Matcher:
		-Pattern:
		-Regex Character classes(Metacharacters): [abc], [^abc], [a-zA-Z], [a-d[m-p]] ....

			

-field vs variable
	-field : class 내부에 선언된 멤버, 혹자는 private로 선언된 member로 한정 하기도 하지만 딱히 올아 보이지 않음, property와 attribute를 모두 아우르는 단어?
	-variable : 좀더 프로그램적 관점에서 설명한 field의 의미? 다시말해 member를 할당한 변수


-property vs attribute
	-사람들이 혼용하여 동일어로 생각하는 경우가 많음, 그 차이가 다소 애매하고 어느 문맥에서 말하는지에 따라 조금씩 다르다(xml, html, react등 어느 관점에서 말하는지에 따라 구체적인 내용이 조금씩 다름)
	
	-보편적 의미 : 절대적이라 볼순 없음, 둘다 해당 글레스의 멤버(field)이다.
		-property : 
			-보통 생성자를 통해 생성시 셋팅되는 필드, 다시말해 해당 클레스의 태생적 특징을 갖는 멤버?, 변경할수도 있겠지만 주로 잘 변경되지 않은 필드? 
			-생성자를 통해 property가 셋팅되면서 동일한 이름의 attribute의 값을 같이 셋팅해 주는 경우가 있음, 이러한 이유로 사람들의 혼선이 생기는 듯함.
		
		-attribute : 
			-생성자를 통해 특정 property 와 동일한 이름으로 셋팅되는 경우도 있으나 주로 필요에 의해 setter, getter에 의해 변경되는 필드?
			

-Generic : 데이터의 타입(data type)을 일반화하여 선언 하는것으로 컴파일 단계에서는 아직은 알수 없는 클래스 타입을 임의로 잡아놓고 처리하는것, 프레임워크 기술에서 많이 사용됨
	-전에는 모든 클래스를 대표하는 object 클래스를 사용하였으나, 실제 사용에서 다시 타입 케스팅을 하는등 오류가 여지가 많았음. (J2SE 5 부터 generic 지원)
	-예전처럼 object로 대처하는 방식에서는 실제 클레스를 넣는 사람과 사용하는 쪽에서 알아서 잘 넗고 알아서 잘 타입케스팅을 해서 사용했다. 그러다 보니 개발중 또는 컴파일 시에는 오류가 나지 않던것이 런타임시 발생하는 문제들이 있었음
		---	
			List list = new ArrayList();
			list.add(10); list.add("10");  //서로 다른(int, string) 타입을 넣어도 컴파일시 에러가 나지 않았음			  
		---
			List<Integer> list = new ArrayList<Integer뒷쪽은생략가능!!>();
			list.add(10); list.add("10");  //서로 다른(int, string) 다른 타입을 넣으면 컴파일시 에러가 발생함(런타임 확율을 줄여준다)
		---
			List list = new ArrayList();    
			list.add("hello");    
			String s = (String) list.get(0); //사용하는 측면에서 항상 알맞은 타입케스팅이 필요함(넣는 쪽과 사용하는 쪽이 다르다면 이를 확실히 하기가 어려울 수 있음)			
		---
			List<String> list = new ArrayList();    
			list.add("hello");    
			String s = list.get(0); //사용시 타입 케스팅 불필요함

	-사용가능 방식(위치)
		-제네릭 클레스를 생성하는 과정:
			-List<String> list = new ArrayList<String>();  
			-Map<Integer,String> map=new HashMap<Integer,String>();  
			-List<? super MyClass> list = new ArrayList(); //이 경우 super 클레스가 명확하지 않음으로 사용시 타입케스팅이 필요함(MyClass mc = (MyClass)list.get(0); 또는 MyClassSub 형태의 상속받은 클레스로 케스팅)
			-List<? extends MyClass> list = new ArrayList(); //??? 될것 같은데.. extend 키워드 사용은 에러는 안나지만 사용시 add할때 에러가남. 확인필요!!
			
		-클레스를 정의하는 과정: 해당 T라는 키워드를 해당 클레스 내에서 클레스의 타입으로 활요할 수 있다. 클레스명 옆에 작성, 이러한 형태의 경우 set/get 또는 기본적인 object 메소드를 사용하여 메소드를 만드는거외 특별히 할수있는게 없는듯??
			-class MyGen<T>{...} 
			
		-클레스의 메서드를 정의하는 과정: 해당 E라는 키워드를 해당 메스드 내에서 클레스의 타입으로 활용할 수 있다. (리턴정의 앞쪽에 위치하며 static, non static 메서드 모드에서 사용 가능)
			-public static <E> void myMethod(E[] elements) {...}
			-public static <E extends MyClass> void myMethod(E[] elements) {} 
				-파람 E[]는 내부에서 for문을 통해 처리가능 (ex: for ( T element : elements){...})
				-특정 클레스를 상속받은 형태만 받을수 있도록 처리함으로써 프레임워크를 개발하는등에 가장 많이 사용 될수 있을것 같음, 특정화된 클레스는 아니지만 MyClass를 상속받은건 확실함으로 타입케스팅 없이 MyClass의 메소드를 내부적으로 사용 가능
				
			-public static <E super MyClass> void myMethod(E[] elements) {...} //??? 될것 같은데.. extend 키워드 사용은 에러는 안나지만 사용시 add할때 에러가남. 확인필요!!
			
		-메서드의 아규먼트를 정의하는 과정:
			-private static void myMethod(ArrayList<Integer> al) {...}
			-private static void myMethod(ArrayList<? extends MyClass> al) {...}
			-private static void myMethod(ArrayList<? super MyClass> al) {...}
			-private static void myMethod(ArrayList<?> al) {...}
			
	-제네릭 파라미터 컨벤션 : 특별한 의미는 없다, 말그데로 켄벤션이며 해당 타입이 어떤 항목인지를 사용자가 감?이 오게 도와줄 뿐이다.
		-T - Type
		-E - Element
		-K - Key
		-N - Number
		-V - Value
		

-Anotaions : java 어노테이션은 클레스, 인터페이스, 메쏘드, 필드등에 붙여 사용할수 있는 Tag 로써 붙어 있는 해당 항목에 대한 부가적인 정보를 compiler 또는 JVM에 제공한다.(물론 이 정보를 개발자가 사용가능)
	-어노테이션은 사실 특별한게 아니라 특정인터페이스, 클레스, 필드 등에 어떤 어노테이션이 달려(달려있는지와 설정값또한) 있는지를 컴파일러, JVM(개발자 활용가능)에 알려주고 그에따른 정해진 처리를 할수 있게 도와주는 용도 이다.
	-어노테이션은 일반 개발자는 직접 개발할 경우가 거의 없고 보통 프레임워크 환경에서 implementation provider가 만들어논 어노테이션을 활용?하는 정도로 사용되고 있다.
	
	-Built-In Java Annotations : 자바 자체가 가지고 있는 내장 어노테이션으로 기본? 어노테이션이 정도로 볼수 있다 (기본이란 말은 사용자가 어노테이션을 직접 만들어 낼수도 있다는 의미)
		-개발자가 코드내에서 사용하는 어노테이션 :
			-@Override : 메소드에 테그하여 해당 메소드는 상속받아 override 하는 것임을 나타낸다. (개발자가 참고적의미로 도움이 될수도 있고 컴파일러도 참고하여 super 클레스에 해당 메소드가 없다면 오류를 내주는 등의 역할을 할수 있게 해준다)
			-@SuppressWarnings : 해당 메소드에 Warning이 있더라도 컴파일시 무시하도록 해준다. (운영 편의적 느낌?)
			-@Deprecated : 해당 메소드가 또는 필드가 없어 질수 있음으로 사용하지 않도록 개발 또는 컴파일시 어닝을 제공한다.(당장의 사용은 가능하다)			
			-@SafeVarargs : 제너릭 같은 가변인자 매개변수를 사용할 때 경고를 무시합니다. (자바7 이상), 좀더확인 필요!
			-@FunctionalInterface : 람다 함수등을 위한 인터페이스를 지정합니다. 메소드가 없거나 두개 이상 되면 컴파일 오류가 납니다. 좀더확인 필요!
			
		-Meta Annotation : 어노테이션을 만들때 만들어질 어노테이션의 특성?을 정의 하기 위한 어노테이션 이다.
			-@Target : 해당 어노테이션을 어느 어느 항목에 태깅할수 있는지를 정의한다. (ElementTypes = TYPE, FIELD, METHOD, CONSTRUCTOR, LOCAL_VARIABLE, ANNOTATION_TYPE, PARAMETER)
				-한개일경우 : @Target(ElementType.TYPE)  -> 인터페이스나 클레스에만 붙일수 있는 어노테이션
				-다수일경우 : @Target({ElementType.TYPE, ElementType.FIELD, ElementType.METHOD}) ->인터페이스나 클레스, 변수(필수), 메소드에도 붙일수 있는 어노테이션
				
			-@Retention : 어노테이션의 기능?이 언제까지 유효한지에 대한 정의 이다. (RetentionPolicy = SOURCE(개발과정에만적용), CLASS(컴파일러까지적용), RUNTIME(JVM,실행환경에도적용))			
				-@Retention(RetentionPolicy.RUNTIME)  ->해당 어노테이션은 JVM까지 적용되어 실행환경에서도 역할을 한다.
			
			-@Inherited : 기본적으로 어노테이션은 상속되지 않지만 해당 어노테이션을 태깅하여 만들어지 어노테이션은 해당어노테이션이 붙은 클레스를 상속받아 반들어진 클레스에게 까지 영향을 준다.				
			-@Documented : 해당 어노테이션을 태깅하여 만든 어노테이션을 사용하는 클레스를 사용할때 java Doc(설명)에 관련 내용이 나타난다고 하는데.. 잘 사용하지 않는듯 하고.. 이부분은 java 도큐먼트부분과 함께 다시 봐야할듯?
			-@Repeatable : 반복적으로 어노테이션을 선언할 수 있게 한다. 좀더확인 필요!
			
	-Custom Annotations : 개발자는 직접 어노테이션을 만들어 사용할 수 있다.(실제 그럴일은 별로 없지만..)
		-어노테이션 타입 :
			-Marker Annotation : 단순히 해당 항목(인터페이스, 클레스, 필드)에 어노테이션이 붙어 있는지 없는지만 확인하는 용도
				-생성 : 
					---
					@Retention(RetentionPolicy.RUNTIME)  ->런타임시까지 적용됨
					@Target({ElementType.TYPE, ElementType.FIELD, ElementType.METHOD}) ->인터페이스, 클레스, 필드, 메소드에 해당 어노테이션 적용이 가능하게 됨
					public @interface MyAnnotation{}  
				-활용 :
					---
					@MyAnnotation  ->클레스에 어노테이션 적용
					public class Myclass {
						@MyAnnotation ->메소드에 어노테이션 적용
							public void myMethod {
									...
							}					
					}
							
			-Single-Value Annotation : 어노테이션 여부와 하나의 설정값을 갖을수 있는 어노테이션
				-생성 :
					---
					@Retention(RetentionPolicy.RUNTIME) ->런타임시까지 적용됨
					@Target(ElementType.FIELD) ->필드에 해당 어노테이션 적용이 가능하게 됨					
					public @interface MyAnnotation {
							String value() default "This is StringInjector."; ->value라는 String 타입의 설정값을 하나 갖을수 있고 디폴트값이 지정됨
					}
				-활용 :
					---
					public class Myclass {
						@MyAnnotation("My name is X") ->name 필드에 어노테이션이 지정되었고 
						private String name;
						...
					}
			
			-Multi-Value Annotation : 어노테이션 여부와 다수의 설정값을 갖을수 있는 어노테이션
				-생성 :
					---
					@Retention(RetentionPolicy.RUNTIME) ->런타임시까지 적용됨
					@Target(ElementType.FIELD) ->필드에 해당 어노테이션 적용이 가능하게 됨					
					public @interface MyAnnotation {
							String value1() default "This is StringInjector."; ->value라는 String 타입의 설정값을 하나 갖을수 있고 디폴트값이 지정됨, String, enum 및 기본타입으로 만들수 있으면 기본타입의 []배열 형태도 가능
							int value2() default 0;
					}
				-활용 :
					---
					public class Myclass {
						@MyAnnotation(value1="My name is X", value2=10) ->name 필드에 어노테이션이 지정되었고 두개의 설정값을 셋팅해 줬다.
						private String name;
						...
					}
					
	-어노테이션 활용 
		-간단 버전 :
			---
			class Hello{  
			@MyAnnotation(value=10)  ->메소드에 어노테이션 적용 및 10 설정(어노테이션은 만들었다 치고..)
			public void sayHello(){System.out.println("hello annotation");}  
			}  
  
			---
			class TestCustomAnnotation1{  
			public static void main(String args[])throws Exception{  
				
			Hello h=new Hello();  
			Method m=h.getClass().getMethod("sayHello");  				
			MyAnnotation manno=m.getAnnotation(MyAnnotation.class); ->특정 클레스의 메소드에 해당 어노테이션이 적용되어있는지 확인(설정값도포함)
			
			System.out.println("value is: "+manno.value());  
			}}  		

		-어드벤스 버전:
			---
			@Target(ElementType.FIELD)
			@Retention(RetentionPolicy.RUNTIME)
			public @interface StringInjector { ->String 멤버를 갖는 어노테이션 생성
					String value() default "This is StringInjector.";
			}
			
			---
			public class MyObject {
				@StringInjector("My name is JDM.") ->어노테이션적용, 값설정
				private String name;

				@StringInjector ->어노테이션 적용
				private String defaultValue;

				@StringInjector ->어노테이션 적용
				private Integer invalidType;

				public String getName() {return name;}
				public String getDefaultValue() {return defaultValue;}
				public Integer getInvalidType() {return invalidType;}
			}		
			
			--- : Spring의 DI(dependency injection) 처럼 특정 객체의 초기값을 설정하여 대리 생성해 주는 모듈
			public class MyContextContainer {
					public MyContextContainer(){}
					private <T> T invokeAnnonations(T instance) throws IllegalAccessException {
							Field [] fields = instance.getClass().getDeclaredFields();
							for( Field field : fields ){
									StringInjector annotation = field.getAnnotation(StringInjector.class);
									if( annotation != null && field.getType() == String.class ){ 
											field.setAccessible(true);
											field.set(instance, annotation.value());
									}
							}
							return instance;
					}

					public <T> T get(Class clazz) throws IllegalAccessException, InstantiationException {
							T instance = (T) clazz.newInstance();
							instance = invokeAnnonations(instance);
							return instance;
					}
			}
			
			--- : 실행
			public class AnnotationDemo {
					public static void main(String[] args) throws IllegalAccessException, InstantiationException {
							MyContextContainer demo = new MyContextContainer();
							MyObject obj = demo.get(MyObject.class);

							System.out.println(obj.getName()); // print is "My name is JDM."
							System.out.println(obj.getDefaultValue()); // print is "This is StringInjector."
							System.out.println(obj.getInvalidType()); // print is "null".
					}
			}
		

-Reflection : java.lang.reflect.*패키지를 이용하여 주어진 특정 객체(클래스)의 메타 정보를 런타임시 확인, 사용할 수 있는 기술, https://www.geeksforgeeks.org/reflection-in-java/
	-해당 객체가 어떤 메소드, 어떤 필드를 갖고 있는지 알수 있다.
	-스트링을 값을 통해 해당 이름의 메소드 및 필드에 호출(접근)할 수 있다. 다시말해 메소드 및 필드 접근을 컴파일 이후 실시간으로 처리할 수 있다(획기적인데?!!)
	-주로 프레임워크 기술 또는 개발툴, 디버깅툴 개발 기술에 활용 된다.


-Callback & listener & handler : 본질적으로 유사하다, 개발자 측면에서 다른점은 callback은 상황이 될때 이걸 호출해줘(처리할코드를포함), listener은 특정 상황이 될때 이걸 호출할께 여길 구현해놔, handler는 이것좀 처리해줘(메시지를 보낸다) 요청하면 처리른 main(?) 프로세스에서
	-callback : callback interface를 구현한 클레스를 main(?) 프로세스에 넘겨주는 형태로 구현하며 main은 특점 시점에 넘겨받은 callback 클레스의 특정 메소드를 호출한다.
	-listener : mina framework의 OnConnected, OnDisconnected 또는 android view에서 OnClick 등과 같이 framework로 부터 전달되는 이벤트에 대해 처리하는 방식이다.
	-handler : Android에서 UI 처리를 위해서 main 쓰레드로 메시지를 보내는 것이 예가 될수 있다 (받은 메세지는 메시지큐에 쌓이고 looper가 돌며 해당 메시지를 핸들러의 처리하는 곳으로 넘긴다)


-Exception : 
	-throw : 임의로 특정 Exception을 발생 시키는 방식, throw를 통해 임의로 Exception을 발생했을 경우 해당 catch문을 구성하거나 throws 통해 호출자에서 처리하도록 구성해야 한다.
	-throws : 해당 메소드에서 발생한 Exception을 자신을 사용하는 상위 스택에서 처리하도록 하는 방식, 특정 Exception을 넘길수도 있고 특정화 할수 없는 경우 최상위 Exception을 그대로 throws 하면 된다.
		-!!! throws 를 하지 않더라도 해당 메소드에서 처리하지 못한 Exception이 발생하면 호출자로 넘어간다. 
		-!!! 그럼에도 throws를 하는 의미는 throws 하게 되면 throw 또는 특정 try를 강제로 해줘야 하는 코드에 대해 해당 메소드 내에서 처리를 하지 않더라도 컴파일시 에러를 내지 않도록 처리해 준다. 
		-!!! 또한 throws한 메소드를 사용한 호출자에게 해당 Exception에 대한 처리를 하지않으면 컴파일 에러가 나도록 강제해 주는 처리를 해준다.
		
	----------
	public class MyThrow {
		public String myMethod1() throws Exception {
		
			//todo(ex: 10/0) --> 예상치 못한 위치에서 catch하지 못한 exception 발생시 해당 Exception은 호출한 메소드로 넘어간다(!!throws가 있든 없든). 넘어가면서 해당 코드는 더이상 진행되지 않고 거기서 중단되고 스텍을 빠져 나온다.
			
			try{
				throw new MyException(); --> throw를 하기 위해서는 해당 exception에 대한 catch를 반드시 해줘야 함, 또는 throws 통해 자신을 호출한 메소드로 처리를 요청해야 함				
				//-->throw 하단 코드는 모드 death 코드가 된다.
				
			}catch(MyException myE){
				//todo --> 발생된 exception 이 catch를 통해 적절히 처리되면 해당 catch 블럭밖의 코드까지 실행됨(ex: 아래 return..)
				
			}
			
			return "result"; --> catch 되지 않은 exception 발생시 도달하지 못한다. (exception 발생 위치에서 스텍을 빠져 나온다)
		}
	----------
		
	
	



[build automation tool]
-maven : Apache, Apache License 2.0
	-의존성 관리(개발자마다 다를수 있는 lib 버전등을 명시적으로 관리), 패키징 처리(war, jar..), 버전과 릴리즈 관리, 원격 저장소 배포 지원
	-maven 설치
		-https://maven.apache.org/download.cgi 에서 다운로드
		-Windows : 제어판 > 시스템 등록 정보 > 고급 > 시스템 환경 변수 추가 Path 항목에 java/bin와 maven/bin 위치 추가
		-Mac & Linux : bash 정보 파일에서 Path java/bin와 maven/bn 위치 추가 (mvn --version 으로 테스트)

	-main goals
		-validate : ??
		-clean : target 폴더를 비워준다
		-compile : target/classes 에 컴파일
		-test : ??
		-package : pom에 명시된 패키징 수행(jar, war..)
		-install : local repo(사용자/.m2)에 install 수행
		-deploy : remote repo에 배포

	-maven project Dir 구조 : https://maven.apache.org/guides/introduction/introduction-to-the-standard-directory-layout.html
		-src/main/java(언어)/package : 실제 소스
		-src/test/java(언어)/package : maven 빌드시 테스트를 위한 클래스가 위치한다. src/main/java/package와 동일한 패키지 처럼 동작하나 빌드 package(jar..)에 포함되지 않는다.

	-pom 파일 : code 관련 dependency(lib) 및 build 나 deploy 관련 plugin을 정의한다. (직접 치지 말고 STS의 Add Dependency 또는 Add Plugin 활용할 것)

	-repository
		-local repository : central에서 down 받아 local에 저장된 repo, install시 빌드된 package가 저장되기도 한다. (사용자/.m2 에 위치)
		-central repository : local repo에 없는 의존성을 다운받기 위한 repo, 기본 위치는 https://repo.maven.apache.org/maven2/
		-plugin repository : maven plugin을 다운받을 수 있는 repo (컴파일 기능등을 위한 3rd p`arty? 정확히 몰겠음??)

	-versioning
		-x.x-SNAPTION : 개발진행 중임을 나타낸다.
		-x.x.x : release 버전
		-관용표현 : x.x-RC(release candidate), -M(milestone release), -RELEASE(release 버전)

	-maven Command :
		-mvn dependency:tree
		-mvn clean
		-mvn compile
		-mvn test
		-mvn package
		-mvn deploy
		-mvn install

	-maven build elements
		-----------
		<build>
			<!-- package 파일명 -->
			<finalName>Maven-Webapp</finalName>

			<!-- resource 폴더를 인식하게 해줌 -->
			<resources>
				<resource>
					<directory>src/main/resources</directory><filtering>true</filtering>
				</resource>
			</resources>

			<!-- mvn exec:java로 실행 가능하도록 해줌 -->
			<plugins>
				<plugin>
					<groupId>org.codehaus.mojo</groupId>
					<artifactId>exec-maven-plugin</artifactId>
					<configuration>
						<mainClass>com.sungil.H2_JPA.App</mainClass>
					</configuration>
				</plugin>

				<!-- target 폴더에 libs 폴더를 만들어 maven-dependency 라이브러리를 카피해줌 -->
				<plugin>
					<groupId>org.apache.maven.plugins</groupId>
					<artifactId>maven-dependency-plugin</artifactId>
					<executions>
						<execution>
							<id>copy-dependencies</id>
							<phase>prepare-package</phase>
							<goals>
								<goal>copy-dependencies</goal>
							</goals>
							<configuration>
								<outputDirectory>
									${project.build.directory}/libs
								</outputDirectory>
							</configuration>
						</execution>
					</executions>
				</plugin>

				<!-- 메인 클레스를 알고있는 jar를 만들고(실행 가능 jar 생성) 해당 jar 실행시 참고할 libs 폴더를 알수 있게 해줌 (libs가 실제 jar에 포함되는 것은 아님) -->
				<plugin>
					<groupId>org.apache.maven.plugins</groupId>
					<artifactId>maven-jar-plugin</artifactId>
					<configuration>
						<archive>
							<manifest>
								<addClasspath>true</addClasspath>
								<classpathPrefix>libs/</classpathPrefix>
								<mainClass>
									com.sungil.H2_JPA.App
								</mainClass>
							</manifest>
						</archive>
					</configuration>
				</plugin>

				<!-- 모든 libs 및 기타 doc 파일을 실제 jar에 포함되도록 함 -->
				<plugin>
					<groupId>org.apache.maven.plugins</groupId>
					<artifactId>maven-assembly-plugin</artifactId>
					<executions>
						<execution>
							<phase>package</phase>
							<goals>
								<goal>single</goal>
							</goals>
							<configuration>
								<archive>
									<manifest>
										<mainClass>
											com.sungil.H2_JPA.App
										</mainClass>
									</manifest>
								</archive>
								<descriptorRefs>
									<descriptorRef>jar-with-dependencies</descriptorRef>
								</descriptorRefs>
							</configuration>
						</execution>
					</executions>
				</plugin>

				<!-- mvn jetty:run 로 실행할 수 있게 해줌 -->
				<!-- http://www.eclipse.org/jetty/documentation/current/jetty-maven-plugin.html -->
				<plugin>
					<groupId>org.eclipse.jetty</groupId>
					<artifactId>jetty-maven-plugin</artifactId>
				</plugin>

				<!-- Default is too old, update to latest to run the latest Spring 5 + jUnit 5 -->
				<plugin>
					<groupId>org.apache.maven.plugins</groupId>
					<artifactId>maven-surefire-plugin</artifactId>
				</plugin>

				<plugin>
					<groupId>org.apache.maven.plugins</groupId>
					<artifactId>maven-war-plugin</artifactId>
				</plugin>
			</plugins>
		</build>
		-----------


-gradle : build automation system. 빌드 스크립트(Groovy, Kotlin 언어)에 논리적 개념(프로그램 처럼)을 적용, java뿐 아니라 여러 언어 프로젝트 지원
	-DSL : Domain Specific Language (Groovy 기반)
		-Internal(비공개) :
		-Incubating(실험) :
		-Public(공개) :
		-Deprecated(패지) :

	-장점 :
		-xml을 사용하지 않아 장황하지 않고 간결하다.
		-Groovy 언어를 기반으로 하기때문에 변수, if, else, for 등의 로직을 포함할 수 있다.
		-공식 사이트에 문서화가 잘되어 있다. (변화 속도가 빠르므로 가능한 공식 사이트를 이용하자)
		-빌드 속도를 개선하기 위한 여러 준비가 있다
			-증분 빌드 :
			-작업 결과 캐싱 :
			-증분 하위 작업 :
			-데몬 프로세스 재사용 :
			-병렬 실행 :
			-병렬 다운로드 :

		-멀티 프로젝트 지원 : 하나의 Repository에 여러 프로젝트를 구성할 수 있다.
		-유연성, 확정성 :
			-Groovy 기반 스크립팅을 통해서 다양한 기능을 스크립트안에 직접 구현할 수 있다. (system 정보를 읽어 빌드시 이용등..)
			-직접 Task를 구현하고 플러그인을 만들어 기능을 추가할 수도 있다.
			-Plugin 허브를 지원하며 유용한 plugin을 이용할 수 있다.
				-checkstyle, pmd, findBugs, Sonar, Lint : 소스코드 정적 분석 툴을 적용하면 빌드시, 룰에 어긋나는 코드를 경고한다(리포트도 만들어줌)
				-jacoco, cobertura, clover, sonarqube : 테스트 커버리지 툴을 적용하면 빌드시, 테스크 커버리지에 대한 리포트가 만들어지고, 경고를 띄우는 등의 설정도 가능하다.

	-설치 :
		-Groovy 설치시 Library가 포함되어 있어 별도 설치 필요 없음
		-https://gradle.org/releases/ : 공식 사이트를 통해 다운로드 (5.6.2 binary-only)
			-unZip binary : C:\Program Files\Gradle (적당한 위치)에 다운받은 압축을 풀고 저장
			-환경변수 설정 :
				-GRADLE_HOME : C:\Program Files\Gradle\gradle-5.6.2
				-path 설정 : C:\Program Files\Gradle\gradle-5.6.2\bin

	-기본구조
		- gradle/wrapper/gradle-wrapper.jar : 생성된 프로젝트를 이후 어느 시스템에서도(java나 gradle이 설치되지 않은) 빌드할수 있도록 빌드가 가능한 환경 자체를 포함함
			-gradle build : system에 설치된 gradle 환경을 이용하여 빌드
			-./gradle build : gradle-wrapper.jar을 이용하여 빌드

		-gradle/wrapper/gradle-wrapper.properties : gradle-wrapper에 대한 설정 파일
		-gradlew.bat : 윈도우용 실행 스크립트 (gradlew build = gradle-wrapper.jar을 이용하여 프로젝트 빌드)
		-gradlew : 리눅스용 실행 스크립트 (gradle.bat 과 동일 기능)
		-build.gradle : 의존성이나 플러그인 설정 등을 위한 스크립트 파일 (pom.xml과 유사), 하위 프로젝트가 있는경우 프로젝트 별로 각각의 build.gradle을 갖는다.
		-settings.gradle : 프로젝트의 구성 정보(어떤 하위프로젝트들이 어떤 관계로 구성되어 있는지) 파일이다. Gradle은 이 파일을 토대로 프로젝트를 구성한다.

	-settings.gradle 구성 요소 :
		-----------
		rootProject.name = 'algorithm' //최상위 프로젝트
		include 'java' //하위 프로젝트
		include 'java::kotlin' //하위의 하위 프로젝트
		-----------

	-build.gradle 구성 요소 :
		-----------
		plugins { // 빌드(컴파일??)를 위한 plugin
			id 'org.springframework.boot' version '2.1.8.RELEASE'
			id 'io.spring.dependency-management' version '1.0.8.RELEASE'
			id 'java'
		}

		group = 'com.sungil' // 패키지의 그룹?
		version = '0.0.1-SNAPSHOT' // 패키지 버전
		sourceCompatibility = '1.8' //java 호환 버전

		configurations {
			compileOnly {
				extendsFrom annotationProcessor
			}
		}

		repositories {
			mavenCentral()
		}

		dependencies { // 컴파일을 위한 dependencies
			implementation 'org.springframework.boot:spring-boot-starter-data-jpa'
			implementation 'org.springframework.boot:spring-boot-starter-jdbc'
			implementation 'org.springframework.boot:spring-boot-starter-web'
			compileOnly 'org.projectlombok:lombok'
			annotationProcessor 'org.projectlombok:lombok'
			testImplementation 'org.springframework.boot:spring-boot-starter-test'
		}
		-----------

	-버그 및 tip :
		-gradle dependency 업데이트 후 sts gradle dependencies에 반영이 안되는 경우 : project->sts gradle-> refresh all 해본다.


-jenkins server : continuous integration and continuous delivery (CI/CD) server(pipeline) written in Java, Stable release	2.176.1, MIT License
	-jenkins 설치 : java 설치 필수
		-$wget -q -O - https://pkg.jenkins.io/debian/jenkins.io.key | sudo apt-key add - : apt로 설치하기 위해 jenkins repo를 접속하기 위한 key 값을 받아 온다
		-$sh -c 'echo deb http://pkg.jenkins.io/debian-stable binary/ > /etc/apt/sources.list.d/jenkins.list' : apt list에 jenkins repo 추가
		-$sudo apt updatesudo : apt 업데이트
		-$apt install jenkins : jenkins install (설시시 자동 서비스 등록 및 실행)
		-$systemctl status jenkins : 서비스 상태 확인
		-$sudo ufw allow 8080 : 방화벽 오픈 (sudo ufw status 확인, port 변경(vi /etc/default/jenkins 에서 HTTP_PORT=XXXX 변경 후 restart)

	-user 생성 및 환경 설정 : (https://linuxize.com/post/how-to-install-jenkins-on-ubuntu-18-04/)

	-주요 메뉴
		-첫화면 : jenkins의 모든 빌드 상태를 보여줌
		-새로운 Item : 새 빌드 추가 (하나의 빌드 환경을 하나의 Item으로 보는 듯), Freestyle, Maven, Pipeline, Git등 여러 템플릿 선택 가능
		-사람 : Users 정보 (새 유저 등록 방법은 ??)
		-빌드 기록 : 모든 빌드 기록
		-프로젝트 연관 관련 : ??
		-파일 핑거프린트 확인 : 어떤 빌드 패키지(jar, war..)의 빌드 번호가 몇 인지 확인할 수 있다.
		-Jenkins 관리 : 연동 환경에 대한 설정(설치된 plugin에 따라 다양한 설정이 필요)
			-System Admin 정보 : email
			-Maven 관련 : Local Maven Repository 위치,
			-Git 정보 : ??
			-Pipeline :
		-My Views : 로그인 사용자 Item 빌드 상태를 보여주는 View
		-Lockable Resource : ??
		-Credentials : ??
		-New View : jenkins의 모든 Item의 빌드 상태를 보여주는 view를 추가해줌(filter 및 기타 컬럼 지정 하여 customize 함)

		-Build 시나리오
			-jenkins + maven + svn : jenkins 서버의 maven local repo로 빌드
				-sts에 코드 작성 및 svn commit : main/java 와 test/java, Resouces파일(해당시), pom.xml 들을 commit
				-jenkins Item(maven) 생성 : 소스코드관리>Repository URL(끌고올 프로젝트의 svn주소), Credentials(svn 계정, jenkins에서 생성하여 연동)
				-Build Now : 빌드 처리
				-Console Output : 빌드 결과 확인
					-빌드결과, 테스트결과 확인
					-jenkins의 workspace 확인 가능 (svn에서 소스를 가져다논 위치), /var/lib/jenkins/workspace/projectName/
					-jenkins가 빌드한 package를 저장한 maven local repo 확인 가능, /var/lib/jenkins/.m2/repository/groupName/projectName/


[server/os]
-ubuntu : 18.xx LTS(long-term support)
	-Commands : 활용 높은 Commands
		-특정 프로그램(install)의 관련 파일 위치 확인 : dpkg --listfiles firefox
		-TCP 네트워크 사용 상태 확인(port) : sudo lsof -i -n -P | grep TCP | more
		-비밀번호 변경 : passwd





[VM/Hypervisor, Container]
-VirtualBox : oracle
	-take(snapshot) : 메모리 상태등을 포함한 현재 서버를 프리징(특정 서버 상태로 돌아갈수 있다)
	-clone : 현재 서버를 복제(여러개의 vm 실행 가능)
	-host2guest, guest2guest 현결을 위한 셋팅
		- Network : Host-only-Adapter 설정
		- File>Host Network Manage>comfigure adapter manually(host의 vip 셋팅, maskset 셋팅, dhcp enable) - host의 vip가 guest의 dhcp 또는 gateway ip가 됨

-Docker : 커널을 공유함, Docker is a platform for developers and sysadmins to develop, deploy, and run applications with containers.
	-Images : A container is launched by running an image. An image is an executable package that includes everything needed to run an application--the code, a runtime, libraries, environment variables, and configuration files.
	-Containerization 장점
		-Flexible: Even the most complex applications can be containerized.
		-Lightweight: Containers leverage and share the host kernel.
		-Interchangeable: You can deploy updates and upgrades on-the-fly.
		-Portable: You can build locally, deploy to the cloud, and run anywhere.
		-Scalable: You can increase and automatically distribute container replicas.
		-Stackable: You can stack services vertically and on-the-fly.

	-구조 : Docker는 이미지를 통째로 생성하지 않고, 바뀐 부분만 생성한 뒤 부모 이미지를 계속 참조하는 방식으로 동작
		-Image : 베이스 이미지에 필요한 프로그램과 라이브러리, 소스를 설치한 뒤 파일 하나로 만든 것
		-Container : image 파일을 실행하여 메모리로 올린 상태
		-특징 : Docker는 특정 실행 파일 또는 스크립트를 위한 실행 환경임
			-Docker는 이미지를 통째로 생성하지 않고, 바뀐 부분만 생성한 뒤 부모 이미지를 계속 참조하는 방식으로 동작
			-이미지를 저장소에 올릴 때는 자식 이미지와 부모 이미지를 함께 올려야함. 받을 때도 부모 이미지를 함께 받음. 이후에는 내용이 바뀐 이미지만 주고받음

	-설치 : https://docs.docker.com/install/linux/docker-ce/ubuntu/
	-docker 설치 위치 : /var/lib/docker, 이미지 파일등이 있는것 같은데 실제 파일은 권한의 이유로 볼수 없다, 보는 방법은 ??
	-docker 서비스 실행 : service docker restart 또는 systemctl restart docker
	-Docker Hub : docker image를 공유하기 위한 public Repository (https://hub.docker.com)

	-docker Command : docker command는 항상 root(sudo)권한으로 실행해야 함
		-sudo를 안쓰기 위해 나의 user를 docker 그룹에 포함시킬 수 있음(sudo usermod -aG docker ${USER}, 재 로그인 필요)
		-search : docker search [특정유저]/ubuntu[:latest] (호스트가 CentOS 라도 Ubuntu image 사용 가능)
		-pull : docker pull ubuntu:latest (docker hub에서 이미지 내려 받기)
		-images : docker images [imageName] (로컬에 다운받은 이미지 목록 조회)
		-run : docker run [-i(input) -t(out) --name containerName] ubuntu [/bin/bash(실행사항)]
			-.. -v /root/data:/data (host의 /root/data를 container의 /data와 연결)

		-ps : docker ps [-a(stop상태포함)]
		-start : docker start {containerName 또는 ID}, 정지된 container를 다시 시작한다.(image가 아니라 container 임)
		-restart : docker restart hello, 컨테이너를 재 시작(os reboot과 유사)
		-attach : docker attach hello, 컨테이너로 접속 (bash 쉘 실행상태로 접속)
		-container 에서 나오기 : exit 또는 Ctrl+D (나오면서 stop), Ctrl+P and Q (실행상태로 나오기)
		-exec : docker exec hello apt-get install nano, 호스트 컴퓨터에서 container 내부로 명령어 보내기(실행 결과가 host 컴퓨터에 나옴, 안되는 명령어들도 있음)
		-stop : docker stop hello, container 정지
		-rm : docker rm hello, container 삭제 (메모리상에서 제거, 해당 container에서 작업한 모두 내용도 삭제 됨)
		-rmi : docker rmi ubuntu:latest, 이미지를 삭제한다.

	-docker file 생성 : 특정 base 이미지를 이용하여 새로운 이미지를 만들수 있는 파일 (ubuntu 베이스로 nginx가 설치된 이미지 생성)
		-Dockerfile(생성하기위한 스크립트 파일) : 파일은 원하는 위치 어디에든 만들수 있으나 파일명은 반드시 Dockerfile로 해야함
		-Dockerfile Command :
			-FROM : base 이미지				FROM ubuntu:14.04
			-MAINTAINER : 작성자				MAINTAINER Foo Bar <foo@bar.com>

			-RUN : 스트립 실행					RUN apt-get update
											RUN apt-get install -y nginx
											RUN echo "\ndaemon off;" >> /etc/nginx/nginx.conf
											RUN chown -R www-data:www-data /var/lib/nginx

			-VOLUME : 공유 Dir				VOLUME ["/data", "/etc/nginx/site-enabled", "/var/log/nginx"]
			-WORKDIR : 시작시 실행될 명령어 위치 	WORKDIR /etc/nginx
			-CMD : 시작시 명령어 				CMD ["nginx"]

			-EXPOSE : 호스트와 연결 port			EXPOSE 80
											EXPOSE 443

			-ADD : Copy a file from the host machine to the new docker image ??
			-ENV : Define an environment variable. ??
			-ENTRYPOINT : Define the default command that will be executed when the container is running. ??
			-USER : Set the user or UID for the container created with the image. ??

		-Dockerfile Build : Dockerfile로 부터 image를 만든다.
			-docker build --tag mynewimage(이미지명):0.1(버전,디폴트 latest) ./(Dockerfile 위치) , 생성된 이미지 파일은 docker의 기본 위치로 들어간다.
			-docker run --name mynewimage -d -p 80:80 -v /root/data:/data mynewimage:0.1 , 해당 이미지 실행



[Virsion Control (VCS)]
SVN : Apache, Apache License 2.0, Central VCS 방식
	-ubuntu, apahche(web), svn : svn 클라이언트가 http 방식으로 svn에 연결할수 있도록 apache 설치 필요(일반적)
	-sudo apt install apache2 apache2-utils
	-sudo apt-get install subversion libapache2-mod-svn subversion-tools libsvn-dev
	-sudo(root)으로 설치, www-data 서비스 유저를 생성하여 관리
	-/etc/apache2/mods-enabled/dav_svn.conf 연결위한 설치 파일
	-svnadmin 명령을 통해 사용자 및 repository 생성(cli를 대체할 gui 툴이 있을듯)
	-http://, https://, file://, svn:// 여러 접속 방식 설정 가능

	-사용
		-서버접속 : pc에서 TortoiseSVN 설치하여 서버 접속 (TortoiseSVN을 서버처럼 사용할수도 있는것 같음, create repository here 명령을 통해 폴더를 서버의 repo 처럼 사용가능, 잘은 모르겠음??)
		-여러 사용자를 생성하여 각 repository 별 사용 권한을 주는 부분을 잘 모르겠음??

Git : version control system, local에서 개발자 단독으로 사용가능, Distributed VCS 방식, 2005년 Linus Torvalds가 개발
	-빠른속도, 단순한 구조, 비선형적인 개발(수천개의 브랜치 동시 개발 가능), 완벽한 분산, 대형 프로젝트에서 검증(안정성)
	-SVN이 버전별 모든 소스코들 가지고 있다면 Git은 Base 버전과의 차이만을 가지고 있어 매우 가볍고 빠르다.
	-Git은 Github와 연동하기 전까진 많은 부분 local에서 개발자 본인을 위한 VCS 기능에 충실한 역할을 한다.
	-소스코드의 각 상태에 대한 스냅샷의 개념
	-repository에 들어간(commit) 데이터는 어떤한 경우에도 임의로 변경할수 없다 (SHA-1 해시를 사용하여 체크섬값을 갖는다.)

	-local에서의 코드 상태
		- working Directory : 실제 작업 디렉토리(수정되면 해당파일은 modified 상태가 됨)
		- staging Area(가상의 공간으로 index라고 부름) :
		- git directory(Repository) : 수정된(새로생성된) 파일이 최종 commit 되어 해당 파일이 snapshot된 상태
		
	-git Graph 에서의 HEAD 의 의미 : 
		-해당 브랜치에서 내 코드가 위치한 커밋 위치
		-orgin/HEAD : 해당 Repository의 최초 브랜치(최상의 부모)의 현재 위치를 보여주는듯. 기본적으로 최초 브랜치가 master 임으로 항상 master 브랜치와 같이 움직이지만 최초 브랜치가 master가 아닌경우를 위해 origin/HEAD 를 표기해주는 걸까???
		
		-(그냥)HEAD : 
			-개념적 : 
				-현재 내 로컬 디렉토리의 코드가 위치한 위치. 기본적으로 현재 브랜치의 최상단이 HEAD가 되겠지만 그래프상(sourcetree) 딱히 HEAD라 표기해 주지 않음.
				-특정 브랜치에서 커밋하지 않은 코드 수정이 있는 경우 Uncommited changes라고 표기해 주는데 이 유치가 현재 코드의 위치이고(커밋은 안했지만) 다시말해 HEAD의 의미와 동일함
				
			-활용적 :
				-특정 브랜치로 체크아웃하는 것이 아니라 특정브랜치의 특정 시점으로 체크아웃 하는 개념(코드 트리에서 특정 위치를 클릭하여 체크아웃 가능)
				-이 경우 로컬 코드가 특정 브랜치의 특정 위치에 있기때문에 해당 브랜치로 체크아웃 했다고 보여주기 애매함(보통 브랜치로 체크아웃하면 해당 브랜치의 최상단에 위치하기 때문), 그래서 현재 로컬의 그 위치를 표기하기 위해 HEAD라는 것으로 표시해줌(일종의 임시 브랜치)
				-그럼, 이 특정위치에서 코드를 수정하고 commit이 가능 할까? 가능함, commit시 HEAD(임시브랜치)에 반영되며 기존 브랜치에서 갈래로 빠져 나온다(origin 브랜치가 없기 때문에 push는 당연히 불가)
				-그럼 다시 다른 브랜치로 체크아웃 하거나 다른 코드 위치로 옮기게 되면 HEAD는 어떻게 될까? 모두 날라감, 임시브랜치의 개념처럼 다른 위치로 옮기게 되면 이미 commit한 기록을 포함하여 모두 소멸됨
				-그럼 이게 왜 필요할까? 코드의 특정위치로 쉽게 쉽게 옮겨 다니며 이전 코드를 확인해 보거나 해당 시점 코드로 로컬 서버를 돌려보는 용도로 활용할 수 있다.
				-특정 시점의 코드에서 수정을 해보고 싶은 경우 하면되고 맘에 들면 commit(임시적)도 해서 관리할수 있다. 그러다가 해당 시점의 코드에서 뭔가 재대로 해보고 싶은 경우는 HEAD(임시브랜치)를 새로운 정식 브랜치로 만들면 된다(그냥 옮기면 모두 소멸)
				-딱히 더이상 할게 없는 경우는 다시 다른 브랜치로 옮기면 깔끔히 모두 소멸 됨


	-git 설치
		-ubuntu : sudo apt install git-all, Source Code를 다운받아 설치도 가능(기능 수정이 필요하거나 특정 플러그인의 추가 삭제가 필요한 특별한 경우에 함)
			-기본설정 : ~/.gitconfig 또는 /etc/gitconfig 설정 (개인 설정이 우선함)
			-필수설정 : $git config --global user.name "John Doe" and $git config --global user.email johndoe@example.com
			-설정확인 : $git config --list

		-window : http://git-scm.com/download/win, git(git for window), cli 및 gui 환경을 제공하는 3rd party 제품 (여러 종류가 3rd party가 있는듯 함)
			-설정 : ubuntu 설정과 유사하게 하면된다.
			-GitHub Desktop
				-local에 새 git repo생성(git init 해주는 의미), 이미 존재하는 git repo를 툴에 로드, GitHub에서 clone 받아 local에 신규 git repo 생성
				-툴에 로딩되어 있는 repo에서 변경 사항이 발생시 확인할수(changes 리스트에서) 있음(바로 commit 가능, stage로 올리는 단계(add를 통해) 없이 바로 commit 하는것 같음??)
				-툴에 로딩되어 있는 repo에 대한 commit결과를 확인할수(history 리스트에서) 있음(cli 통해 commit한 내용도 desktop에 실시간 반영됨)
				-GitHub로 push(Fetch), pull 가능
				-툴을 GitHub 계정과 연동 가능(File>options) - GitHub에서 인증키 복사해서 사용했나??

			-GitHub GUI : repo 생성, 오픈, clone 기능 제공(별쓸모 없어 보임)
			-Git CMD(deprecated) : cli를 사용할수 있도록 cmd 창을 열어줌(별쓸모 없어 보이며 deprecated 됨)
			-Git Bash : cli를 사용할수 있도록 bash 창을 열어줌 (linux command 사용해야 함)

			-git Command
				-git 처리 단계 : working Dir(빨강글씨) $git add [fileName] -> stage/index(녹색글씨) $git commit [fileName] -> Repository
				-git init : 새로운 git repo 생성, .git 디렉토리가 생성됨
				-git clone repo-url : 해당 git repo-url의 repo를 복제한다. (복제한 repo는 origin repo의 모든 이력을 포함하며 원본 repo가 해당 repo의 orgin repo가 된다.), 로컬 repo도 clone 가능??
				-git status [-s] : 해당 repo의 코드 상태 확인 (Untracked files>>새파일, modified>>수정, deleted:삭제파일)
				-git add [fileName] : 새파일 또는 변경된 파일을 stage/index 단계로 올려 준다
				-git commit [fileName] [-a(working 상태 모두)] [-m commitMessage] : stage/index 단계의 파일을 repo에 commit
				-git diff [--staged/--cached] : 수정 내용 확인
				-git rm [fileName] : 파일 삭제, 실제 working Directory 에서 삭제 가능
				-git mv oldFileName newFileName : 파일명 변경된
				-git reset fileName : staged 상태의 파일을 working 상태로 다시 내린다. (이번 커밋에서 제외가 필요할 경우)
				-git checkout -- fileName : 해당 파일을 최초 clone 했을때의 상태로 복구
				-git log [옵션이 많음] : 해당 repo의 history 확인 (Gui 툴을 쓰는게 날듯)
				-git remote -v : 해당 repo의 origin remote 정보를 보여준다. (또한 해당 orign에 할수 있는 권한도 보여 준다(push/fetch)

			-Commit 수정(이미 commit된 것에 파일을 추가하고 하나의 커밋으로 보이도록 처리, 오류 커밋 직후 사용할것)
				-git add fileName : 추가할 파일을 stage/index 로 올린다.
				-git commit --amend : 직전 커밋과 하나로 만들어 준다

			-.gitIgnore
				-repo /(루트)에 위치해야 함, 표준 Glob 패턴을 사용한다, https://github.com/github/gitignore 참고

			(https://git-scm.com/book/ko/v2/Git%EC%9D%98-%EA%B8%B0%EC%B4%88-%EB%A6%AC%EB%AA%A8%ED%8A%B8-%EC%A0%80%EC%9E%A5%EC%86%8C)

			-git pull and git merge : pull은 동일한 브랜치에 대해 remote의 코드를 local로 가져온다(complict이 날수 있음), git merge는 서로다른 브랜치의 코드를 합치는 작업(complict이 날수 있음)

			-git advanced Command : 문제 해결 
			
				-reset : 해당 커밋 위치로 로컬 HEAD를 옮기는 의미 (source tree에서 특정 커밋을 클릭하여 옮기는 의미와 유사)
				
					-git fetch --all  이후 git reset --hard origin/브랜치name
						-options :
							-soft(keep all local changes) : 
								-최상위 커밋 상태의 코드와 비교하여 옮겨질 위치의 코드와 다른 점들을 모두 staged상태에 모아 준다.
								-결과적으로 로컬 코드는 최상위 커밋 상태와 같은 상태지만 이후에 staged에 있는 파일들을 discard를 이용하여 모두 또는 선별적으로 날려 버릴수 있다
								-로컬에 commit 하지 않은 코드가 있는 상태에서 reset soft 시 로컬에 commit하지 않은 코드는 unstaged 상태에 있게 된다. 
								
							-mixed(옵션이 없을경우 default, keep working copy but reset index) :
								-soft와 동일하나 최상위 커밋 기준 변경사항이 soft는 staged에 남는 반변 mixed는 unstaged에 남게 된다(로컬에 commit하지 않은 코드가 있었던 경우라면 파일이 섞여서 혼선이 생길수도 있을 듯)
								
							-hard(discard all working copy changes) :
								-해당 커밋 위치로 로컬 HEAD를 옮기는 것만 해준다. 최상위 커밋 상태와 다른 점들은 그냥 무시된다(unstage, stage 어디에도 남겨 주지 않는다.) 또한 로컬에 commit하지 않는 코드가 있더라도 모두 날려 버린다.) 
								-딱 그상태로 만들어주는 개념 (source tree에서 특정 커밋을 클릭하여 옮기는 의미와 거의 유사)
												
				-push(force 옵션) : 나의 현재 로컬 브랜치 상태로(해당 브렌치의 HEAD 위치로) remote 브랜치를 강제로 일치 시킨다.
					-git push -f origin master(브랜치명)
						-리모트에 다른 commit 들이 선행되어 있는경우 pull 하기 전에 push가 불가능 하나 --force 옵션을 통해 pull하지 않고도 강제로 push 할수 있다
						-이 경우 remote에 있는 선행 컷밋들은 모드 날라가게 된다.
						-잘못 push한 내용이 있는경우 reset을 통해 원하는 위치로 로컬 위치를 옮긴 후 push --force를 통해 remote의 상위 commit을 강제로 날리수 있다.
						-강제 옵션(git push --force)을 사용하기 위해서는 해단 repository에 protect 옵션 해제 또는 권한이 필요하다 (git 상품에 따라 확인 필요)
						-!!! 만약 다른 사람이 이미 remote의 내용을 pull 해간 상태에서 내가 remote의 내용을 특정 위치로 변경(삭제)하면 다른 사람은 어떻게 해야 하지?? 다들 해당 위치로 reset을 해줘야 할까???			
			
				-머지한 커밋을 원복한다(merge revert) :
					-git revert 머지커밋번호(7자) -m 1

GitLap : web-based DevOps lifecycle tool that provides a Git-repository manager providing wiki, issue-tracking and CI/CD pipeline features
	-사용자 무제한 무료 (기술 서포트를 받기 위해서는 비용 지불 필요)
	-minimum requirement : 2core, 4GB (to support up to 100 users)
	-공식 사이트 : https://about.gitlab.com/update/#ubuntu

	-설치 : https://teamlab.github.io/jekyllDecent/blog/tutorials/%EB%82%98%EB%A7%8C%EC%9D%98-Git-%EC%84%9C%EB%B2%84-Gitlab-%EA%B5%AC%EC%B6%95
		-$sudo apt-get install curl openssh-server ca-certificates postfix : 필요한 부가 모듈 설치 (postfix=메일전송기능관련, openssh-내부적으로 필요)
		-$curl -sS https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.deb.sh | sudo bash : Gitlab 패키지 저장소 추가
		-$apt-get update : 저장소 업데이트
		-$sudo apt-get install gitlab-ce : Gitlab Community Edition 설치
		-$sudo gitlab-ctl reconfigure : 서버에 문제가 있거나 업데이트/설정 변경을 한경우 실행해 준다.
		-$sudo vi cd /etc/gitlab/gitlab.rb : 주요 설정 사항 변경
			-## external_url 'http://localhost' >> 'http(S)://localhost:9081' (port를 붙이지 않으면 80적용, ssl을 사용하기 위해서는 ip가 아닌 도메인 설정)
			-## gitlab_workhorse['auth_backend'] = "http://localhost:8080" >> "http(s)://localhost:9082" (external_url와 다른 포트를 사용해야 함)
			-## unicorn['port'] = 8080 >> 9082 (gitlab_workhorse와 동일 포트 사용해야 함)

		-$sudo gitlab-ctl reconfigure , $sudo gitlab-ctl restart , $sudo gitlab-ctl status : reconfigure 및 재 실행
		-gitlab web 접속 및 초기 설정 : root 계정의 비밀번호를 등록 한다.
		-SSL 접속 설정 : https 접속시 설정 (https://blog.lael.be/post/5476)

	-내부 사용 모듈 : nginx, openssh, postfix(mail), unicorn(DB??), redis ..
	-방화벽(TCP인바운드) 오픈 포트 : http(nginx=9081), https(nginx=443), ssh(openssh=22)

	-관리 :
		-Backup : $sudo gitlab-rake gitlab:backup:create (환경 설정, 사용자 정보, 저장소 정보를 포함한 모든 gitlab 정보가 백업)
			-backup 위치 : /var/opt/gitlab/backups (/etc/gitlab/gitlab.rb 파일의 gitlab_rails[‘backup_path’] 에서 수정가능)
		-Recovery :
			-/var/opt/gitlab/backups/ : 해당 위치에 백업할 tar 파일이 존재 해야함 (신규 서버에서 백업 파일을 복구할경우 이동해 준다.)
			-$sudo gitlab-ctl stop unicorn , sudo gitlab-ctl stop sidekiq : DB 관련 서비스 중지
			-$gitlab-rake gitlab:backup:restore BACKUP=1553573272_2019_03_26_11.9.0 : _gitlab_backup.tar을 제외한 백업날자 까지만 입력(확실한지 물으면 yes)
			-신규 서버로 복구시 : /etc/gitlab/gitlab-secrets.json 파일도 같이 이동 (gitlab에서 사용하는 암호화키 파일)
			-$gitlab-ctl restart : 서비스 재시작
			-$gitlab-rake gitlab:check SANITIZE=true : 복구된 체크 및 교정(해결될때까지 반복)


Github :
BitBucket :


Sourcetree : GIT 클라이언트 툴
	-repository 만들기 : 상단 + 탭을 이용하여 생성
		-Local : 기존에(이미) local pc에 존재하는(sourcetree에서 만들었던) reposity 목록을 보여 주고 선택시 해당 repository로 바로 연결해 준다.
		-remote : 등록된 계정을 통해(gitlab 이든 github등) 해당 계정에 연결된 remote(계정이 있다는건 당연히 remote를 의미하겠지만)의 repository를 보여주고 clone 할수 있게 해준다.
		-clone : 이미 존재하는 (로컬이든 리모트든) repository에 접근하여 local로 clone(복제)후 연결해 준다.
		-add : 기존에(이미) local pc에 존재하는(sourcetree에서 만들었던 아니든) reposity 목록을 보여 주고 선택시 해당 repository로 바로 연결해 준다.
		-create : 로컬에 새로운 repository를 만들어 준다.

	-존재하는 로컬 프로젝트를 로컬 repository로 만들고 서버 repository로 올리는 방법 :
		-create를 이용해 기존 프로젝트 폴더를 repository로 만든다. (기존 코드를 첫 커밋하기 전에 .gitignore 파일을 만들고 하는게 좋다)
			-해당 로컬 리포지토리를 서버 repository로 올리고 싶을때  :
				-서버에 Repository를 하나 먼저 만든다. 새파일(readme등)을 만들어 master 브랜치를 만든다.
					-로컬 리포지토리의 설정에 remote를 선택하여 해당 서버의 주소를 clone해서 붙여 넣는다. (fetch를 해보면 서버의 master 위치가 보임, 서로 연결고리는 없음)
						-서로 연결 고리가 없어서 pull, push, merge가 안됨
							-git command로 연결해 준다(연결성 없는 관계지만 pull 하는 옵션) : git pull origin master --allow-unrelated-histories
								-연결성이 생겼음으로 push 할 수 있게 된다.

	-참고:
		-origin Branch로 local Branch로 생성 후 최초로 push 하기 위해서는 pull할 것이 없더라도 최초 origin으로 부터 pull을 한후 push 해야 한다.(최초 연결 고리가 없기 때문에 pull할께 있어도 모르기 때문)



[Web Service]
-웹서비스 구성 : web server(Apache HTTP Server, IIS, Nginx, Lighttpd..) + was server(Apache Tomcat Server, .Net, Zend Server(PHP)..) + etc(DB..)

	-Web서버(static 서버) : 클라이언트(브라우저)로 부터 http를 통해 요청되는 request를 받아서 서버에 준비되어 있는 컨텐츠를 http를 통해 !!그대로 내려주는 역할을 한다.
		-초창기 web 서비스의 경우는 서버에 있는 컨텐츠를 에이전트로 그대로 내려주는 역할만을 했다(이때는 이걸로도 만족). 서버는 서버의 자원을 조작하지 않고 저장된 정적 파일(html문서, js파일, 이미지파일)을 그대로 내려 준다.
		-현시대에는 위 static한 역할만 하는 서버는 무용지물인데 왜 계속하여 사용 할까? 
			-was를 통해 dynamic하게 처리된 최종 결과 html을 생성하여 내려주면(결국은 text) 브라우저는 해당 document를 읽으며 그에 관련된 static 파일(js, 이미지 파일등)을 다시 요청하게 된다. 
			-이럴때 web 서버를 두면 static한 처리와 dynamic한 처리를 구분지어 처리하게 할수 있음으로 부하 분산의 효가가 있다.
			-was 서버또한 web 서버가 하는 static한 파일을 내려주는 역할을 다 할 수 있지만 부하 측면에서 두 서버간 역할을 구분하는 것은 좋은 방법이다. 또한 일반적으로 web 서버가 static한 파일을 처리하는데 훨씬 가볍고 빠르게 동작한다.
			-부가적인 이점으로 web 서버를 앞에 둠으로 해서 중요한 자원과 코드를 뒤쪽 was에 둠으로서 보안적 측면에 이점이 있다. 또한 web 서버에 연결할 was 서버를 선택적으로 설정하여 무중단 패치등도 가능하다.
		
		-웹서버 주요 기능 및 설정 (웹서버의 종류에 따라 설정 파일명이 다를수 있다)
			-웹서버 기능 설정을 위한 configuration 파일	
				-httpd.conf : 아파치 서버 전체에 대한 설정 파일이다, 개별 설정인 .htaccess 파일을 활성/비활성 하게 할수 있다.<Directory ...>AllowOverride (all->none으로 변경)</Directory ...> 
					-설정 항목을 별도의 conf파일로 분리 작성 후 해당 파일을 include 하여 동작하게도 할 수 있다, 웹서버가 start 또는 reload 될때 한번만 로딩한다.
					
				-.htaccess(hypertext access) : httpd.conf 파일의 설정을 무시하고 해당 디렉토리 전용 설정을 할수 있게 해줌, 그래서 호스팅 서버의 경우 각 사용자 디렉토리별로 서로 다른 설정이 가능함
					-해당 설정은 자신 디렉토리와 함께 하위 디렉토리에 모두 적용됨, 하위디렉토에 새로운 .htacess 파일이 존재하면 설정이 새로 적용됨
					-매 request 마다 해당 파일을 읽기 때문에 request가 많은 서버의 경우 비효율적인 문제가 있음 (실제 설정 내용이 없더라도 .htaccess 파일 옵션을 enabled 하는것 많으로도 부하를 높이기 때문에 사용 옵션을 끄는것이 좋다)
					-.(쩜)으로 시작되는 파일은 보통 시스템에서 숨긴처리가 됨으로 .htaccess 파일이 보이지 않을수 있음(숨김처리되어)
		
			-웹서버 주요 기능 (httpd.conf와 .htaccess가 기본적으로 동일? 한것으로 보고 .htaccess 기준으로 설명), https://www.whoishostingthis.com/resources/htaccess/
				-static 파일들에 대한 웹서비스를 제공하는 웹 루트를 제공함 (public_html or www 디렉토리)
				-.htaccess 파일을 통한 서비스 제약 설정 가능(.htaccess 파일 생성은 vi같은 에디터 프로그램으로 직접 만들수도 또는 만들어진 파일을 FTP로 올리수도 있음
					
					-접속제한(권한) : .htaccess 파일의 가장 기본적인 목적은 특정 사용자만 접속할수 있도록 하기위한 목적이었다(하나의 web 서버를 여러사용자가 사용하는 형태 였기 때문에)
						-.htpasswd 파일과 .htaccess 파일의 설정을 통해 구현 가능
						-.htpasswd 파일 생성
							-htpasswd -c /usr/local/etc/ .htpasswd johnsmith (-c:생성하겠다는 옵션 -b옵션을 통해 비번 암호화 알고리즘을 선택 할 수도 있다, 이미 .htpasswd 파일이 존재하는 경우 라인이 추가된다.(여러명 한파일에 가능))
							-위 명령어 입력시 비밀번호를 입력하는 프롬프트가 나온다, 비빌번호를 추가로 입력하면 해당 파일 생성이 완료됨
							-.htpasswd 파일은 웹에 오픈된 디렉토리에 두면 안되고 /usr/local/etc/ 등 웹과 연결되지 않은 위치에 둘것!
								------
								johnsmith:F418zSM0k6tGI (이러 내용의 파일이 생성됨, 뒤 내용은 암호화된 비빌번호 값(기본으로 md5로 적용됨)
								------
							-.htpasswd 파일을 .htaccess 파일과 연결
								------
								AuthUserFile /usr/local/etc/.htpasswd   (.htpasswd 파일 위치)
								AuthName "Name of Secure Area" (!!그냥 네이밍에 불과, 큰의미 없음)
								AuthType Basic
								
								<Limit GET POST>
								require valid-user  (!!.htpasswd 에 올려진 모든 사용자가 접속가능, 물론 psw 가 일치해야 함)
								</Limit>
								
								<Limit GET POST>
								require user johnsmith (!!.htpasswd 에 올려진 사용자 중에서도 특정 사용자만 접속가능, 역시 psw 가 일치해야 함)
								require user janedoe
								</Limit>
								------
								
								(그룹파일을 생성하여 해당 그룹에 속한 사람에게만 권한을 주게 할수도 있다)
								.htgroups  파일 생성		
								------
								admin: johnsmith janedoe
								staff: jackdoe cindysmith
								------
								(.htpasswd 와 .htgroup 을 .htaccess 파일과 연경해서 사용 가능함)
								------
								AuthUserFile /usr/local/etc/.htpasswd
								AuthGroupFile /usr/local/etc/.htgroup
								AuthName "Admin Area"
								AuthType Basic
								<Limit GET POST>
								require group admin
								</Limit>
								------
						
					-에러코드 핸들링 : 웹서버나 was 서버가 자체적으로 판단해 오류코드를 발생(response http status 코드와 body에 내용을 담을듯)하는 경우와 was 서버가 오류를 Exception 처리하여 코드를 내리는 경우로 볼수 있다.
						-4XX(Client Request Error) : 요청에 잘못이 있을때 발생 (없는 리소스를 요청하거나 요청권한이 없는것을 요청하는등) 
						-5XX(Server Error) : 서버에 내부 오류가 발생했을 경우 발생, 또는 내부 인프라의 오류 등, 보통 WAS와 연결된 경우 was쪽에서 발생하는 에러들일 것이다. (개발자의 의도에 따라 4XX에러로 얼마든지 내릴수 있다)
						-서버 자체 판단에 의해 내려간 에러 코드나 개발자가 Exception 처리를 통해 발생시킨 에러코드든 response의 http status 코드에 따라 최종 response가 나가는 시점에 특정페이를 랜딩해줄 수 있다(에러페이지 등)
							-.htaccess 파일을 아래와 같이 적용하여 처리 가능 (해당 .htaccess 파일의 하위 디렉토리부터 발생한 에러 코드에 대해 적용됨)
								--------
								ErrorDocument 400 /errors/bad-request.html
								ErrorDocument 401 /errors/auth-reqd.html 등등..
								--------
								
					-Server Side Includes (SSI) 기능 활성화 : html에 해더 html 또는 풋터 html을 붙일수 있는 <!--#include file="header.html" --> 스크립트를 서버가 인지할수 있도록 해준다.
						-요즘?의 Layout Template Engines 인 Tiles 또는 Sitemesh 가 처리하는 기능을 수행하기 위한 초기?의 기능과 같은것 인듯? (지금은 별로 사용될일이 없어 보임)
							-------(대충 이런식)
							AddType text/html .shtml
							AddHandler server-parsed .shtml
							Options Indexes FollowSymLinks Includes
							-------
							
					-IP 접근 제어 (IP Blacklisting and IP Whitelisting) : 특정 ip만 접근하게 또는 특정 ip만 접근 못하게
						-Blacklisting by IP : 특정 ip만 차단
							--------
							order allow,deny
							deny from 111.22.3.4
							deny from 789.56.4. (ip 영역으로 지정 가능)
							allow from all
							--------
						
						-Whitelisting by IP : 특정 ip만 허용
							--------
							order deny,allow
							deny from all
							allow from 111.22.3.4
							allow from 789.56.4. (ip 영역으로 지정 가능)
							--------						
						
						-Blacklisting by Domain or referrer : 특정 도메인(정확히는 DNS가 내려주는 해당 도메인의 IP를 차단하는 개념임)과 핫링크가 걸려있는 경우에 대한 방어로 reffer 값을 통해 차단 가능
							--------
							order allow,deny
							deny from example.com (DNS에 질의하여 example.com 의 ip와 같은 경우 차단됨)
							allow from all
							--------	
							
						-핫링크로 자신의 서버 리소스를 땡겨가는 경우를 차단하기 위해 
							--------
							RewriteEngine on (해당 기능 on, mod_rewrite 모듈이 설치되어 있어야 함)
							RewriteCond % ^http://.*example.com [NC,OR] (NC=대소문자 구분 없음, OR=아래 다른조건도 적용된다는 의미)
							RewriteCond % ^http://.*anotherexample.com [NC,OR]
							RewriteCond % ^http://.*onemoreexample.com [NC]
							RewriteRule .* - [F] (해당 referr에서 요청이 왔을경우 403 Forbidden 을 주라는 의미)
							--------
			
					-디렉토리 디폴트 페이지(index) 지정 :
						------
						DirectoryIndex index.php index.shtml index.html (여러 형태의 디폴트 파일을 지정할수 있다. 순서대로 확인함)
						------
						
					-페이지 이동 (URL Redirects and URL Rewriting) : 요즘은 web서버 차원이 아닌 was의 servlet 내부에서 코드를 통해서 처리하는 경우도 많음
						-Redirects : 301(Permanently Moved) 또는 302(Temporarily Moved) 코드와 함께 이동할 주소를 응답해 주면 응답받은 브라우저가(사용자의 간여없이) 새 url로 다시 request를 하는 방식
								-반드시 그런것은 아니지만 보통 다른 도메인으로 이동되는 경우에 사용됨 (같은 서버 내의 다른 path로 이동시킬수도 있음)
								
							-응답코드 차이 : 301, 302는 SEO(searching engin optimization)와 브라우저의 동작에 있어서 차이가 있을 수 있다.
								-301 : origin url에서 new url로 영속적으로 변경된 것으로 판단하여 보통의 검색 엔진은 갖고 있던 origin url에 대한 정보를 new url 정보로 변경 처리한다. (origin url에 대한 평가 점수도 그대로 new로 이동)
									-브라우저가 갖고 있던 북마크 정보에서 origin url 정보가 있으면 new url 정보로 변경처리 (브라우저에 따라 동작은 다를 수 있다)
						
								-302 : origin url 이 new url로 임시적으로 올겨졌다고 판단하여 검색엔진이나 브라우저가 특별한 처리를 하지 않음(브라우저가 단순히 new url로 다시 request만 보냄)
							
							-------
							Redirect 301 /relative-url.html http://example.com/full-url.html (/relative-url.html 요청을 http://example.com/full-url.html 으로 재 접속하게 만듬)
							-------
							Redirect 301 /old-directory http://example.com/new-directory (특정 디렉토리 내의 요청을 특정 디렉토리 내의 요청으로 모두 적용가능)
							-------
							Redirect 301 / http://newurl.com (모든 요청을 새 도메인으로 요청하도록 적용 가능, 특정 서브도메인 예를들어 www 이 붙은 경우 www이 안붙은 도메인으로 처리할수도 있음)
							-------
						-rewriteing : 아파치 웹서버가 같고 있는 하나의 기능? 으로 servlet의 forwarding과 유사?하게 동작함, 브라우저에서 new url로 재 접속하는 것이 아니라 ruquest를 받은 서버거 new url로 request를 넘겨줌
								-origin url과 new url이 동일한 request를 공유함, 그렇기 때문에 보통 같은 서버의 다른 path로 이동되는 경우에 사용되고 서버단에서 일어나는 동작임으로 브라우저는 별도의 처리나 url 창에 변화가 없음
								-301 또는 302 등의 response 코드를 사용하지 않는다.
								-해당 기능을 사용하기 위해서는 mod_rewrite 가 서버에 플러그인 되어 있어야 함
									
									-redirect와 forward의 차이점!!
										-redirect는 HttPServletResponse에 선엔된 메서드로 response 해더를 통해 301or302 status와 location 값을 이용하여 브라우저가 직접 new Url로 이동하도록 유도하는것(주로 타서버로 이동시 사용됨)
										-forward는 RequestDispatcher에 선언된 메서드로 최초 들어온 request를 container(was)가 주간하여 타 리소스(uri) request를 넘겨주는것이다.(동일서버에서만 넘길수 있음, 동일 request가 공유됨)
					
					-특정 파일 deny 처리 : 특정 중요 파일이 web public 폴더 내에 있더라도 access deny 되도록 처리 할 수 있다.(예를 들면 .htaccess 파일 같이 보안과 관련한 중요한 설정에 대한 파일들)
						--------
						<Files .htaccess> (.htaccess 파일에 대한 엑세스 불과 처리)
						order allow,deny
						deny from all
						</Files>
						--------
						
					-MIME Type 설정 : Multipurpose Internet Mail Extensions의 뜻으로 그 기원?은 메일처리를 위한것에서 출발하였으나 지금은 해당 서버가 처리할수 있는 파일 타입을 정의하는 의미로 보면됨
						-mime type 설정에 빠져 있는 데이터를 요청시 서버는 해당 request에 대해서 fail을 내려 준다.
						-해당 서버가 처리할 수 있는 파일 타입을 선언하는 의미와 동시에 특정 파일의 경우 브라우저에서 직접보여주는 것이 아니라 download 될수 있도록 설정해 줄수 있다.
						-보통 인터넷에 돌아다니는 List of File Extensions and MIME Types 목록을 가져다 그냥 모두 때려 넣어 사용하면 됨(일일이 정리하기에 너무 많음)
							------
							AddType text/richtext rtx  (텍스트 형태의 richtext 파일로 rtx 확장자를 사용하고 있는것이란 선언)
							AddType image/jpeg jpeg jpg jpe JPG (이미지 파일로 jpeg 파일로 jpg, jpe, JPG 확장자를 쓸수 있다고 선언)
							AddType application/octet-stream pdf doc docx rtf (application/octet-stream 사용을 통해 pdf doc docx rtf 확장자의 파일을 요청 받으면 브라우저에서 보이지 말고 다운로드 하도록 할수 있음)
							------
					
					-핫링크 방지(Block Hotlinking) : 다른 서버가 내 서버의 리소스를 무단으로 연경하여 사용하는 것을 방지 (복사해가는 것이 아니라 실제 나의 서버로 request 하는 경우를 말하며 이럴경우 나의 서버에 부하를 주게 된다)
						------
						<img src="http://yourdomain.com/image.jpg"> (이런식으로 타 서버가 내 서버로 이미지나 js, css 등을 요청하는 경우에 대한 방지
						------
						RewriteEngine on (mod_rewrite 모듈을 사용하여 처리)
						RewriteCond % !^$
						RewriteCond % !^http://(www.)?example.com/.*$ [NC] (내 도메인이 아닌 곳에서 요청이 올경우)
						RewriteRule .(gif|jpg|jpeg|png|js|css)$ - [F] (gif,jpg... 에 대한 요청이면 Fail를 내려라)
						------
						RewriteEngine on
						RewriteCond % !^$
						RewriteCond % !^http://(www.)?example.com/.*$ [NC]
						RewriteRule .(gif|jpg)$ http://www.example.com/no-hotlinking.jpg [R,L] (gif, jpg 요청이 오면 no-hotlinking.jpg 이미지로 대체해서 내려줘라(엿먹이는??))
					
					-디렉토리 indexing 기능에 대한 처리 : 웹서버로 특정 파일에 대한 요청이 아니라 특정 디렉토리까지 path가 지정되어 요청되었을때 웹서버는 해당 디렉토리내의 파일 목록을 보여줄수도(특정파일은 빼고 보여줄수도 있다) 안보여줄수도 있다
						-------
						Options -Indexes (디렉토리 내 파일 목록을 보여주지 않는다, 보안상 좋음)
						-------
						Options +Indexes (디렉토리 내 파일 목록을 보여준다)
						IndexIgnore *.gif *.jpg (gif, jpg 확장자 파일은 제외하고 보여준다)
						IndexIgnore secret.txt (특정 파일명을 지목하여 안보여주게 할수 있다)
						-------
						
					-CGI 디렉토리 변경 : Common Gateway Interface은 perl 또는 SSI 스크립트를 통해 웹페이지안에 html 이 아닌 스크립트를 넣어 서버가(적절한) 동작을 할수 있게 해준다.
						-일반적으로 CGI 스크립트는 웹서버의 /cgi-bin/에 자리하는데 "-"를 url에 표기할때의 문제, 큰 사이트의 경우 많은 cgi 리소스가 같은 폴더에 보관되는게 관리에 어려움이 있을수 있다. 
						-이때 cgi 리소스의 위치를 /cgi-bin/로 한정하지 않고 사용할 수 있는 방법을 제공해 준다.
							-------
							AddHandler cgi-script .cgi (확장자 .cgi는 cgi 스크립트로 인식하여 처리하게 해준다)
							Options +ExecCGI 
							-------
					
					-스크립트 및 코드를 텍스트로 인식하게 처리 : 특정 웹 디렉토리 내의 코드를 실행인 아닌 text로 인식하여 화면에 보여줄수 있는 기능을 제공한다. (Git과 같이 코드관리 사이트의 경우를 말함)
						-------
						RemoveHandler cgi-script .pl .cgi .php .py (해당 확장자에 대해 cgi 실행을 차단한다)
						AddType text/plain .pl .cgi .php .py  (해당 확장자를 plan 텍스트로 받아드려 브러우저에 보여주게 한다)
						-------
						RemoveHandler cgi-script .pl .cgi .php .py (해당 확장자에 대해 cgi 실행을 차단한다)
						AddType application/octet-stream .pl .cgi .php .py (해당 확장자를 application으로 인식하게 하여 브라우저가 다운로드 하도록 처리한다)
						-------
						
					-PHP 관련 설정 : 상세 설정은 php.ini 에서 처리하지만 .htaccess파일에서 일부 설정을 적용할수 있다(웹호스팅의 경우 한 사용자가 전체 php에 영향을 주는 php.ini 파일을 수정할수 있게 하지 않기 때문에)
						-php 설정값 셋팅 : php의 모든 설정 변수를 셋팅할 수 있는 것은 아니다.
							-------
							php_value upload_max_filesize  10M (php의 upload_max_filesize 설정값을 10M로 셋팅)
							php_value date.timezone 'Asia/Seoul' (php 에서 사용할 타임 기준을 정할 수 있음)
							-------
						
						-기타 php 관련 include 파일 및 ini 파일들에 대한 엑세스 제한 기능도 제공하고 있다.
					
					
			
			
			
		
	-Was서버(dynamic 서버) : 클라이언트(브라우저에서 직접 또는 web서버를 거쳐 들어온 요청)로 부터 요청을 받아 처리된 결과물을 dynamic하게 생성하여 요청한 클라이언트로 내려 줄수 있다.
		-was 대표 구성 요건 :
			-web server connectors : http web서버(apache같은)의 연결을 받기 위한 connector.
			-programming languages : dynamic한 처리 결과를 만들어 내기 위해 제공된 lib를 이용하여 개발할수 있는 언어를 제공해야 함
			-runtime libraries : 여러 주요 부가기능(보안, 트랜젝션, 편의기능)을 lib를 통해 서버들이 제공해 주고 있다.
			-database connector : DB를 연결할수 있는 수단을 제공함
			-administration code : deploy, configure, manage를 위한 부가 요소
			
		-was 서버에서의 특징 : 
			-IoC(Inversion of Control) 개념이 커짐, 프레임워크의 성향을 띄기에 개발자가 전체 프로그램의 흐름을 주도하는 것이 아니라 적제적소에 필요한 코드를 넣어 주는 개념(AOP)이 강해짐(전체적인 흐림과 주요공통 기능에 대해 서버에 일임)
			-was + spring 또는 EJB 서버의 경우 IoC 개념이 더욱더 커지개 되었다 (was+spring 형태는 EJB 서버의 기능 구성과 유사한듯..)
			
	
	
-대표 WAS 서버 : 
	-apache Tomcat : 
	
	-EJB서버들(weblogic, Webspere, Jboss..)
		





[Spring & Spring boot]
-Spring Framework : 아래와 같은 주요 기능(Main Features)을 Dependency Injection 해줌
	-Spring JDBC
	-Spring MVC : 브라우저->Filter->DispatcherServlet->HandlerMapping->Controller(Bean,Model,Service,DAO,DB 이용)->DispatcherServlet->ViewResolver->View->DispatcherServlet->Filter->브라우저
	-Spring Security
	-Spring AOP (aspect oriented programing) : 개발자가 핵심 로직에만 집중할수 있도록 공통 기능을 framework 에서 지원 (filter 처럼 선/후 처리를 지원하는 class 지정 가능)
	-Spring ORM (object relational mapping) : 하이버네이트, JPA 등을 이용해서 DAO 레이어를 구축하는 방식
	-Spring Test


-Spring Boot Framework : Spring Framework의 확장형으로 설정과 관련한 편의성이 향상 되었다.
	-application configuration 이 간소해짐(xml이 사라지고 거의 모두 코드 레벨에서 어노테이션을 통해 이루어짐)
	-Tomcat 같은 서버가 Embedded 되어 패키징 됨(별도의 서버 설치나 deploy가 필요 없음)
	-Metrics, Helth check, and externalized configuration
	-Automatic config for Spring functionality – whenever possible


-Handler Interceptor : 인터셉터는 DispatcherServlet이 컨트롤러를 호출하기 전,후에 요청과 응답을 가로채서 가공할 수 있도록 해준다.
-HandlerMethodArgumentResolver : ??


-Spring Boot Resource : src/main/resources/static은 URL에서 Resource의 / 이다


-Spring Config :
	-WAS 설정 : WAS(tomcat)와 Spring의 연결 고리??
		-server.xml : 서버의 기본 설정, 포트, ssl, Context path 및 docBase 지정, (/tomcat/conf/..위치)
		-web.xml : 서블릿 배포 기술자(Deploment Descriptor)
			-서블릿의 배치, mine type 지정, welcom file 지정, error 페이지 지정, filter 지정, (/tomcat/conf/(전역설정) 또는 /Webroot/WEB-INF/..에 )
			-----------
			web.xml 파일에 spring 관련 context 파일의 위치를 알려준다. (서버 스타트시 같이 읽어 로딩한다.)
			-----------
			//tomcat은 서블릿 컨테이너를 제공한는 웹서버로 자신의 기본 servlet(Catalina) Container를 이용할수도 있고 spring등 다른 컨테이너를 사용할 수도 있다.
			//사용할 container를 web.xml을 통해 설정할수 있고 동시에 여러 servlet container를 사용할 수도 있다.
			//DispatcherServlet 은 spring MVC용 서블릿인가??
			<servlet>
				<servlet-name>sungil-Servlet</servlet-name>
				<servlet-class>org.springframework.web.servlet.DispatcherServlet</servlet-class>
				<init-param>
					<param-name>contextConfigLocation</param-name>
					<param-value>/WEB-INF/config/*-servlet.xml</param-value>
				</init-param>
			</servlet>

			<servlet-mapping> //.do 패턴은 sungil-Servlet 설정의 컨테이너에서 처리한다.
				<servlet-name>sungil-Servlet</servlet-name>
				<url-pattern>*.do</url-pattern>
			</servlet-mapping>
			-----------

		-context.xml : ??, (/tomcat/conf/..위치)


	-Spring 내부 설정 : 예전방식(Boot 이전), 요즘은 Anotation으로 거의 처리 함
		-application-context.xml : spring 설정과 관련한 가장 상위 configuration (여러 형태의 XXX-contex.xml 파일로 쪼갤수 있다. 하나로도 뭉칠수도 있다)
			-----------
			Datasource 관련 설정, apache의 BasicDataSource 클래스를 Bean으로 올리고 필요값들을 설정해 준다.
			-----------
			<bean id="dataSource" class="org.apache.commons.dbcp.BasicDataSource" destroy-method="close">
				<property name="driverClassName" value="com.mysql.jdbc.Driver"/>
				<property name="url" value="jdbc:mysql://주소/스키마"/>
				<property name="username" value="아이디"/>
				<property name="password" value="비밀번호"/>
			</bean>
			-----------

			-----------
			Mybatis 관련 설정, mybatis의 SqlSessionFactoryBean, SqlSessionTemplate을 Bean으로 올려서 스프링과의 연결 고리를 만들어 준다.
			-----------
			<bean id="sqlSession" class="org.mybatis.spring.SqlSessionFactoryBean">
				<property name="dataSource" ref="dataSource" />								<!--사용할 Datasource-->
				<property name="mapperLocations" value="classpath:/mapper/**/*_SQL.xml" /> 	<!--SQL문의 위치-->
			</bean>
			<bean id="sqlSessionTemplate" class="org.mybatis.spring.SqlSessionTemplate">
				<constructor-arg index="0" ref="sqlSession"/>
			</bean>
			-----------

			-----------
			modelAndVew 관련 설정, controller 가 이 방식의 modelAndVew 를 쓰겠다는건 어떻게 알려주지??
			-----------
			//InternalResourceViewResolver, view.BeanNameViewResolver, MappingJacksonJsonView, UrlBasedViewResolver (여러 형태의 spring 제공 뷰가 있다)
			<bean class="org.springframework.web.servlet.view.InternalResourceViewResolver">
				<property name="prefix" value="/WEB-INF/views/" />
				<property name="suffix" value=".jsp" />
			</bean>
			-----------

			-----------
			Interceptor 관련 설정, url 페턴과 implement 클래스를 지정해 준다.
			-----------
			<mvc:interceptors>
				<mvc:interceptor>
					<mvc:mapping path="/**"/>
					<bean id="loggerInterceptor" class="com.sungil.common.logger.LoggerInterceptor"></bean>
				</mvc:interceptor>
			</mvc:interceptors>
			-----------

			-----------
			Mybatis 를 이용한 DAO 구성한다
			-----------
			public class myDAO {
				@Autowired
				private SqlSessionTemplate sqlSessionTemplate;		//mybatis의 SqlSessionTemplate 주입

				result = sqlSessionTemplate.insert(queryId, params);		//insert
				result = sqlSessionTemplate.update(queryId, params);		//update
				result = sqlSessionTemplate.delete(queryId, params);		//delete
				result = sqlSessionTemplate.selectOne(queryId);				//여러 형태 select 들
				result = sqlSessionTemplate.selectOne(queryId, params);
				resultList = sqlSessionTemplate.selectList(queryId);
				resultList = sqlSessionTemplate.selectList(queryId,params);
			-----------
	-yml-importer : Spring Framework 의 EnvironmentPostProcessor Cycle에 특정 path 의 yml 기반으로 Configure Property 를 로드하는 기능을 하는 모듈


-Spring Boot Config : server.xml, web.xml, application.xml 등을 사용하지 않고 주로 어노테이션을 사용하여 설정을 정한다.(스프링은 전체 클레스의 어노테이션 스캔을 통해 해당 클레스가 어떤역할을 위한 클레스인지를 알수 있다.)
	-@Configuration(extend WebMvcConfigurerAdapter) : spring 설정과 관련한 클레스임을 알린다.
		-특히 WebMvcConfigurerAdapter 클래스를 상속 받아 server.xml, web.xml, application.xml 의 설정을 대신 할수 있다.


-Spring boot Filter(필터) : 스프링 필터 클레스를(여러형태가있음) 상속받아 @Component 어노테이션을 통해 만들수 있다.
	-필터가 적용되는 지점 : Filter, Interceptor, AOP (Filter는 Servlet 엔진(Servlet Context)에서 주관, Interceptor는 Spring(Application Context)에서 주관, 컨테이너 진입 전(후), AOP는 메소드 단위에 걸수 있다.
	-필터 생성 :
		-----------
		@Component
		@Order(1) //필터 적용 순서를 명시할 수 있다.
		public class MyFilter1 implements Filter {	//Spring은 여러 형태의 Filter 클레스를 제공한다. (Filter 클레스가 가장 기본)
			@Override
			public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException {
				HttpServletRequest req = (HttpServletRequest) request;
				//..하고싶은 코드 작성
				LOG.info("Starting a transaction for req : {}", req.getRequestURI()); //Spring 컨테이너로 진입 전 처리
				chain.doFilter(request, response); //다음필더 적용(모든 필터가 처리되면 실제 컨트롤로 로직까지 처리된 후 복귀함)
				//..하고싶은 코드 작성
				LOG.info("Committing a transaction for req : {}", req.getRequestURI()); //후 추리
			}
		}

		@Component
		@Order(2)
		public class MyFilter2 implements Filter {
		...
		-----------

	-필터 적용 :
		-----------
		@Configuration //config class 에서 AbstractFilterRegistrationBean을 상속받은 class를 bean으로 잡는것으로 처리 가능
		public class MyConfiguration extends WebMvcConfigurerAdapter
			...

			@Bean //MyFilter1을 특정 url(/users/*)에만 적용하고 싶은 경우
			public FilterRegistrationBean<MyFilter2> loggingFilter(){
				FilterRegistrationBean<MyFilter2> registrationBean = new FilterRegistrationBean<>();
				registrationBean.setFilter(new MyFilter2());
				registrationBean.addUrlPatterns("/users/*");
				return registrationBean;
			}

			@Bean //MyFilter2는 특정 url(/produc/*)에만 적용하고 싶은 경우
			public FilterRegistrationBean<MyFilter2> loggingFilter(){
				FilterRegistrationBean<MyFilter2> registrationBean = new FilterRegistrationBean<>();
				registrationBean.setFilter(new MyFilter2());
				registrationBean.addUrlPatterns("/produc/*");
				return registrationBean;
			}
		}
		-----------

-Spring boot Interceptor(인터셉터) : 스프링 인터셉터 클레스를(여러형태가있음) 상속받아 @Component 어노테이션을 통해 만들수 있다.
	-인터셉터 생성 :
		-----------
		@Component
		public class MyHandlerInterceptor1 extends HandlerInterceptorAdapter {
			@Override
			public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler){
				//controller 진입 직전, return true시 controller 진입
				return true // true=다음 interceptor chain을 실행한다.
			}

			@Override
			public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView){
				//controller 처리 후 view 진입 직전, modelAndView로 view로 데이터 전송 가능
			}

			@Override
			public void afterComplete(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex)
				//view 랜더링 이후
			}

			@Override
			public void afterConcurrentHandlingStarted(HttpServletRequest request, HttpServletResponse response, Object handler){
				//servlet 3.0에서 지원, postHandle, afterComplete 대신 역할
			}
		}
		-----------

	-인터셉터 적용 :
		-----------
		@Configuration //config class 에서 AbstractFilterRegistrationBean을 상속받은 addInterceptors(InterceptorRegistry registry)를 override 함
		public class MyConfiguration extends WebMvcConfigurerAdapter{
			@Autowired
			MyHandlerInterceptor1 myHandlerInterceptor1;

			@Autowired
			MyHandlerInterceptor2 MyHandlerInterceptor2

			@Autowired
			MyHandlerInterceptor3 MyHandlerInterceptor3
			...

			@Override
			public void addInterceptors(InterceptorRegistry registry) {
				//path 패턴의 같은 경우 등록 순서대로 적용됨
				registry.addInterceptor(myHandlerInterceptor1).addPathPatterns("/user/*.do");
				registry.addInterceptor(myHandlerInterceptor2).addPathPatterns("/user/*.do", "/produc/*.do"); //여러 path 등록 가능

				//path 패턴이 없는 경우 모든 경로에 적용됨
				registry.addInterceptor(myHandlerInterceptor2);
			}
		}
		-----------




-Annotation : https://gmlwjd9405.github.io/2018/12/02/spring-annotation-types.html
	-@SpringBootApplication : 완전한 하나의 web application으로 인식하게 한다.
		-----------
		@SpringBootApplication
		public class StartWebApplication {
			public static void main(String[] args) {
				SpringApplication.run(StartWebApplication.class, args); //이후 @Controller로 정의된 클레스를 찾아 동작
			}
		}
		-----------

	-@EnableWebMvc : DelegatingWebMvcConfiguration(Spring MVC 설정을 담당하는 객체)에게 MVC 새 설정 사항이 있음을 알린다. (보통 @Configuration, @Bean과 함께 사용)
	-@Bean : method-level의 어노테이션, 해당 메소드의 return 객체를 spring이 관리(인스턴스)한다.
		-개발자가 직접 만든 클래스가 아닌(직접 만들었다면 코드에 @Component를 붙였을거임)경우 사용됨(보통 @Configuration과 함께 사용)
	-@Configuration : 해당 클래스가 Spring에서 관리할 Bean(내가수정할수없는)을 정의했음을 알린다. @Bean 과 함께 사용하여 해당 메소드의 return 객채를 Spring의 Bean으로 올린다.
		-----------
		@Configuration
		public class ApplicationConfiguration {

		@Bean(name="demoService") //name을 넣지 않으면 Return Class명을 통해 찾는다.
		public DemoManager helloWorld(){
			return new DemoManagerImpl(); //Bean으로 올릴 Class를 리턴, 이 방식을 통해 Spring의 기본 Bean들을 수정거나 다른 클래스로 대치 할수 있다.(ex.ViewResolver)
		}
		-----------

		@AutoConfigureBefore(After)을 통해 해당 @Configuration 클래스가 읽히는 순서를 정할수 있다.
		-----------
		@Configuration
		@AutoConfigureBefore(Myclass.class) //해당 설정을 Myclass 보다 항상 먼저 읽는다.
		public class SpringAutoConfiguration {
		}

		AnnotationConfigApplicationContext를 통해 Spring에 올라온 Bean을 가져올수 있다.
		-----------
		public static void main(String[] args){
			ApplicationContext context = new AnnotationConfigApplicationContext(ApplicationConfiguration.class);
			DemoManager  myDemoManager = (DemoManager) context.getBean("demoService");
		}
		-----------

	-@Component : Spring에 의해 인스턴스가 관리 된다. 개발자가 직접 만든 클레스에 적용됨
		-@Controller : 해당 클래스가 Controller 임을 알림
		-@Service : 해당 클래스가 Service 임을 알림 (spring이 DB transaction을 지원)
		-@Repository : 해당 글래스가 DAO 임을 알림, (spring이 DB Exception Translation을 지원)

	-@RequestMapping
		-Class Level
			-----------
			@RequestMapping("/home")
			public class HomeController {
			-----------

		-Handler Level(Method)
			-----------
			@RequestMapping(value = "/employees", method = RequestMethod.POST) //method 적시를 않하면 get, post.. 모두
			public String addEmployee(Employee employee) {
			-----------

	-@GetMapping("/home") : http://localhost:8080/home?index=1
		-@RequestParam
			-----------
			@GetMapping("/home")
			public String show(@RequestParam("index") int index) {
			-----------
			@GetMapping("/user/{userId}/invoices")
			public List<Invoice> listUsersInvoices(@PathVariable("userId") int user,@RequestParam(value = "date", required = false) Date dateOrNull) {
			-----------

		-@ModelAttribute : @RequestParam의 값들을 Object로 매핑해줌
			-----------
			@RequestMapping(value="/add" method = RequestMethod.POST)
			public String add(@ModelAttribute Myinfo myInfo, BindingResult result, Model model){ //Reqest param 값을 Myinfo로 매핑요청, BindingResult=매핑 유효성 체크??, Model=view로 전달할 데이터를 담을 Object??
				...
				return "redirect:/myInfo"; //return 되는 스트링값을 viewResolver가 받아 해당 처리
			}
			-----------


	-@PostMapping("/index/{idx}") : http post만 처리 가능
		-@pathVariable("idx") :
			-----------
			@PostMapping("/index/{idx}")
			public boolean deletePost(@PathVariable("idx") int postNum) {
			-----------

	-@ResponseBody : 메핑 메소드의 리턴 값을(class) json 문자열 형태로 반환한다.
	-@RequestBody : http post 요청만 처리, request body의 값을 object(messageConverter)로 읽기 위해 사용 ??

	-@RestController : @Controller + @ResponseBody
		-@ResponseBody : method의 반환 결과(class)를 jason 형태로 반환
		-@Controller 와 @RestController 의 차이 :
			-@Controller : API 또는 view(웹화면)을 처리, 주로 view 리턴이 주목적
			-@RestController : view가 필요없는 API만 지원하는 경우 사용

	-@required : Boot에서 사용??, bean property xml 설정시 해당 클래스가 주입 받아야 하는 필수 class를 정의 한다.
	-@Autowired : Spring에게 해당 Bean의 주입을 요청 (생성자 (@AllArgsConstructor 사용) -> 권장방식)??
		-@Qualifier : Boot에서 사용??, @Autowired를 통해 주입 요청시 동일한 이름의 클래스가 두개 존재할 경우 특정 class를 지목하기 위해 사용, Qualifier값은 xml에 적용
			-----------
			@Autowired
			@Qualifier(value="noty") //-->"noty" 값은 bean을 설정하는 xml에 정의 되었었음, boot에서 사용??
			private Boy student;
			-----------
	-@Inject : @Autowired와 동일??
	-@Resource : @Autowired와 같이 Bean의 주입을 요청, (표준 어노테이션으로 특정 framework에 종속적이 않게 하기위해 권장함)

	-@Transactional : Exception 발생시 모든 DB 작업을 롤백하기 위해 사용 (비즈니스 로직과 DB 로직이 있는 Service 모듈에 보통 적용)

	-@Value("${welcome.message}") : application.properties(classpath 내부 존재, 보통 resource 폴더)의 값을 초기값으로 지정함
		-----------
		@Value("${welcome.message}")
		private String message;
		-----------

	-@PropertySource : Property 파일을 Environment로 로딩 (yml 파일은 읽을수 없다)
		-----------
		@PropertySource("classpath:/setting-dev.properties") //동일한 키값이 있는경우 override 됨
		//@PropertySource("classpath:/setting-${spring.profiles.active:default}.properties") //환경에 따라 적용 가능(변수를 사용하여)
		//@PropertySource(value = {"classpath:/properties/example.properties","file:/data/properties/example.properties"}) 보안상의 이유로 class path 외부에 위치 시킬수 있음
		public class MyClass {

			@Resource
			private Environment environment; //property가 자동으로 매핑 됨

			public void myMethod(){
				logger.info("my.value : {}" + environment.getProperty("my.value"));
			}
		-----------


	-Spring AOP(Aspect Oriented Programming) : 주로 공통작업을 처리하기 위해 (인증, 로깅 등)
		-@EnableAspectJAutoProxy : ??
		-@Aspect : 해당 클래스가 Aspect 클래스 임을 선언
		-@PointCut : ??
		-@Before : 어드바이스 타겟 메소드가 호출되기 전에 어드바이스 기능을 수행
		-@After : 타겟 메소드의 결과에 관계없이(즉 성공, 예외 관계없이) 타겟 메소드가 완료 되면 어드바이스 기능을 수행
		-@Around : 메소드 실행 전후, 어드바이스가 타겟 메소드를 감싸서 타겟 메소드 호출전과 후에 어드바이스 기능을 수행
		-@AfterReturning : 정상적 반환 이후, 타겟 메소드가 성공적으로 결과값을 반환 후에 어드바이스 기능을 수행
		-@AfterThrowing : 예외 발생 이후, 타겟 메소드가 수행 중 예외를 던지게 되면 어드바이스 기능을 수행

			-----------
			@Component //Bean으로 등록
			@Aspect    //해당 클래스가 Aspect 임을 선언
			public class PerfAspect {
				//어떤 클래스의 어떤 시점에 실행될지를 정함
				@Around("execution(* com.saelobi..*.EventService.*(..))") //특정 패키지 밑에 특정 클래스
				---
				@Around("bean(simpleEventService)") // 특정 Bean이름으로 지명 할수 있다.
				---
				@Around("@annotation(PerLogging)") //특정 어노테이션이 붙은 클래스
				---
				public Object logPerf(ProceedingJoinPoint pjp) throws Throwable{
					long begin = System.currentTimeMillis();
					Object retVal = pjp.proceed(); //---->실제 클라스가 실행될 위치
					System.out.println(System.currentTimeMillis() - begin);
					return retVal;
				}
			}
			-----------
			//어노테이션 생성
			@Target(ElementType.METHOD)
			@Retention(RetentionPolicy.CLASS)
				public @interface PerLogging {
			}
			-----------
			//생성된 어노테이션을 사용
			@Component
			public class SimpleEventService implements EventService {

				@PerLogging //특정 메소드에 생성한 어노테이션을 붙인다.(어노테이션 이름으로 Aspect를 걸수 있다)
				@Override
				public void createEvent() {
					System.out.println("Created an event");
				}

				@Override
				public void publishEvent() {
					System.out.println("Published an event");
				}

				@PerLogging
				@Override
				public void deleteEvent() {
					System.out.println("Delete an event");
				}
			}
			-----------

	-JPA
		-@Entity : DB의 테이블과 매칭될 클래스임을 선언. (DTO는 컨트롤러에서 사용되는 객체로 주로 request, response 데이터를 담는다, Entity는 DB 고유의 상태를 가져야 함으로 둘을 분리하는것이 좋다.)
		-@Table : @Table(name = "USER"), 엔티티 클래서에 매핑할 테이블을 나타낸다.
		-@ID : 테이블의 PK 필드를 나타낸다.
		-@GeneratedValue : PK의 생성규칙 (엔티티의 PK는 Long 타입의 Auto_increment를 추천)
		-@Column : @Column(name="username"), 테이블의 컬럼과 매핑됨을 선언한다. 컬럼명이 같은경우 자동 매핑됨

	-@Vaild : import javax.validation.Valid
		-@Size(max=10, min=2, message=”errMsg”) : ??
		-@Email(message=”errMsg”) : ??
		-@NotEmpty(message=”errMsg”) : ??

	-@Configuration
		-@EnableWebSecurity
		-@SpringBootApplication
		-@EnableWebMvc
		-@RestControllerAdvice
		-@ExceptionHandler
		-@ResponseStatus

	-Lombok
		-@NoArgsConstructor : 기본 생성자를 추가해 주고 생성자의 접근 권한을 protected로 제한한다. (Entity 클래스를 new해서 생성하는것은 막고 JPA에 생성하는 것은 허용하기 위해)??
		-@AllArgsConstructor : 모든 필드 값을 파라미터로 받는 생성자를 추가한다.
		-@requiredArgsConstructor : final 이나 @NonNull인 필드값만 파라미티터로 받는 생성자를 추가(final이 최초 할당되면 이후 변경 불가)
		-@Getter : 클래스 내 모든 필드의 Getter() 생성
		-@Setter : 클래스 내 모든 필드의 Setter() 생성규칙
		-@ToString : @ToString(Exclude="password"), toString 메소드를 생성하며 특정 필드를 제외 할수 있다.
		-@EqualsAndHashCod : @EqualsAndHashCode(callSuper = true), 클래스의 equals() 와 HashCode()를 생성한다. callSuper = false 시 해당 메소드를 구성할때 상속받은 클래스의 정보는 활용하지 않는다.
		-@Builder : 생성자와 유사하게 클래스 생성 시점에 값을 채워주는 역할을 한다. (어떤 필드에 어떤값을 채울지 명확히 인지 가능 ??)
		-@Data : Lombok 에서 제공하는 모든 필드 관련 코드를 생성해 준다.

	-Json
		-@JsonManagedReference : ??
		-@JsonBackReference : ??
		-@JsonProperty : ??
		-@JsonIgnore : ??

	-Jackson Property Inclusion Annotation
		-@JsonIgnoreProperties : 무시할 속성이나 속성 목록을 표시할 때 사용한다. ??
		-@JsonIgnore : 필드 레벨에서 무시할 속성을 표시할 때 사용한다. ??
		-@JsonIgnoreType : ??
		-@JsonInclude : 어노테이션 속성을 제외할 때 사용한다. @JsonInclude(JsonInclude.Include.NON_NULL)NON_NULL 사용 시 name이 null인 경우에 제외된다. ??
		-@JsonAutoDetect : @JsonAutoDetect(fieldVisibility = JsonAutoDetect.Visibility.ANY) ??

	-@ConfigurationProperties : Config 클레스를 만들면서 properties 파일을 참조하여 초기값을 셋팅할수 있게함(yml 파일도 가능)
		-----------
		@Configuration //옵션?
		@PropertySource("classpath:configprops.properties") //위치 지정이 없다면 기본값으로 클레스 페스내 application.properties 을 로딩
		@ConfigurationProperties(prefix = "service.mydb") //prefix는 옵션, "service.mydb"만 써도 됨
		public class MyDataSource {
			private String dbUrl;
			private int dbPort;
			// standard getters and setters
		-----------

	-@EnableConfigurationProperties : 특정 Bean을 특정 property 값으로 초기화 해서 생성 할수 있다.
		-----------
		@SpringBootApplication //메인 클레스 생성 시점에서 적용할 수 있다.
		@EnableConfigurationProperties(MyDataSource.class) //MyDataSource클레스를 property 값으로 초기화 하여 Bean으로 로딩한다.
		public class MainApplication {
		-----------
		@Configuration //Configuration 클레스 생성 시점에서 적용할 수 있다.
		@EnableConfigurationProperties(MyDataSource.class)
		public class MainApplication {


		//실제 클래스에 @ConfigurationProperties가 적용되어 있어야 하낟.
		@ConfigurationProperties("service.mydb")
		public class MyDataSource {
		-----------

	-@ControllerAdvice : ???
	-@ExceptionHandler : ???


	-기타 어노테이션
		-@EnableJpaAuditing : JPA Audditing을 활성화 한다. ??
		-@MappedSuperclass : JPA Entity 클래스들이 BaseTimeEntity을 상속할 경우 필드들(createdDate, modifiedDate)도 컬럼으로 인식하도록 한다 ??
		-@EntityListeners(AuditingEntityListener.class) : BaseTimeEntity 클래스에 Auditing 기능을 포함한다.
		-@CreatedDate : Entity가 생성되어 저장될 때 시간이 자동으로 저장된다.
		-@LastModifiedDate : 조회한 Entity의 값을 변경할 때 시간이 자동으로 저장된다.

		-@SuppressWarnings : warn 발생을 막음(IDE에서)


	-Spring Boot Profile :  dev, test, prod 등으로 구동 환경을 세분화하여 서비스를 관리한다. 이런 식별 키워드를 바로 Profile이라고 부른다
		-Profile 설정 값에 따라 config 및 클래스 로딩을 선택적으로 가능 (spring boot에서 config 파일일 application-xxx.yml 형태의 파일이 클레스 페스내에 있을때 자동 인식됨)
		-프로파일이 명시적으로 설정 되지 않은 경우  : local 또는 default 키워드로 처리 됨

		-설정 방법 :
			-환경 변수로 설정
				-윈도우 시스템 환경 변수:
					-변수 이름: SPRING_PROFILES_ACTIVE
					-변수 값 : prd, stg, ...

				-리눅스 환경 파일로 설정 :
					-환경 파일 : vi $HOME/.bashrc
					-설정 : export SPRING_PROFILES_ACTIVE=prd ...

			-실행시 파라미터 : -D옵션(시스템의 property 값을 설정한다)
				- java -Dspring.profiles.active=dev -jar project-이름.jar

			-코드상으로 저정 :
				-System.setProperty("spring.profiles.active", "dev"); //프로파일 자체를 지정
				-System.setProperty("spring.config.location", "classpath:/application-dev.yml");
					-원래는 프로파일에 의해 config가 자동 로드 되지만 특정 config(property)를 지정 하고 싶을때 설정 가능 (이경우 프로파일이 변경되는 것은 아님)


				-테스트시 지정?? : 테스트 클레스에 @ActiveProfiles(value={"develop"}) 직접 지정 가능

		-특정 프로파일 환경(dev) 에서 application-dev.yml 에 특정 값이 없는 경우 기본?? config 파일이 되는 application.yml을 참조하여 가져 온다.
		-사용 예시 : 해당 Configuration 클레스는 Profile이 develop 일때만 적용되며 읽어올 property 파일은 클레스페스 내 develop/ 디렉토리것을 읽어라
			-----------
			@Configuration
			@Profile(value="develop")
			@PropertySource({"classpath:develop/application.properties"})
			public class ProfileDevelop {
			}
			-----------

-ObjectMapper : json 데이터를 변형하기 위한 객체 (json String -> boject, object -> json String)
	-----------
	//Object to JSON in file, user 객체로 부터 json String 파일을 생성
	mapper.writeValue(new File("c:\\user.json"), user);

	//Object to JSON in String, user 객체를 json 스트링으로 변환
	String jsonInString = mapper.writeValueAsString(user);

	//JSON from file to Object, json String 파일을 읽어 user 객체로 변환
	User user = mapper.readValue(new File("c:\\user.json"), User.class);

	//JSON from String to Object, json String으로 부터 user 객체 생성
	User user = mapper.readValue(jsonInString, User.class);
	-----------


-MessageSource : 다국어 처리 메커니즘을 지원해주는 class
	-메세지 파일 형식 : [파일이름]_[언어]_[국가].properties, class path내 위치, (요건의 맞는 파일을 찾을수 없는 경우 message.properties를 기본값으로 한다.)
	-----------
	# messages_en_US.properties
	greeting={0} and {1} are friends.

	# messages_ko_KR.properties
	greeting={0} 와 {1} 는 친구이다.
	-----------

	@Autowired
	MessageSource messageSource;

	void messageCall(){
		System.out.println(messageSource.getMessage("greeting", new String[]{"Tom", "Jerry"}, Locale.KOREA));
	}
	-----------

	//자동 reload 필요시 ReloadableResourceBundleMessageSource 사용
	ReloadableResourceBundleMessageSource messageSource = new ReloadableResourceBundleMessageSource();
	messageSource.setBasename("classpath:/messages");
	messageSource.setDefaultEncoding("UTF-8");
	messageSource.setCacheSeconds(10);
	return messageSource;
	-----------

-Spring Test :
	-테스트 코드 위치 : src/test/java/
		-----------
		@RunWith(SpringRunner.class)
		@SpringBootTest(webEnvironment = RANDOM_PORT)
		public class WebControllerTest {
			@Autowired
			private TestRestTemplate restTemplate;

			@Test
			public void 메인페이지_로딩() {
				//url "/"을 호출
				String body = this.restTemplate.getForObject("/", String.class);
				assertThat(body).contains("xxx"); //본문에 "xxx" 문자열이 있으면 테스트 통과
			}
		-----------


-Spring security

-Spring 주요 개념
	-Spring IOC(inversion of control) : 나늘 누가 생성해서 언제 쓸찌는 모른다.. 그것을 다른 주체(Spring container)에게 맞기고 나는 부품으로써의 구성을 해두면 된다.
		-DL(dependency lookup) : 컨테이너가 제공하는 api를 이용하여 컨테이너가 관린하는 been을 검색하는것(직접 생성하지 않고 검색하여 이용하는 것???)
		-DI(dependency injection) : 각 클레스를 생성할때 자신에게 필요한 다른 클레스를 컨테이너에게 알려주면 컨테이너가 알아서 주입해 주는것(개발 편리성과 더블어 뭔가 더 효율적인 관리를 하나???)

	-Spring POJO(plain Old Java Object) : getter/settr를 가진 평범한 object로 spring은 이러한 단순한 형태의 pojo 지향적 설계를 오히려 지향한다. (복잡한 플로우는 컨테이너가 알아서 해줄꺼야???)
	-Spring AOP(Aspect Oriented programming) : 핵심 기능(실제업무)과 공통 공통기능(늘쌍있는 보안, 로그인 등..)을 구분해서 구분해서 개발하자는 주의(OOP의 개선??), 공통기능은 많은 부분 컨테이너에 위임함
	-Spring MVC 흐름 개요 : Client->Servlet(Controller)->(DTO)->Service(비즈니스계층)->(DTO)->DAO(퍼시스턴스계층)->DB ->-역순환->..->Servlet(Controller)->View(jsp, 프리젠테이션계층)
		-Model : 데이터 처리를 담당하는 부분 (Service와 DAO영역), model에서는 view와 controller의 어떠한 정보도 가지지 않아야 함
			-주의점 : Service영역은 불필요한 http 통신을 하지 말아야 하며, request, response등을 파람으로 받지 않아야 한다. 또한 view에 종속적인 코드가 없어야 한다.(view의 변경과 무관해야 함)
		-View : 사용자 interface를 담당하는 보여지는 부분, view는 controller만 연관성을 갖는다.
		-Controller : view에서 받은 요청을 가공하여 model에 넘겨주는 역할, 모델로 받은 결과를 view로 넘겨주는 역할, 모델에서 부터 올라오는 에러등에 대한 처리

-Spring boot 환경 설정 : 
	-application-xxx.yml : 기본이 되는 yml 파일로 해당 프로파일에서 특정 프로퍼티 벨류를 못 찾을 경우 application.yml 파일에서 찾게 되있다. (resources 하위에 위치)
		-ex : env 가 stg 일경우 
			-application-stg.yml에서 환경 프로퍼티를 찾게 되있음 만약 해당 yml에서 찾을 수 없는 값이 있는 경우 기본 파일인 application.yml 에서 찾게 됨
		
		-spring boot과 관련한 여러 설정이 가능
			-서버 설정 : yml 파일에 tab 기준의 인턴데이션으로 작성해야 한다.
			-----------
				server:
					port: 8080 //서버포트 지정
					context-path: /kr/ko //서버 context path 지정
			-----------
			
---

[DB]
-DBMS :
	-RDB :
		-Mysql :
		-Maria :

	-NoSQL DB : Not Only SQL
		-MongoDB : MongoDB is a cross-platform document-oriented database program. Classified as a NoSQL database program, MongoDB uses JSON-like documents with schema.
			-개요 :
				-명칭 :
					-Database : Database는 Collection들의 물리적인 컨테이너입니다. 각 Database는 파일시스템에 여러파일들로 저장됩니다.
					-Collection : 테이블과 유사한 개념으로 Collection 내부에 Document이 위치하고 있다.
					-Document : Record와 유사한 개념, Jason 형태, 같은 Collection(테이블)에 있는 Document들이 서로 다른 형태를 갖을 수 있다.
					-embeded Document : { a:'a', b:'b', c:[{c1:'c1', c2:'c2'..},{}..]} 또는 { a:'a', b:'b', c:['c1', 'c2'..]}

				-장점 :
					-정해진 스키마가 없으며 같은 Collection 안에 서로다른 스키마의 Document가 있을수 있다 (데이터의 형태를 매우 유연하게 가져갈수 있다, 그래서 더 모호한 느낌도 있음)
					-복잡한 JOIN이 없으며 단일 각 Collection 의 구조(의미)가 뚜렷하다.
					-Deep Query ability 를 통해 SQL만큼의 쿼리 성능을 제공한다.
					-application의 Object를 DB에 적용할때 Conversion/Mapping이 불필요하다. (DB 자체가 json 구조임)

				-ubuntu install : $ sudo apt-get update, $ sudo apt-get install -y mongodb-org, $ sudo service mongod start
					-log : $ cat /var/log/mongodb/mongod.log1
					-port : 27017(default) /etc/mongod.conf
					-connect : $ mongo (터미널을 통해 접속)

				-schema 고려 사항 : RDB 상에서 join 할 엔티티들을 하나의 엔티티로 구성한다.
					-read할때 collection간 join을 하려하지 말고 embeded document를 이용하여 하나의 document로 구성한다.(생성때 join 의 형태로 구성)
					-collection간 join은 하지 않는다는 것을 전제로 한다.


			-쿼리 :
				-DB 관리
					-use mydbname :  해당 이름의 db로 switch 한다. 해당 이름의 db가 없는 경우 생성하고 스위치 한다.
					-db : 현재 사용중인 db 이름을 확인 한다.
					-show dbs : db 목록을 확인 한다. (db에 하나 이상의 collection이 있어야 목록에 보임)
					-db.dropDatabase(); : 사용중인(switched) db를 삭제한다.

				-Collection	관리
					-db.createCollection("myCollectionName") : myCollectionName으로 collection 생성
						-옵션 : collection 생성시 옵션을 줄수도 있다. (최대용량적용여부(롤링됨), 자동인덱스필드추가여부, 최대용량적용시사이즈(byte), document최대저장갯수)
							-----------
							db.createCollection("book", {capped: true, autoIndex: true, size: 6142800, max: 10000})
							-----------

					-document를 만들면서 collection이 없으면 collection도 함께 생성됨
						-----------
						db.book.insert({"name": "MongoDB Tutorial", "author": "velopert"}); : book이란 collection이 없다면 document 입력과 동시에 생성됨
						-----------

					-show collections : 생성된 collection 목록 확인
					-db.collectionName.drop() : 현재 switch 된 DB에서 collectionName을 제거 한다.

				-Document 관리
					-insert : db.collection.insert([{document},..] or {document});
						-db.books.insert({"name": "NodeJS Guide", "author": "Velopert"}) : book collection에 하나의 document 추가
						-db.books.insert([{"name": "Book1", "author": "Velopert"}, {"name": "Book2", "author": "Velopert"}]); : 동시에 2개 추가

					-find : db.book.find({query 검색조건}, {projection 보여질 필드}).sort({}).skip().limit().pretty()
						-db.books.find().pretty() : books collection 확인(모든 document의 모든 필드가 select 됨), .pretty()는 보기 좋게 보여줌
						-db.books.find({"name": "mybook"}) : name값 mybook인 document만 확인
						-db.books.find({"likes": {$lte:30}}).pretty() : 좋아요 수가 30 이하인 것만 조회. (less than or equal)
							-비교연산 : $eq, $gt, $gte, $lt, $lte, $ne, $in, $nin
								-db.books.find({"writer":{$in:["Alpha", "Bravo"]}}).pretty()

							-논리연산 : $or, $and, $not, $nor
								-db.book.find({$or:[{"title":"article01"}, {"writer":"Alpha"}]})

							-정규식 : i대소문자 무시, m정규식에서 anchor(^)를 사용할 때 값에\n이 있다면 무력화, x	정규식 안에있는 whitespace를 모두 무시, s	dot(.)사용 할떄 \n을 포함해서 매치
								-db.book.find({"title":/article0[1-2]/}) : /정규식/

							-$where 연산자 : javascript expression 을 사용 할 수 있습니다.
								-db.book.find({$where:"this.comments.length == 0"})

							-$elemMatch 연산자 : Embedded Document가 배열 형태이고 그 값을 조건으로 할때
								-{.., comments:[{name, ..},{}]} : comment가 여러개(배열)일수 있는데.. comment 작성자명이 Charlie 인것 검색
									-db.book.find({"comments":{$elemMatch:{"name":"Charlie"}}})

							-Embedded Document가 배열 형태가 아닐 경우
								-{.., comment:{name, ..}} : comment가 배열의 형태는 아닌경우
									-db.book.find({"comment.name":"Charlie"})

							-Embedded Document가 값으로만 된 배열인 경우
								-{.., comments:["", ""]}} : comment가 값으로만 구성된 배열인 경우
									-db.book.find({"comment":"Charlie"})

						-db.articles.find({"comments":{$elemMatch: { "name": "Charlie" }}}, {"title":true, "comments.name":true, "comments.message":true})
							-댖글 배열에서 작성자가 Charlie인 사람이 들어 있는 document에서 책의 title과 댖글 배열에서 이름과, 내용을 보여준다.(여러 사람 댖글이 다 나온다)

						-db.book.find({"comments":{$elemMatch:{"name":"Charlie"}}}, {"title":true, "comments":{$elemMatch:{"name":"Charlie"}}, "comments.name": true, "comments.message":true})
							-댖글 배열에서 작성자가 Charlie인 사람이 들어 있는 document에서 책의 title과 댖글 배열에서 오직 이름이 Charlie인 사람의 댖글의 이름과, 내용을 보여준다.(Charlie인 사람의 댖글만 나옴)

						-db.book.find().sort({"_id":1}) : id 값으로 정렬, 1=오름, -1=내림
						-db.book.find().sort({"amount":1, "_id":-1}), 2가지 정렬 조건으로
						-db.book.find().limit(3) : 출력 갯수를 3개로 제한
						-db.book.find().skip(2) : 시작부분의 2개의 Document 제거 (paging 처리등에 사용)
							-db.book.find().sort({"_id":-1}).skip((page-1)*2).limit(2); :2개씩 페이징 예

					-update : db.collection.update({query}, {update}, {upsert:true}, {multi:true}, {writeConcern:true}})
						-db.people.update({name:"Abet"}, {$set:{age:20}}) : Abet의 나이를 20으로 변경
						-db.people.update({name:"Betty"}, {"name":"Betty 2nd", age:1}) : Betty의 document의 field 값을 바꾸는 것이 아니라 전체 document를 replace(기존값은 모두 사라지고 현재 값으로 샛팅)
						-db.people.update({name:"David"}, {$unset:{score:1}}) : David의 score필드를 삭제(값이 아니라 필드 자체를 제거함, 1의 이미는 ??)
						-db.people.update({name:"Elly"}, {name:"Elly", age:17}, {upsert:true}) : Elly의 존재하면 document를 replace, 없으면 insert
						-db.people.update({age:{$lte:20}}, {$set:{score:10}}, {multi:true}) : age가 20 이하인 여러 document를 모두 update 함
						-db.people.update({name:"Charlie"}, {$push:{skills:"angularjs"}}) : Charlie의 embeded document[a,..] 형태에 값 추가
						-db.people.update({name:"Charlie"}, {$push:{skills:{$each:["c++", "java"], $sort:1}}}) : Charlie의 embeded document[a,..] 형태에 여러 값을 넣고 정렬하여 저장함
						-db.people.update({name:"Charlie"}, {$pull:{skills:"mongodb"}}) : Charlie의 embeded document[a,..] 형태에 값 제거
						-db.people.update({name:"Charlie"}, {$pull:{skills:{$in:["angularjs", "java"]}}}) : Charlie의 embeded document[a,..] 형태에 여러 값 제거

					-index : db.COLLECTION.createIndex({인덱스할필드:1,..}, {PROPERTY:true}) : 인덱스의 속성(PROPERTY)
						-db.report.createIndex({score:1}) : score값에 대한 오름차순 인덱스 생성
						-db.report.createIndex({age:1, score:-1}) : age와 score에 대한 복합 인덱스 생성
						-db.userinfo.createIndex({email:1}, {unique:true}) : email 필드를 인덱스로 만들며 해당 값은 중복될수 없다.
						-db.userinfo.createIndex({firstName:1, lastName:1}, {unique:true}) : 복합 인덱스를 만들고 해당 값(쌍)은 중복될수 없다.
						-db.store.createIndex({name:1}, {partialFilterExpression:{visitors:{$gt:1000}}}) : name으로 인덱스를 만드는데 visitors값이 1000보다 큰경우의 document만 적용(속도와 저장공간 절약가능)
						-db.notifications.createIndex({"notifiedDate":1}, {expireAfterSeconds:3600}) : 3600초 후에 해당 인덱스 제거??

						-db.COLLECTION.getIndexes() : 해당 COLLECTION의 인덱스 조회
						-db.COLLECTION.dropIndex({KEY:1}) : 해당 COLLECTION의 해당 인덱스 제거



-Frameworks :
	-JDBC : Java Database Connectivity, DB 접속 및 사용을 위한 java interface (개발자의 많은 코딩이 필요함)
	-Datasource : DB 접속을 위한 정보 set(url, userId, password..) 갖는 클래스 (그 정보 자체를 말하기도 한다.)

	-Persistence Framework : 미들웨어 소프트웨어의 성격으로 프로그램과 DB의(보통RDB) 연결 레이어로 작동한다.
		-Mybatis : 개발자의 코드와 sql들을 연결하고 결과 매핑을 도와주는 Persistence Framework, 일반적으로 스프링에서 Dao와 DB를 연결하는 하나의 방식으로 사용됨, JDBC로 처리할때의 많은 부분을 대신 처리해줌.
			-dependency : mybatis dependency를 추가해줘야 함(mybatis-x.x.jar)

		-Ibatis : ?

	-Hibernate : ??




[Logging]
-Logging : println를 이용 한다면 개발 이후에 다 지울꺼야? 보고 실을때도 있고 안보고 싶을때는??, 오픈소스에서 모든사람이 쓰는 방식이 다를텐데? 성능, 파일저장 등의 이슈도 있다.

-java.util.logging : logging을 위한 자바 기본 로깅 클래스, 실제 프로젝트에서는 잘 활용하지 않음(더 좋은걸 사용함)

-Logging Framework : 보통 로그를 처리하는 abstraction layer(Logger)와 실제 표현하는 implement부분(Appender)으로 구분되며 이러한 implement를 바인드 하여 사용한다. 로그 레벨 및 주기등의 설정을 appenader에 정의.
	-Logger : 코드상에서 로그를 발생시키는 주체, error, warn, info 다양한 로그를 발생시킨다. 발생한 로그는 실제 처리하는 Appender 클레스로 전달된다. Appender 클래스를 지정하지 않으면 Console로 처리됨
	-Appender : 발생된 로그를 처리(어디로, 어떻게 보낼지)하기 위한 주체, Logback, Log4j등 다양한 Logging Framewor에서 다양한 Appender를 제공한다. (Logback, Log4j를 쓰는 이유임)
	-log level : FATAL(사용안함), ERROR, WARN, INFO, DEBUG, TRACE

	-SLF4J : SLF4J(Simple Logging Facade for Java) is basically an abstraction layer (not implement), parameterized logging 지원
		-로그 처리를 위한 중간 layer로써의 표준같은(?) 역할을 함, logback-classic을 기본 implement로 가지고 있어 별도의 logging implement를 바인딩하지 않고도 사용할 수 있음(그럴경우 console에 찍힘)
		-logback 이나 log4j 등을 바인딩 하여 사용할 수 있음

			-----------
			import org.slf4j.Logger;
			import org.slf4j.LoggerFactory;
			-----------
			//로그의 시작인 LoggerFactory는 항상 slf4j에서 생성(??),
			Logger logger = LoggerFactory.getLogger(MyClass.class); //MyClass.class의 의미는 logger의 name을 "com.sungil.MyClass"로 set, 실제 스트링 값으로 입력해도 무관함.
			String myName = "sungil";
			int myAge = 40;

				logger.info("Name : {}, age : {}.", myName, myAge); // parameterized logging, ({}에 어떤 object 도 대입 가능 함), +string 보다 빠르다. 로그 활용성이 좋아짐.
			} catch (Exception e) {
				logger.info("Name : {}, age : {}.", myName, myAge, e); //excepton 에 대해서는 대응되는 {} 가 없어도 적용 가능.
			}
			-----------
			14:21:49.500 [main]  INFO com.sungil.MyClass - Name : sungil, age : 40.
			   호출시간     호출스레드  로그레벨      호출클래스             로깅내용(파라미터 값)
			-----------

		-Logger Context의 구조 : LoggerFactory.getLogger("com.sungil.MyClass.class")를 통해 Logger의 name을 셋팅하고 그 이름의 "."을 기준으로 Logger Context를 hierarchy 하게 갖음.
			-----------
			-logger1=LoggerFactory.getLogger("a"), logger2=LoggerFactory.getLogger("a.b"), logger3=LoggerFactory.getLogger("c")
			-logger2는 logger1의 하위 context를 갖음, logger1.setLevel(Level.INFO) 시 logger2 에도 적용됨. logger3는 적용되지 않음 (특별히 이걸 뭐에 쓸까??)
			-----------



	-Logback : 크게 3개로 구분되어짐 (https://www.baeldung.com/logback#example)
		-logback-core : slf4j 처럼 abstraction layer의 역할을 함
		-logback-classic : slf4j에 native 되어 있음, slf4j, log4j등과 함께 사용될 수 있다.
		-logback-access : tomcat, jetty등 servlet container와 access log를 수집하는 기능을 함(잘 모르겠음??)

			-----------
			import org.slf4j.LoggerFactory;
			importch.qos.logback.classic.Logger
			import ch.qos.logback.classic.LoggerContext;
			import ch.qos.logback.core.util.StatusPrinter;
			-----------
			qos.logback.classic.Logger logger = (qos.logback.classic.Logger)LoggerFactory.getLogger(MyClass.class); //logback Logger를 사용하기로 함
			logger.info("Name : {}, age : {}.", "sungil", 40); //기본 사용법은 slf4j와 거의 동일(제품마다 고유 메소드가 제공됨 ex=setLevel)

			LoggerContext lc = (LoggerContext) LoggerFactory.getILoggerFactory(); //logback의 configuration 상태를 확인.(logback은 클래스페스 내부를 모두 scan해서 자신의 설정파일을 스스로 찾음)
			StatusPrinter.print(lc);
			-----------
			15:10:25.985 [main] INFO com.sungil.MyClass - Name : sungil, age : 40.
			15:10:25,936 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback-test.xml]
			15:10:25,937 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback.groovy]
			15:10:25,938 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback.xml]
			15:10:25,947 |-INFO in ch.qos.logback.classic.BasicConfigurator@2437c6dc - Setting up default configuration.
			//위의 설정파일을 통해 ConsoleAppender 및 여러 형태의 Appender destination(console, files, Syslog, TCP Sockets, JMS and many more)을 설정 할수 있다.

		-LogBack Configuration file
			-----------
			logback.xml (classpath 어느 위치에 있어도 됨), logback-test.xml??, logback-spring.xml, logback.groovy??
			-----------
			<configuration debug="false" scan="fase" scanPeriod="15"> <!-- 디버깅용 으로 모든 정보가 다 보여지도록 일괄 설정됨 , 설정 파일을 15초마다 재스캔하여 로드함 -->
				<statusListener class="ch.qos.logback.core.status.OnConsoleStatusListener" /> <!--설정된 패키지별 Logback 설정 정보(level..) 및 에러, 경고를 시작때 알려 준다. -->

				<property name="LOG_DIR" value="C:/TESTLOG/" /> <!-- 내부 변수 설정 -->
				<property name="LOG_FILE_NAME" value="myLog" />
				<property name="LOG_FILE_NAME2" value="myLog2" />

				<!-- appender1 : console로 찍히는 기본 -->
				<appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender">
					<encoder>
						<pattern>
							%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n
						</pattern>
					</encoder>
				</appender>

				<!-- appender2 : 파일로 찍히며, 파일명 설정 -->
				<appender name="FILE1" class="ch.qos.logback.core.FileAppender">
					<file>${LOG_DIR}/${LOG_FILE_NAME}.log</file>
					<append>true</append>
					<encoder>
						<pattern>%-4relative [%thread] %-5level %logger{35} - %msg%n</pattern>
					</encoder>
				</appender>

				<!-- appender3 : 파일로 찍히며, 파일명 및 롤링(day, size) 기준 설정 -->
				<appender name="FILE2" class="ch.qos.logback.core.rolling.RollingFileAppender">
					<file>${LOG_DIR}/${LOG_FILE_NAME2}.log</file>
					<rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
						<fileNamePattern>${LOG_FILE_NAME2}.%d{yyyy-MM-dd}.gz</fileNamePattern>
						<maxHistory>30</maxHistory>
						<totalSizeCap>3GB</totalSizeCap>
					</rollingPolicy>
					<encoder>
						<pattern>%-4relative [%thread] %-5level %logger{35} - %msg%n</pattern>
					</encoder>
				</appender>

				<!-- 특정 로거의 레벨 지정 (해당 패키지 이하의 로거의 기본 레벨) -->
				<logger name="com.sungil" level="INFO" />

				<!-- 로거의 root 레벨 지정  -->
				<root level="debug" additivity="true">
					<appender-ref ref="STDOUT" />
					<appender-ref ref="FILE1" />
					<appender-ref ref="FILE2" />
				</root>
			</configuration>
			-----------

			-보통의 사용 예 :
				-private Logger logger = LoggerFactory.getLogger(getClass()); getClass통해 자신 클래스명(패키지포함)을 이용하여 생성함
				-각 클레스 마다 자신의 패키지에 대한 로거를 생성한 후 필요에 따라 logger.debug(msg); logger.info(msg); 등을 선택적으로 사용하여 필요 위치에 로깅 함
				-이후 logback-spring.xml 파일에서 각 profile에 따른 appender를 설정하고 로그형태, 로그policy, 로그레벨(나의 팩키지 별, 외부 패키지 등)을 설정 할 수 있다.

			-참고!!
				-로거를 통한 로깅은 파일에만 가능한 것이 아니다. 시스템의 표준 출력 Standard out(STDOUT, 모통은 모니터, 다시말해 콘솔)을 통해서도 가능하다.
				-console에 로깅하기 위해서는 <appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender"> STDOUT 네임으로 어펜더를 구성할 수 있다.
				-!! system.print.out(); 또는 e.printStackTrace(); 같은 경우 console에 남으나 로깅이 아님으로 STDOUT 어펜더에 영향을 받지 않는다.
				-!! system.print.out(); 또는 system.err.out(); 의 경우 console이 기본이지만 구현을 통해 파일에 남기게 할수도 있다 (logger를 통한 것과는 별개로...)
				-!! exception을 트레이스 정보와 함께 로거로 남기고 싶은 경우 logger.xxx(e.getMessage(), e);

				-특정 어펜더 로거의 기본 레벨을 설정 가능, root 지만 default 값의 의미, 특정 패키지별로 레벨이 설정 되지 않은 경우의 기본이 되는 레벨
					<root level="OFF"> OFF는 사용하지 않겠다는 의미
						<appender-ref ref="FILE_APPENDER" />
					</root>

				-특정 패키지 별로(하이러키하게 상속) 로그 레벨을 설정할 수 있다. (root level 보다 명시된 레벨이 적용된다. 디폴트 레벨 느낌???)
					<logger name="kr.ap.amt.config.DebugParamInterceptor" level="DEBUG" />
					<logger name="kr.ap" level="DEBUG" />

				-외부 패키지 (라이브러 내의 로깅 레벨 설정 : ???
					<logger name="feign" level="DEBUG" />


	-Log4j2 : 크게 2개로 구분되어짐
		-log4j API : slf4j 처럼 abstraction layer의 역할을 함, logback등과 연동할수 있음, parameterized logging 지원, lsf4j보다 더많은 logging api를 제공, 람다 표현식 지원
		-log4j implement : abstraction layer에 바인딩되어 사용됨


[Front End]
-MVC frame work : model(도메인, DTO, VO), View(html, jsp, thymeleap), Controller(Spring Controller) 방식의 Web frame work

-ModelAndView : model(데이터set)과 view(html)을 포함하는 object로 spring mvc의 controller의 return object로 사용될수 있다.
	-----------
	DispatcherServlet 의 controller 일부 내용
	-----------
	{
		ModelAndView model = new ModelAndView("employeeDetails"); /employeeDetails는 html또는 jsp 파일명(Template Engine 설정에 따라)
		model.addObject("employeeObj", new EmployeeBean(123));
		model.addObject("employeeObj", new EmployeeBean(123));
		model.addObject("msg", "Employee information.");
		return model;
	}
	-----------

-Spring View : 화면을 렌더링 하기위해 미리 정의되어 있는 페이지 객체? 이다. Template Engines을 통해 실행되며 보통 html 파일형태로 저장, EL표기법${}을 사용한다.

-Spring View Resolver : Controller 와 view 간의 바인딩 역할을 수행한다. View Resolver의 설정을 통해 동작할 Template Engines(JstlView, Thymeleaf)이 선택 된다.

-Template Engines : 
	-Text Template Engines :
		-JSP : Java Server Page로 servlet의 확장된 기능으로 java코드(jsp코드, 거의유사)와 html 코드를 혼영해서 사용할수 있게 해준다. !!Java EE 스펙 중 일부로 웹 애플리케이션 서버에서 동작한다.
			-servlet(JSP container?) container가 읽어드려 동적인 view 페이지를 만들어 낼수 있게하기위한 코드(언어)?이다 
			-container는 서버 요청시 해당 jsp 파일을 모두 java 파일로 변경하여 컴파일해(이미컴파일되어 있으면 재컴파일 않함) 기존 sevlet과 동일하게 실행시켜준다 (jsp->java->class->실행됨)
			-jsp란 결국 동적으로 html 결과를 만들어내기 위한 방법으로 해당 기능을 java로 짜기위해서는 다소 불편한 부분이 있어 이를 개선한 코드(랭귀지)?라고 생각된다. .jsp 파일로 만들며 내부에는 html 태그와 혼용되서 구성된다. 
			
			-JSP Directive : jsp파일은 3종류의 지시자를 갖을 수 있다. j
				-page : 해당 jsp 페이지와 관련된 기본적인 정보를 container에게 알려준다. key=value 형태로 여러 attibute 를 갖는다. (ex: <%@ page language="java" contentType="text/html; charset=UTF-8" %>)
				-include : 해당 파일에 다른 파일을 include하여 컴파일하게 해준다. (ex: <%@ include file="file_url"%> 또는 <jsp:directive.include file="file_url"/> )
				-taglib : jsp 페이지가 사용할 태그라이브러리가 있을경우 지정하게 해준다. 
					-(ex: <%@ taglib url="tag_library_url" prefix="tag_prefix" %> 또는 <jsp:directive.taglib url="tag_library_url" prefix="tag_prefix" />
		
		-JSTL : jsp기능을 확장하기 위해 사용될 수 있는 커스텀 태그를 모아놓은 것을 말한다. (JSP에 비해 더 쉽고 간결하게 사용할수게 하기위한 목적이다. 직접 추가적인 커스텀 테그를 만들수도 있지만 쉽지 않고 JSTL에 있는것만으로도 보통은 충분)
			-코드는 jsp 파일 내부에 작성되며 jsp가 그러하듯 html, jsp 코드와 혼영하여 뷰단 로직을 구성할수 있게해주는 표기법(기술)
			-JSP를 잘 모를더라도 JSTL 태크를 이용하여 동적 페이지를 만들수 있게 해준다
			-대규모 프로젝트에서는 view의 양이 많고 view단을 처리하기 위해 모두가 java, jsp에 능숙한 개발자일 필요가 없기 때문에 view 단만을 제어할수 있는 간단한 문법의 JSTL이 유용하며 MVC 모델의 분업화에도 용이함. 
			-이러한 view 테그라이브러리 컴포넌트드들은 보통 기본적인 if문과 반복문, 국제화, 지역화 기능을 제공한다.
				----------------
				<%@ page language="java" contentType="text/html; charset=UTF-8" %> (jsp page 디렉티브)
				<%@ taglib uri="/WEB-INF/tld/c-rt.tld" prefix="c-rt" %> (jsp page 디렉티브) (jsp taglib 디렉티브)
				<html>
				<head>
						<title>Java Code Geeks Snippets - Simple JSTL in JSP Page</title>
				</head>
				<body>
						<c-rt:if test='<%= request.getParameter("myparam") != null %>'> (jstl 코드)
								<%= request.getParameter("myparam") %>
						</c-rt:if>
				</body>
				----------------

		-Freemarker :

		-Thymeleaf : MVC based web application에서 view 레이어에 해당, servlet에서 xml, html의 template engine으로 동작함 (JSP를 대체함)
			-----------
			<dependency>
				<groupId>org.springframework.boot</groupId>
				<artifactId>spring-boot-starter-web</artifactId>
			</dependency>
			<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter-thymeleaf</artifactId>
			</dependency>
			-----------

			controller 클래스
			-----------
			@GetMapping("/") //@RequestMapping(value="/", method = RequestMethod.GET) 동일
			public String main(Model model) {
				model.addAttribute("message", message);
				model.addAttribute("tasks", tasks);

				//Model object의 내용을 갖고 해당 view로 return 됨
				return "welcome"; //view (thymeleaf가 적용된 html 명)
			}
			-----------

			thymeleaf 적용된 html 파일, EL표기법과 유사 (보통 src/main/resources/templates/ 에 위치)
			-----------
			<h2><span th:text="'Hello, ' + ${message}"></span></h2>
			-----------

	-Layout Template Engines :
		-Tiles :
		-Sitemesh :


[Cloud]
-용어 :
	-SLA(Service Level Agreement) : 해당 서비스의 성능(?), API 호출수,  장애(?) 상황등에 대한 보장 이다

-주요 서비스 제공자 :
	-Azure :
	-AWS :
	-GCP :
	

[AWS]
	-EC2: Amazon Elastic Compute Cloud, EC2


[DevOps]
-ALM : Application Life cycle Management (요구사항관리, 프로젝트일정관리를위한 Task관리, 빌드환경및형상관리자동화, 테스트자동화 등 보통 4가지 요소를 포함한다)
	-ALM 조합 예시 : JIRA+Hudson+xUnit, JIRA+Confluence+Bamboo+xUnit, JIRA+Hudson+xUnit+Mantis, Confluence+Hudson+xUnit

-Azure DevOps : Plan smarter, collaborate better and ship faster with a set of modern dev services. (프로젝트 일정, 개발 항목 관리(Scrum지원) 및 관련 CICD 기능을 제공)
	-Organization : 계정별 프로젝트 관리의 가장 큰 단위 (Organization 단위 또는 프로젝트 단위의 팀원 관리(추가/삭제)는 어떻게 이루어 지지??)
		-project : 하나의 Organization에 여러개의 프로젝트를 갖을 수 있다.
			-Overview : 프로젝트 전반에 대한 요약 정보를 제공한다.
				-Summary : 프로젝트 소개, 관련통계, 구성원 정보
				-Dashboards : 원하는 형태의 여러개의 데시보드를 만들수 있으며 선택적으로 switch 할수 있다
				-Wiki : 해당 프로젝트와 관련한 위키 페이지를 만들 수 있다. (각 페이지의 버전 관리가 이루어진다.)



			-Board : 애자일 방법론을 기반으로 프로젝트의 계획, 논의, 개발, 관리, 추적등 팀원간의 성공적 업무 환경을 제공한다.(https://docs.microsoft.com/en-us/azure/devops/boards/get-started/what-is-azure-boards?view=azure-devops&tabs=basic-process)
				Work item : 자신에게 할당된 아이템과 같은 특정 기준으로 item을 검색하기 쉽다.
					-BASIC Work item :
						-Epic :
						-Issue :
						-Task :

					-SCRUM Work items :
						-Bug :
						-Epic :
						-Feature :
						-Implement :
						-Product Backlog Item :
						-Task :
						-Test Case :

					-Agile Work items :
						-Bug :
						-Epic :
						-Feature :
						-Issue :
						-Task :
						-Test Case :
						-User Story : -main?

					-CMMI Work items :
						-Bug :
						-Change Request :
						-Epic :
						-Feature :
						-Issue :
						-Requirement :
						-Review :
						-Risk :
						-Task :
						-Test Case :



				-Board : kanban 형태의 보드로 item 의 현재 상태를 파악하고 관리하기 쉽다.
				-Backlogs : item 목록을 보여주며 plan 기능을 이용하여 item 그룹을 만들거나 조직화 할수 있다.
				-Sprints : Sprint를 생성하고 Sprint에 item을 할당해 줄수 있다
				-Queries : item들을 자기가 만든 필터를 적용하여 리스팅 할수 있다


			-Repos : 프로젝트를 위한 Git 방식의 Private Repository를 제공해 준다.
				-Files :
				-Commits :
				-Pushes :
				-Branches :
				-Tags :
				-Pull requests :


			-Pipelines : 여러 개발언어 및 타 플랫폼(Github..)과 연동하여 빌드, 테스트, 배포 등 CICD 역할을 수행한다.
				-Builds :
				-Library :
				-Task groups :
				-Deployment groups :


			-Test Plans : 개발한 앱에 대한 기능, 성능, 부하 등 다양한 측면의 테스트가 가능한 tool을 제공한다.
				-Test plans :
				-Parameters :
				-Configurations :
				-Runs :
				-Load test :


			-Artifacts : 연계성(Library) 패키지를 생성 관리하여 간단한 방법으로 다른 Pipeline과 공유할 수 있는 방법을 제공한다.

-Bitbucket :
-IBM Jazz

[development principles]
-Waterfall : old 스타일 개발 방법론으로 모든 프로젝트 일정이 종료되어야 product를 볼수 있음, 후반으로 갈수록 부담이 커지고 고객(요구자)의 변화된 요구 사항을 반영하기 어렵다.
-Agile : Waterfall 방식의 개선을 위해 탄생?, 주기적인(2w) Iteration을 통해 product를 개선해 나간다. 매 Iteration(=sprint) 마다 실행 가능한 결과물이 빌드되야 한다.

	-Scrum : Agile 방법론을 구체화 시킴
		-Backlog : 해당 프로덕트를 만들기 위해 해야할 것들 (기능정의, 출시일자, 우선순위 등 포함)
		-Sprint : 프로덕트가 완성되기 까지 일정한 기간을 두고 주기적으로 이루어지는 개발 및 빌드 기간(분석,설계,디자인 포함됨)
		-Sprint Backlog : 해당 스프린트에 진행하기로한 Backlog.
		-Task : Sprint Backlog를 좀더 상세히 쪼개놓은 것으로 우선순위, 요구설명, 예상시간, 진행자를 명시한다.(1 테스크는 1일 작업량을 넘지 않게하며 팀원이 직접 쪼개는것을 권장)
		-기본적 Workflow : Commitment Point -> Todo -> in progress -> Done -> Delivery Point (보통 cycle기간을 Lead time 이라함)
		-WIP(work in progress) Limit : 각 단계별 진행중인 상태에 단계를 둘수 있다 (ex. in progress 상태에 2개 이상의 테스크를 동시에 둘수 없는 제약)

		-담당자
			-product 관련자(고객) : 고객사 또는 서비스 사용자등
			-product owner : 회사의 임원 또는 전략 기획 및 영업 담당자로 고객과 함께 프로덕트의 기능정의, 출시일자, 기능별 우선순위를 정한다.
			-scrum master : scrum 방법론의 전반적 관리자
				-Sprint 계획 : owner와 함께 이번 sprint에 포함될 backlog를 선정하고 팀원과 함께
				-Team 관리 : 협의, 외부간섭, 장애 제거등 scrum팀의 생산적 활동을 보장해 준며 팀원의 scrum 프로세스 준수를 관리한다.
				-일일 스크럼 미팅 : 매일 15분정도의 스크럼 미팅을 통해 진행사항을 확인하고 장애제거를 돕는다.
				-스프린트 리뷰 및 회고 : 스프린트 종료시 고객,오너,팀원 모두 모여 리뷰 미팅을 진행, 팀원만 모여 회고 미팅 진행
			-scrum team : 해당 스프린트를 직접 진행할 담당자(기획, 설계, 디자인, 개발, 테스트 모두 포함 가능), 5-9명 적정
			-Agile 코치 : 외부 또는 전사적으로 애자일을 코칭해줄수 있는 전문가?

		-Rule
			-마스터는 매 스프린트 시작전 팀원의 휴일 및 잡업무를 고려하여 명확한 업무가능 시간을 도출해야 한다. (하루 4시간을 실질적인 코딩 가능 시간으로 봐야함)
			-스프린터가 잘 진행되기 위해서는 각 task에 대한 정확한 분석(업무량 및 소요시간)이 필요하며 불확실한 요소를 최대한 줄여야 한다.
			-스프린트 기간에는 선정된 backlog를 변경하지 않는것을 원친으로 한다.(긴급한 요구사항은 가능한 다음 sprint에 추가하고 sprit 기간을 1w으로 잡을수 있다)
			-스프린트 기간은 같은 길이(2w)을 유지하고 연속적으로 이루어져야 하며 정해진 시간에 끝내는 것을 원칙으로 한다.

-Kanban board : Scrum 방법론을 관리 보안해 줄수 있는 툴로 여겨진다. 프로젝트의 현재 흐름을 비주얼하게 보여주며 Scrum 방식의 룰을 조금 유연하게 적용한다.




[Develop Dependencys]
-spring-boot-devtools : 웹 캐시 기능을 제거하여 개발시 변경확인에 편리 (hot swapping, disable cache for template, enable live reload)
	-----------
	<dependency>
		<groupId>org.springframework.boot</groupId>
		<artifactId>spring-boot-devtools</artifactId>
		<optional>true</optional>
	</dependency>
	-----------



[REST]
-GraphQL : GraphQL was developed to cope with the need for more flexibility and efficiency! It solves many of the shortcomings and inefficiencies that developers experience when interacting with REST APIs.
	-REST API의 유연성 부족의 한계를 해결해 준다 (Front End 화면은 매번 쉽게 변경되는데(필요한 데이터도 변경).. API 수정이 따라 가질 못함
	-GraphQL : API 의 스키마를 정의 하기 위한 자체 언어(SDL)
		-----------
		Person을 표현하기 위한 example SDL
		-----------
		type Person {
			name: String! //(!=필수항목의 의미)
			age: Int!
		}
		-----------



[TEST]
-Junit 4 : JUnit is a unit testing framework for the Java programming language. JUnit has been important in the development of test-driven development.
	-동작방식 : class path 내부의 junit jar 가 명시된 어노테이션을 확인하여 동작한다.
	-실행 : A 클레스의 a1 메소드 테스트시 보통 ATest 클래스를 만들고 a1메소드를 작성후 @Test 어노테이션을 붙여 동작시킨다. (Run as 에서 Junit Test 로 실행)
	-test Class : src/main/java/A.class를 테스트 하는 경우 src/test/java/ATest.java 형태로 테스트 클래스를 만든다. (관례적)
	-test 메소드 실행 순서 : JUnit 4부터 랜던이 아니다.(이전에는 실행시마다 테스트 메소드가 실행되는 순서가 달랐다). 메소드 내임의 hash 값의 순서대로 호출된다.(호출 순서를 바꿀수 있는 설정이 존재함)
		-----------
		@FixMethodOrder(MethodSorters.DEFAULT) //내부 테스트 클래스의 호출 순서를 정의 할수 있다. (default는 메소드 내임 헤시값 순)
		public class ATest {
		...

		@Test
		public void a1(){
			A a = new A();
			int result = a.a1(10);
			assertEquals(5, result); //a1 메소드의 결과 값이 5이면 테스트 통과
		}
		-----------

	-Annotations :
		-@FixMethodOrder(MethodSorters.DEFAULT), 클래스 어노테이션 : 테스트 클래스의 테스트 메소드 호출 순서를 정함 (필수 요소는 아님, 작성을 안할시는 Default로 메소드 네임 헤시값 순)
		-@BeforeClass : 해당클레스 시작시 한번 실행된다. (JUnit5 에서는 @BeforeAll 로 변경)
		-@Before : 각 @Test 메소드 실행전 매번 호출 됨 (JUnit5 에서는 @BeforeEach 로 변경)
		-@Test : 테스트 메소드 임을 선언한다.
		-@After : 각 @Test 메소드 실행후 매번 호출 됨
		-@AfterClass : 해당클레스 종료시 한번 실행된다.


-Junit 5 :







Template Engine
-Mustache :

-Handlebar : html에 data를 바인딩함
	-spring 설정 : handlebars-spring-boot-starter 라이브러리가 있으므로 특별한 설정을 요구하지 않음
		-----------
		@GetMapping("/")
		public String main() {
			return "main"; //(기본 설정에 의해 prefix: src/main/resources/templates, suffix: .hbs 적용하여 해당 view를 찾는다.)
		}
		-----------


	-jsfiddle(js피들) : HTML, CSS, 자바스크립트(jquery, handlebars, react..)등 코드 스니펫을 테스트하고 결과를 볼수 있는 웹사이트

	-template : html 과 데이터 바인드를 위한 핸들바 expression, 논리적 처리를 위한 헬퍼 코드로 구성됨
		-선언 : <script id="entry-template" type="text/x-handlebars-template">
		-데이터 : {{XXX}} 형태가 기본
		-주석 : {{!-- --}}
		-partial한 template 삽입 : {{#> positionName}} 삽입 실패시 default 내용 {{/positionName}}

		-helper : if, unless 등 기본적 헬퍼를 제공하여 로직 처리를 포함하게 해준다.(custom helper도 지원)
			-loop : {{#users}} 와 {{/users}} 를 통해 반복 ( 또는 {{#each users}} 와 {{#each}} )
			-if :
				-----------
				{{#if @first}}
					<td>첫 아이템 ({{@key}} 번째 요소)</td>
				{{else if @last}}
					<td>마지막 아이템 ({{@key}} 번째 요소)</td>
				{{else}}
					<td>중간 아이템 ({{@key}} 번째 요소)</td>
				{{/if}}
				-----------

			-custom helper
				-----------
				//js내 email 함수를 호출하며 id값를 인자로 넘김
				<td><a href="mailto:{{email id}}">{{email id}}</a></td>
				-----------

	-template 와 데이터를 바인드 해주는 js 파일 : 뭐라 명명하지 ???
		-----------
		//조각 템플릿 가져오기
		var partial = $("#partial-template").html();

		//메인 템플릿 가져오기
		var source = $("#entry-template").html();

		//메인 템플릿 컴파일
		var template = Handlebars.compile(source);

		//메인 템플릿에 바인딩할 데이터
		var data = {
				users: [
					{ name: "홍길동1", id: "aaa1" },
					{ name: "홍길동2", id: "aaa2" },
					{ name: "홍길동3", id: "aaa3" },
					{ name: "홍길동4", id: "aaa4" },
					{ name: "홍길동5", id: "aaa5" }
				]
		};

		//조각 템플릿 partial을 메인 템플랫의 'commonHeader' 위치에 삽입
		Handlebars.registerPartial('commonHeader', partial);

		//커스텀 헬퍼 등록 (id를 인자로 받아서 전체 이메일 주소를 반환)
		Handlebars.registerHelper('email', function (id) {
		  return id + "@daum.net";
		});

		//메인 템플릿에 데이터를 바인딩 및 HTML 생성
		var html = template(data);

		//생성된 HTML을 DOM에 주입
		$('body').append(html);
		-----------






[파일]
-svg : Scalable Vector Graphics, 확대 축소시 안깨짐
-PNG : Portable Network Graphics, gif 파일 라이선스 문제를 해결하기 위한 대안으로 나옴

-java :
	-jar(Java Archive) : zip 포맷을 베이스로하여 class 패키지를 구성해 놓은 파일(resource, properties 파일등도 포함할 수 있다), jar 툴을 이용해 생성, META-INF 디렉토리에 해당 패키지와 관련한 메타 정보를 포함하고 있다.
		-specificaton : https://docs.oracle.com/javase/6/docs/technotes/guides/jar/jar.html
		
		-META-INF 관련 파일 :
			-MANIFEST.MF : 패키지 관련 정보 (Manifest-Version, Created-By, Signature-Version, Class-Path, Main-Class, 기타 applet패키지를 위한  attributes 정의)
				-Manifest.txt : MANIFEST.MF 파일을 만들기위해 생성
					-Class-Path: libs/slf4j-api-1.7.25.jar (해당 jar 내부의 class에서 참조할 다른 jar들의 위치를 잡아 줄수 있다, 단순히 실행 호스트에 해당 경로를 추가해 줄뿐 실행 호스트에 실제 파일이 존재하지 않으면 의미가 없음)
					-Main-Class: testProject1.MyMain (실행 가능한 jar 인경우 Main 클레스를 정해 줄수 있다)				

			-INDEX.LIST : applets과 같은 네트워크 프로그래밍에서 class파일 참조를 최적화 하기위한 용도로 사용됨 (더확인 필요!!)
			-x.SF, x.DSA : 코드 싸인(검증)과 관련된 파일
			-services(디렉토리)/ : 호스트에서 서비스로 동작하는 어플들이 자신과 관련된 interface를 모아놓을수 있는 디렉토리 (더확인 필요!!)
					
		-jar 패킹(jar툴 외에 eclipse에서 jar형태로 export 할수도 있음) : jar cfm testProject1.jar Manifest.txt testProject1/*.* 
			
	-war(Web application ARchive) : jsp, 서블릿, 자바, XML, 파일, 태그 라이브러리, 정적 웹 페이지 (HTML 관련 파일) 및 웹 애플리케이션을 함께 이루는 기타 자원을 한데 모아 배포하는데 사용되는 JAR의 일종(JDK 클레스로더에서 직접 로딩은 못함)
	-ear(Enterprise ARchive) : 하나 이상의 모듈(war등)들은 하나의 아카이브로 묶어서 여러 모듈이 애플리케이션 서버에 동시에 일관성 있게 배치될 수 있도록 하기 위한 자바 EE에 쓰이는 파일 형식이다
	




[웹 개선]
-로딩속도 향상 : head가 다 실행되고 body가 실행 되므로 head의 내용을 최소화 (css는 header에, js 파일을 body 하단에 둔다)
-js lib간 순서 : bootstrap.js는 jquery가 있어야 함으로 jquery가 먼저 선언 되야함
-DTO는 Entity를 사용해도 되지만, Entity는 DTO에 대해 전혀 모르게 코드를 구성해야합니다.


[JS, javascript]
-함수 변수: 여러 js 파일에서 함수 명이 겹쳐서 발생한느 문제를 해결하기 위해
	-----------
	var main = {
		init : function () {
			var _this = this;
			$('#btn-save').on('click', function () {
				_this.save();
			});
		},
		save : function () {
			var data = {
				title: $('#title').val(),
				author: $('#author').val(),
				content: $('#content').val()
			};
		}
	};
	//호출시
	main.init();
	main.save();
	-----------



[윈도우]
-system 관련 인증서 및 자격증 관리 (git 포함) : 제어판\사용자 계정\자격 증명 관리자
-리소스 모니터 : 사용중인 포트의 프로세스 확인 가능 (프로세스 확인 후 종료 처리 가능)

-시스템 환경변수 확인 : cmd 상에서 확인
	-모든 환경 변수 : set
	-특정 환경 변수 : echo %java_home%




[모바일, 안드로이드, IOS]
-딥링크(deep link) : 모웹에서 사용하는 테그 형태로 앱을 깨우거나 모앱의 특정 페이지를 오픈 할 수 있는 메커니즘 (!! 경우에 따라 딥링크, 앱링크, 유니버셜 링크의 이름으로 혼영하여 사용, URL 스킴 방식을 보통 일커름)
	-URL 스킴 방식 : goodoc:// 형태의 링크로 구성, 앱내 특정 위치로 이동가능, 앱 미설치시 아무 동작 안함, 같은 스킴을 사용하는 앱이 여럿 일을경우 사용자가 선택하게 함, 초기 버전의 링크로 Universal Link로 진화
		-스킴 ex : <myappSk://events?key=value>

	-Universal Link : (!!안드로이드의 경우 보통 앱링크라는 이름으로 불려 진다.)
		-스킴 방식과 차이 및 특징 :
			-앱 미설치시 스토어로 이동해 준다.(URL 스킴 방식을 보안하여 형태가 https://도메인 임으로 고유성(앱간중복방지)을 갖는다)
			-사용자의 트리거(클릭)에 의해서만 동작한다 (스크립트에서 자동으로 동작하게 하는 경우 앱이 설치되어 있어도 웹 URL로 동작되는 브라우저가 많음)
			-각각의 장단점으로 인해 스킴방식과 혼용해서 사용

		-os별 구분 :
			-앱링크 : 안드로이드쪽에 사용하는 명칭,
			-유니버셜 링크 : IOS에서 사용하는 명칭,

-디퍼드(deferred) 딥링크 : Universal Link와 같으나 앱이 설치되지 않은 경우 앱설치 페이지로 이동 후 앱이 설치 되면 앱에서 원래 가려던 페이지로 이동해 준다(유니버셜링크의 경우 앱 설치후 앱의 메인으로 오픈됨)
	-단점 : 안드로이드, IOS 각각의 디퍼트딥링크가 존재해서 개발을 두벌씩 해야 하는 번거럼이 있음, 해결을 위해 Firebase 사의 Dynamic Link, Appsflyer사의 One Link 가 생겨남
		-Firebase : 모바일 앱, 웹어플리케이션 앱 플랫폼 개발 회사로 google에서 인수, 앱 개발시 제공하는 SDK를 추가하여 개발하는 방식
			-메인 솔루션 :
				-Cloud Firestore(NoSQL) : web, Aos, Ios 사용가능
				-Dynamic Link :

		-Appsflyer(앱스플라이어) : a SaaS mobile marketing analytics and attribution platform, facebook 등의 마케팅 파트너사,  앱 개발시 제공하는 SDK를 추가하여 개발하는 방식
			-메인 솔루션 :
				-
				-One Link :

-organic install : 특별한 마케팅 링크(디퍼드 딥링크 같은)가 걸리지 않음 순수 스토어를 통한 인스톨



[하이브리드 앱]
-function call :
	-android :
		-javascript -> native :
			-네이티브에 웹뷰 생성 : WebView web;
			-네이티브에 app 라는 이름으로 스크립트 인터페이스 생성 : web.addJavascriptInterface(new MainJsInterface(getApplicationContext()), "app");
			-네이티브에 스크립트에서 호출될 실제 펑션 구현, public void recordEvent(String name, String json){...} , !! 리턴값을 줄수도 있음
			-스크립트에서 네이티브의 펑션 호출 : <script>abc.recordEvent(eventName, eventParams);</script> !! 리턴값도 받을 수 있음

		-native -> javascript :
		     -네이티브 버튼에 특정 스크립트 펑션을 걸수 있다. : public void onClick(View v) {webView.loadUrl("javascript:getValue()");}
				-getValue() 내부에서는 스크립트 -> 네이티브 방식으로 값을 다시 native 쪽으로 넘겨주게 처리 해야 한다. : function getValue(){MyAndroid.receiveValueFromJs(val);}
					-getValue() 내부에 스크립트 -> 네이티브 방식을 구현하지 않고 그냥 return val 형식으로 바로 리턴해서 네이티브로 값을 전달 할 순 없다.!!
					-변칙적으로 특정 값을 가져오기 ?? : (확실히 가능한지는 확인 필요!!)
						-public void onClick(View v) {webView.loadUrl("javascript:MyAndroid.receiveValueFromJs(document.myform.xxx.value)");}

					-기타 참고 :
						-네이티브에서 webview 어느 url을 로딩하는지 알수 있다.
						-webview 로딩이 끝나는 시점을 캐치해서 이벤트를 걸수 있다.

	-ios :
		-javascript -> native :
			-네이티브 view controller에 메시지 수신코드 추가 :
			-(void)userContentController:(WKUserContentController *)userContentController
			didReceiveScriptMessage:(WKScriptMessage *)message {..구현..};

			-스크립트에서 네이티브의 펑션 호출 : <script>webkit.messageHandlers.event.postMessage(eventName + "+" + eventParams);</script>
				-펑션 호출이라기 보단 네이티브의 메시지 핸들러로 메시지를 전달하는 형식 (메시지를 파싱해서 value로 사용 하는듯.. 당연히 네이트브로 부터 리턴도 못 받겠지??)

		-native -> javascript :





[publishing platform]
-개념 : 웹사이트를 만들기 위한 플랫폼 (툴?)
-주요 상품 :
	-wordpress : 전세계 30 쇼핑몰이 wordpress 기반, opensource 기반으로 각정 플러그인 및 테마를 제공함
		-서비스 임대형, 설치형 등 다양한 조건으로 지원
	-wix.com :



[SEO]
-SEO : search engine optimization
-최적화 :
	-https 사용
	-robots.txt 사용 : https:xx;com/robots.txt 에 위치 시킴 (서치엔치이 크롤링 함)
		-접근할수 없는 url path 구현 (로그인이 필요한 마이페이지, 장바구니, 결제 페이지 등..)
	-sitemap.xml
		-robots.txt 파일을 통해 정의 할수 있음
		-보여주고 싶은 페이지에 대한 정의

	-SEO를 위한 타이틀 및 디스크립션 테그 적용
		-<title></title>
		-meta tags :
			-<meta name="title" content="">
			-<meta name="description" content="">
			-<meta name="keyword" content="">
		-robots meta tags :
			-<meta name="robots" content="noindex, nofollow" />
		-이미지 테그의 alt text 활용
		-Canonical tag : 사이트에 거의 동일한 페이지가 존재할경우 정본?? 페이지로 링크될수 있게 할수 있다. 또는 타 사이트의 내용을 따온 경우 원본? 페이지로 링크될 수 있게 할수 있다.
			-<link rel="canonical" href="http://example.com/" />
		-기타 sns tag : og tags...

-ASO : app store optimization (모바일 스토어에서 최적화)




[SNS]
-페이지 공유 :
	-참고 :
		-og(Open Graph) Tag : 페이스북에서 만든 규약으로 지금은 페이지 공유를 하는 많은 사이트의 표준 처럼 사용 됨(카카오, 블러그, SNS 서비스 들이 함께 사용하고 있음, 자체 테그를 추가하기도 함)
			-html head에 메타 테그로 들어가며 서버사이드에서 wirte 되어 내려와야 함 (js에 의해 값이 변경되는 것은 크롤러가 감지하지 못함), 크롤러에게 해당 페이지의 정체를 설명하는 테그들임
			-페이지를 공유하면 공유받은 서비스의 크롤러가 해당 페이지를 읽어 들여 og tag를 확인 후 화면상에 어떻게 보여 줄지를 정함
			-기본적으로는 실제 공유될 페이지에 해당 테그가 존재해야 함 (꼼수로 실제 랜딩 페이지와 다른곳에서 메타 테그를 제공 할수 있긴 함)

		-주요 og Tags :
			-og:url : 특정된 파람이 붙지 않은 해당 페이지 고유의 url, 해당 페이지의 유니크한 id이며 좋아요, 싫어요 카운트 키값으로도 사용됨, 넣지 않아도 됨(넣지 않으면 자기 자신의 url로 인식 되는듯??)
			-og:title : 제목
			-og:description : 설명
			-og:image : 대표 이미지
			-fb:app_id : 페이스북의 인사이트를 사용하는 업체의 경우 해당 앱 ip를 추가하면 대시보드를 통해 트래픽 정보를 받을 수 있음
			-og:type : 문서의 타입으로 기본은 website
			-og:locale : 해당 문서의 언어

	-facebook :
		-링크 팝업 예시 : popupUrl = '//www.facebook.com/sharer/sharer.php?u=' + originUrl;
		-참고 :
			-기본적으로 originUrl쪽 페이지에 og테그들이 있고 링크도 originUrl로 가야 하나
			-만약에 og:url이 originUrl과 다르게 설정되면 크롤러가 og:url쪽으로 이동하여 og테그를 읽고 최종 링크는 originUrl로 랜딩 되는 듯 함(??)
			-클롤러는 페이지 내에 있는 js 스크립트에는 영향을 받지 않는듯 함
				-최종 링크되는 페이지에서 og테그를 지원 할수 없는 경우 originUrl을 https://my.com/productDetail?isShared=true 형태로 주고 productDetail 페이지 내 메타테그를 쓰고
				-로딩되는 시점에 스크립트를 통해 isShared 가 true인 경우 location을 다른 곳으로 이동처리하는 방식이 가능하다 (크롤러는 js 스크립트를 무시하기 때문인듯..)

		-og tag에 대한 확인 테스트 가능 : https://developers.facebook.com/tools/debug/


[브라우저]
-개념 및 기본이라 할수 있는 기능 :
	-URI(Uniform Resource Identifier)가 지정하는 html문서(서버가작성한html이든 정적html이든)를 내려받아 css,js등의 결합적업을 통하여 화면에 표시해 주는 어플리케이션이다. (플러그인 설치를 통해 PDF나 다른 문서를 보여주기도 하지만)
	-브라우저는 사용자 혼란 및 개발자의 개발 코드에 대해 적절한 동작을 보장해야 하기때문에 W3C(World Wide Web Consortium)에서 각 기능 및 동작에 대한 표준을 정해 각 브라우저 개발사가 적용한다.(요즘은 브라우저들이 거의 동일하게 동작함)
	-브라우저들은 기본적인 UI는 이전/다음 버튼, 북마크, 새로고침, 중지, 홈버튼 등을 기본으로 제공한다.
	
	


[Chrome]
-속도 개선 :
	-request 횟수를 최소화 : webpack, parcel 같은 모듈 번들러 사용
	-작은 이미지들은 html에 데이터를 포함시켜서 data-uri로 표현
	-불필요한 request 제거
	-이미지에 대한 lazy loading 처리
	-브라우저 랜더링 시간 절약 : 순처적으로 불러와 지는 js가 dom, cssom 의 개입을 최소화
	-haed 태그에는 필수 css, js만 적용 (가능하면 body태그 마지막에 js를 넣는다)
	-dom 제어와 관련이 있는 스크립트는 defer attribute를 이용
	-Google Analytics 같이 의존성이 없는 스크립트는 async를 이용
	-webpack, parcel : 모듈번들러
	-lazy loading

-develop tool :
	-network :
		-initial connection : 연결 설정 시간(tcp handshake, ssl 협상)
		-TTFB(time to first byte) : 서버로 요청후 첫 byte를 받은 시간(서버의 처리 시간)
		-content Downloaded : 서버로 부터 데이터를 다 받는데 걸린 시간 (개선을 위해 minify, gzip, tree shake 등을 고려)

	-Application :
		-Storage :
			-Cookies : 현재 열려 있는 페이지에서 생성한 cookie 정보를 보여줌, 해당 페이지를 랜더링 하면서 타 사이트를 참조했다면 해당 타 사이트의 cookie 정보도 함께 보여 줌


[인증]
-Token Based Authentication :
	-web 전통 방식 인증 : id/pw 입력후 유효하면 session 및 cookie를 생성하여 다음 요청시 사용
	-단점 :
		-web base가 아닌 Mo 앱등 cookie를 사용할 수 없는 환경에서 한계가 있음, 어떠한 형태의 client의 요청에도 인증하기 위해 token 방식이 이용됨, 특히 API 서버인 경우 client가 브라우저가 아닌경우가 대부분이기 때문
		-서버 세션등의 사용은 서버의 리소스 증가를 발생시키며 Stateful 서버의 형태로 dependency가 생긴다.


-Token Based Authentication : (token 스트링 값을 통해 인증)
	-장점 :
		-전통 방식의 한계 극복, web 서비스(브라우저 base)가 아닌 경우에도 이용 가능
		-redis 등으로 session 관리하여 확장성 및 stateless 서버 형태를 구현할수 있는 추세지만 기본적으로 클라이언트에 token 관리를 넘김으로서 서버는 항시 stateless 상태 유지 가능(실제는 안그런듯?)
		-다른 app간 토큰을 공유하여 사용 가능
	-단점 :
		-토큰 방식은 보안성 측면에서 더 강화된 방식이라 볼 수 없다 (accessToken의 유효기간 동안은 인증서버로 확인을 하지 않기 때문임, 그래서 accessToken의 유효기간은 짧아야 함, 30분?)
		-서버의 Stateless, Scalability, Extensibility 관점에서 의미를 갖는다.
		-token 유출 및 관리자에 의한 해당 사용자의 상태 변화시 대응을 위해서 https를 사용하고 timestemp를 갖고 주기적으로(내부적으로) 재 인증을 하게 하거나 하는 보완이 필요

	-관련 스팩(?) 및 기술 : OAuth,
	-절차 : https 를 사용하여 id/pw(hashed) 서버 전송 -> 인증 -> (access)Token 생성(JWT방식)및 반환 (header? body?) -> 다음 요청시 header에 Authentication : Bearer 값 전송하여 인증
		-http 해더 ex: Authorization: Bearer eyJhbGciOiJSU...

	-Access token을 만드는 방식
		-의미 없는 고유키값을 토큰으로 사용하는 방식 : facebook등의 OAuth의 경우 그저 유니크한 토큰을 발급 (해당 토큰을 통해 원하는 정보를 lookup 해야 함, lookup을 위한 리소스 낭비 발생)
		-token 자체에 필요한 정보를 담는 방식 : id, 권한, 롤 등 기타 필요 정보를 담을 수 있다. (서버가 해당 토큰을 까서 직접 필요한 정보를 얻을 수 있다)

		-토큰 생성 스팩 :
			-JWT(Json Web Token) : 기본(?) 정보를 담을 수 있는 인증 토큰을 만들기 위한 포맷,
				-구성요소 : Header, Payload, Signature
				-Header : 토큰 타입과 암호화 방법을 정의 (Base-64 인코딩됨) =>B-64({typ:'JWT', alg:'HS256'})
				-Payload : 필요한 정보 (유저 및 기타 상품 정보 등, Base-64 인코딩됨) =>B-64({name:'sungil', grade:'admin'})
				-Signature : 유효성을 체크하기 위한 값 => HMACSHA256(B-64(header)+','+B-64(payload)+','+secret_key), secret_key는 서버에 안전하게 보관되야 함 
					-!!! client, auth서버, resource서버 구성에서 누가 secret key의 주인일까?? 누가 누가 이 값을 알고 있을 필요가 있을까?? 
					-!!! client는 auth서버에서 받아온 값임으로 자신이 잘 관리하면 그만이기 때문에 그 값으로 검증할 필요는 없을 듯(auth 서버가 준것이니깐 그대로 신뢰하면 되겠지)
					-!!! resource 서버는 넘어온 access 토큰의 검증을 auth로 묻지 않고 자체 판단하기 위해서는 secret 키가 필요하겠지(auth로 매번 묻지 않기 때문에 auth의 부하는 준다, 그러나 token의 유효기간 동안은 보안적 불안전성이 생긴다.)
					-!!! auth 서버는 당연히 JWT의 생성 주체 임으로 secret 키 값을 가지고 있어야 겠지..
				-token값 : Header + '.' + Payload + '.' + Signature

	-!!! refresh token : accessToken이 만료 되었을때 accessToken을 제 발급 받기 위한 토큰
		-JWT 토큰 인증 방식의 일반적 흐름 :
			-클라이언트(FO서버or앱)가 ID, PS를 이용해 인증서버로 토큰을 요청한다. 인증서버는 id,ps를 확인하여 맞으면 accessToken, refreshToken을 내려 준다.
				-accessToken 주요 내용 : 원하는항목(ex:누구인지 알기위해 id, 고객등급등 서비스에 필요한 요소..), 토큰만료일자(30분?), 유효성 검증을 위한 시그니쳐
				-refreshToken 주요 내용 : 원하는항복(ex:누구인지 알기위해 id ..), 토큰만료일자(7일?), 유효성 검증을 위한 시그니쳐
				
			-access, refresh 토큰의 관리는 시스템 구성에 따라 달라 질수 있다
				-브라우저-FO서버 형태 : 브라우저-FO서버간은 세션(jsessionID)으로 연결하고 각 토큰은 FO 서버의 해당 세션에서 관리 가능
				-앱-FO서버 형태 : 앱에서 직접 각 토큰을 관리할 수도 있다.
			
			-Agent가 클라이언트로(FO서버) 요청시 FO 서버는 access토큰의 만료일을 직접 확인하여 유효시 토큰의 기타정보를 활용하여 화면 구성 등을 할 수 있으며 리소스 서버로 API 호출시도 인증을 위해 함께 전달한다.(auth서버가 준거기 때문에 시그니쳐를 통한 검증이 필요 없음..)
			
			-클라이언트 부터 전달받은 request에 대해 API 서버는 함께 받은 access 토큰을 확인하여 해당 사용자에 대한 정보를 내려 준다(이때 클라이언트 전달한 토큰의 유효성을 무조건 믿을 수 없기 때문에 검증이 필요한데.. 이를 매번 auth 서버로 요청을 하는 것이 아니라 시그니쳐 값으로 직접 위변조를 확인하여 판단한다. 그러기 위해서 리소스 서버는 시그니쳐를 만들어낸 secret key 값을 알고 있어야 할듯!)
			
			-Agent가 클라이언트로(FO서버) 새로운 요청시 FO 서버는 access토큰의 만료일을 직접 확인한다 이때 만료일자가 얼마 남지 않았거나 만료 됐다면(30초?) 갖고 있는 refresh 키를 이용해 auth 서버로 새 authToken 및 refreshToken을 요청한다. 기존 토큰은 파괴하고 새 토큰을 관리한다.
				-이때 auth서버가 해당 refresh 토큰의 주인이 다른 채널을 통해 모두 로그오프를 했거나 id를 탈취되었다고 판단되면 새 토큰 요청에 대해 fail을 주고 더이상 사용하지 못하게 할수 있다.. (이럴경우 다시 id, ps 부터 입력토록 유도)
				
		-JWT 토큰 인증 방식의 장점과 단점 :
			-위의 인증 흐름을 통해 알수 있듯 auth 토큰은 매번 클라이언트 및 리소스 서버로 부터 유효성 요청을 받지 않아도 된다(access 토큰의 유효 기간동안은 각 서버가 알아서 인증을 판단한다, 그렇기 때문에 access 토큰 만료기간은 짧아야 함)
			-반면 클라이언트와 리소스 서버가 auth 서버를 대신해 토큰 만료 기간동안 유효성 판단을 함으로 해당 타임만큼 보안에 취약을 갖는 한계를 갖는다
			
	
	-기본 system 아키텍쳐 : client, Load-Balancer, 인증서버, API서버
		-흐름1 : client 인증요청(id/pw) -> Load-Balancer 적절한 인증서버로 요청 -> 인증서버는 id/pw 확인하여 Token 값 생성하여 반환 (id/pw 오류시 에러 페이지로 redirect)
		-흐름2 : client API 요청(token 값을 Bearer 값으로 사용하여 요청) Load-Balancer 적절한 인증서버로 요청 -> bearer값이 유효한 경우 적절한 API 서버로 redirect (인증오류시 403)


-SSO (single sign on) : 한번의 인증(로그인)으로 여러 사이트 인증
	-서비스 형태 별 구분 :
		-클라이언트 기반 : 개인 PC에서 각 사이트에 대한 계정 정보를 가지고 있다가 자동으로 로그인 시켜줌 (윈도우나 브라우저의 계정 저장 기능과 유사)
		-서비스 기반 : 인증만을 처리해 주는 서비스 (ex : MS passport)
		-서버 기반 : 인증 서버를 두고 처리하는 방식
			-서버 기반 구현 모델: (개념적으로 설명)
				-인증 대행 모델(delegation 방식) : 사용자 -> 인증서버 -> 각각의 모든 서버에 접속하여 해당 사용자를 인증 상태로 만들어 논는다(사용자를 대신해서 모든 사이트에 대신 로그인 해줌(상태를 만듬))
					-특징 : 각 서비스가 수정하기가 어려운 경우 사용됨

				-인증 정보 전달 모델(propagation 방식) : 사용자 -> 인증서버 인증토큰 발급 -> 사용자 (인증토큰을 이용하여 각 사이트 접속) -> 각사이트 (인증토큰이 유효한시 매번(?) 인증서버에 확인)
					-특징 : 인증 서버의 신뢰가 높고 각각의 서비스가 수정이 용이한 경우 (같은 도메인 영역을 사용할 경우 인증 토큰을 cookie로 생성하여 처리 가능)

	-주요 개발 형태 별 구분 :
		-OAuth 2.0 : 표준으로 정립, 2.0부터 OAuth로 명명, SSO의 개념보다는 API 서버 인증, 인가용으로 많이 사용(?), 웹, 모바일, 데스크탑, IoT 장비에 확장성이 좋음, 개발적 인증 절차에서 표준이 된것에 의미가 큼
		-wiki 정의 일부 : Generally, OAuth provides clients a "secure delegated access" to server resources on behalf of a resource owner. It specifies a process
						for resource owners to authorize third-party access to their server resources without sharing their credentials.
						-!! 위 정의에 따르면 자원소유자패스워드승인 방식은 credential이 오픈되는 문제가 있어 보임

			-주요개념(용어) : facebook 예시
				-자원서버(Resource Server) : 실제 고객의 컨텐츠 정보를 가지고 있는 facebook 서버 (API 서버)
				-자원소유자(Resource Owner) : 페이스북 유저
				-인가서버(Authorization Server): 클라이언트가 API를 사용할수 있도록 access token을 발행하는 서버(facebook 소유의 서버)
				-클라이언트(Client) : facebook API를 통해 서버가 뭔가 서비스를 제공하는 제3의 서버,웹서버,앱 등등
				-사용자에이전트(User Agent) : 일반적으로는 브라우저가 될수 있으나 반드시 그런것은 아님, 앱의 경우 에이전트 없이 앱 자체가 에이전트의 역할을 할수도 있음
					-참고 : 클라이언트와 에이전트를 구분짓는 이유는 에이전트는 보통 오픈된 형태의 도구 즉 브라우저등을 의미, 보안이 상대적으로 취약할수 있는 구간을 설명하기 위해 구분 짓는 듯(?)

			-상황별 시스템 구성
				-인가코드승인(Authorization Code Grant) : OAuth가 가질수 있는 full stack(?), 보안성 높음,  클라이언트가 웹서버(Auth code를 받아서 서버로 리다이렉트 해야 함으로?)인 케이스
					-로그인시도 > 클라이언트가 에이전트로 Auth 서버 주소로 리다이렉트 시켜줌 (클라이언트id, state, 인증후 리다이렉트로 돌아올 returnUrl과 함께)
						-에이전트는 Auth 서버로 리다이렉트 되어 사용자가 credentials(id/pw)을 입력하여 전송하면 Auth 서버가 인증/인가 확인 후 Authorization Code + state 값을 내림
							-정확히는 Auth 서버가 에이전트로 Authorization Code + state 값을 주면서 클라이언트쪽의 returnUrl로 바로 리다이렉트 시켜 버림
							-!! 바로 access 코드를 내려 주지 않는 이유 : 실제 resource 서버로 접속가능한 access 토큰이 agent까지 내려간다면 보안상 취약점이 발생할 수 있기에??
							-!! state를 달고 다니는 이유 : 제3의 서비스를 통해 후킹한 Authorization Code를 이용하여 타 서비스로 접근하는 시도를 막기위해 정상적인 요청인지 한번더 체크??

								-클라이언트는 전달받은 state 값이 자신이 발행한 유효값인지 확인후 Authorization Code + client crdential 이용하여 Auth 서버로 최종 access Token을 요청
									-응답받은 access 토큰은 에이전트로 내려가지 않고 클라이언트(클라이언트는 앱이될수도 서버가 될수도 있다)에서만 관리되어 짐
									-!! client 입장에서의 자체 로그인 처리(session 생성등)는 어느 시점? : Auth 서버로 부터 정상적인 access 토큰이 발급되는 이 시점에 처리하면 되지 않을까??

				-암시적승인(Implicit Grant) : 중간 웹서버가 없이 브라우저(js)를 이용하는 앱으로 구성된 경우, Auth code를 가지고 리다이렉트 할수 없음으로 에이전트로 엑세스토콘을 바로 내림(상대적으로 보안 취약)
					-!! 앱스킴값을 이용하여 리다이렉트 할수 있지도 않을까??
					-로그인시도 > 클라이언트가 에이전트로 Auth 서버 주소를 내려줌 (클라이언트id, state값 과 함께)
						-에이전트는 전달 받은 auth 주소로 접속하여 사용자가 credentials(id/pw)을 입력하여 전송하면 Auth 서버가 인증/인가 확인 후 에이전트로 바로 엑세스토큰 + state 값을 내림
							-에이전트는 받은 엑세스 코드를 클라이언트로 전달
							-!! 클라이언트 id 가 앱 형태의 어플에 존재하기 때문에 디컴파일등으로 인한 노출 우려가 있음, 이를 위해 실시간으로 클라이언트 id를 생성해내는 방식이 있다는데.. 잘은 모르겠음??

				-자원소유자패스워드승인(Resource Owner Password Grant) : 사용자가 자신의 클라이언트로 직접 credentials(id/pw)을 입력함 클라이언트에 크리덴셜이 노출됨 (보안 취약, Oauth라 볼수 있나??)
					-사용자가 클라이언트 (보통 앱일듯)에 직접 개인 크리덴셜을 입력
						-클라이언트는 클라이언트id와 개인 크리덴셜을 갖고 auth 서버로 인증 요청
							-auth 서버는 바로 엑세스 토큰을 클라이언트로 내림
							-!! 개인 크리덴셜이 제3의 클라이언트로 바로 노출됨으로 보안이 취약함, 다른 유형의 승인 방식을 사용할 수 없는 경우에만 사용

				-클라이언트인증정보승인(Client Credentials Grant) : 클라이언트가 자원의 소유자이거나 자원 소유자가 이미 클라이언트에 접근 위임을 받은 경우 (회사가 자기 직원 정보를 턴키로 위임 받은 케이스??)
					-사용자 크리덴셜을 입력 받지 않는다
						-클라이언트는 인가서버로 클라이언트id 만을 가지고 엑세스 코드를 발급 받는다
						-!! 해당 엑세스 코드는 해당 클라이언트와 관련된 모든 자원 소유자의 정보에 엑세스 가능??

			-보안 고려 사항 :
				-Oauth 스팩에 Bearer 토큰을 쿼리 파라미터로 전달하는 방법이 있지만 이러한 방식으로 엑세스 토큰이 노출되지 않게 해야함
				-엑세스 토큰이 log 파일등에 남아서는 안된다.
				-auth 서버가 엑세스 토큰을 DB 등으로 관리할때 plain 텍스트가 아닌 암호화해서 저장해 둬야 한다.
				-auth 코드는 한번 access 코드를 발급하면 더이상 사용 할수 없도록 해야 하며 동일한 auth 코드로 요청이 들어오면 기존 해당 auth 코드로 발급된 엑세스 코드도 패기 처리하는게 좋다
				-리다이렉트 url은 client id를 발급해 줄때 미리 받아서 등록되어 있는 return url로만 내려주게 해야 하고 return url은 패턴 형식보다 명확히 픽스된 형태의 uri로 등록되게 해야 좋다
					-등록된 url과 다른 scope의 url이 넘어올경우 400오류를 발생하는것이 좋다


		-SAML(Security Assertion Markup Language) :





[REST API (Representational safe transfer)]
-인증
	-API key 방식 : API포털(개발자사이트)를 통해 특정 스트링 형태의 키를 발급받아 API 호출시 함께 전송 (서버는 키값을 통해 사용자를 확인), 가장 초기적인 방식 이며 특정 표준이 없다.
		-문제점 : api 키값이 노출시 보안에 문제 발생이 쉽다.

	-API Token 방식 : id/pw를 이용하여 인증후 토큰값을(사용기간등 유효한) 내려 받아 api 호출시 id/pw 대신 api 토큰을 전송하여 인증 받는 방식
		-장점 : 매 api 호출시 id/pw를 보내지 않고 token을 보내는 이유는 사용자의 pw가(본인이 바꾸든 해커가 바꾸든) 언제든 바뀔수 있고 매번 id/pw를 넘기는 것 보다 보안에 유리하다.
		-주요 방식 예시 :
			-HTTP Basic Auth :
			-Digest access Authentication :
			-클라이언트 인증 추가 :
				-클라이언트에도 자체 id(client id)와 pw(client secret)을 추가하여 클라이언트 인증 후 id, pw 를 추가 인증 함(조금더 개선된 정도)

			-제3자 인증 방식 : google 이나 facebook 계정을 이용하여 서비스 서버는 사용자의 pw를 공유 받지 않지만 해당 사용자가 google이나 페이스북의 사용자임만 확인 받는다.
				-주요!! : API 서버가 제3의(페이스북 같은) 서버의 API를 이용해야 하는 경우 사용하는 용도로 봐야 겠지?? 단순히 회원가입을 하지 않기 위한 인증용으로만 활용할 수도 있지만
				-인증을 위해 페이스북이 입력 받는 기본 항목 : 페이스북 developr portal에 등록 하는 주요 항목
					-서비스명 :
					-시비스 url :
					-callback url : 인증이 성공 했을때 인증 정보를 받는 url (인증 정보는 보통 client id, client secret)

				-OAuth 방식 : OAuth Provider부터 인증을 받아 OAuth 토큰을 받고 API 호출시 OAuth 토큰을 함께 전송, API키 방식보다 높은 보안 및 OAuth 인증 표준이 존재함 (개발 난이도가 조금 있음)

	-Bi-diretional Certification : 가장 높은 수준의 인증, 서버/클라이언트 양방향 SSL을 제공, 메시지까지 암호함으로 인중 수준이 높다.(개발이 어렵고 특정 서비스에서 사용)

-메시지 암호화 :
	-https : 데이터 암호화를 위해 주로 사용(RSA)
		-문제점 :
			-Man in middle attack : Client 와 서버가 Handshke 시점에 해커가 서버의 인증서를 갈취 후 client에는 자신의 인증서를 내려줌
				-client는 해커의 인증서로 암호화 하여 데이터 전송, 해커는 중간에 갈취하여 자신이 열어본 후 다시 진짜 서버의 인증서로 재 암호화 하여 실재 서버로 전송 (계속 하여 데이터 갈취 가능)

	-데이터 레벨의 암호화 : 보안이 필요한 특정 데이터만 암호화 하여 전송
		-주로 대칭키 기반의 암호화 알고리즘 사용
			-종료 : DES, Triple DES, Blowfish-256, AES-128, AES-256, RC4-256
				-각 암호화 종류마다 보안성 및 처리속도가 다름

-무결성 보장 : 암호화는 데이터를 몰래 볼수 없도록 하기위한 처리라면 무결성은 데이터가 중간에 변경되지 않았는지를 보장하기 위한 조치
	-주요 알고리즘 : HMAC 알고리즘
		-방식 : 클라이언트는 서버와 미리 공유된 key 값을 통해 전송할려는 데이터의 Hash값을 추출하여 전송할 데이터와 함께 전송 한다, 서버는 전송받은 데이터를 공유된 키값으로 해쉬하여 전달 받은 해쉬값과 같은지 본다.
			-문제점 : 해커가 데이터를 변조하지 않고 탈취한 데이터를 그대로 서버로 요청시 요청이 성공됨
			-해결책 : 전송할 데이터에 API 요청 시간을 포함하여 해쉬 값을 만든다. 서버는 해쉬값을 확인하여 변조가 없다면 요청된 시간도 확인하여 +- 몇분(5분?)의 요청만 유효한 요청으로 인정 한다

-FM 정석 : REST API는 완전한 객체 형태로 구성해야 한다.
	-http 메서드 : Post=create, Get=select, Put=update, Delete=delete
		-이게 실제로 지키기가 어렵다.. 이렇게 명확히 구분 짓기 위해서는 모든 API의 기능을 쪼개야 하고 쪼개진 API를 클라이언트가 쪼개서 호출해야 하는데.. 현실에서는 쉽지 않은듯..
		-GET을 제외하고 post, put, delete 모두 request body를 전송 가능하다. (get에 request body를 붙이면 실제로 넘어갈때는 post 메서드로 변경되서 넘어가는듯...?)
	-url :
		-create : HTTP Post, http://myweb/users/, body={"name":"terry", "address":"seoul"}
		-update : HTTP Put, http://myweb/users/, body={"name":"terry", "address":"suwon"}
		-select : HTTP Get, http://myweb/users/terry
		-delete : HTTP Delete, http://myweb/users/terry

	-http method를 명확히 구분하여 사용시 장점
		-http 기존 웹 표준의 인프라를 그대로 사용 가능 : 웹캐싱 등..
		-계층형 구조로 구성이 용이(Layered System) :
			-Authentication, 암호화(SSL), 로드밸런싱을 api gateway나, 간단한 기능의 경우에는 HA Proxy나 Apache와 같은 Reverse Proxy를 이용해서 구현하는 경우가 많다.

	-하지 말아야 하는 실수
		-Get/Post를 이용한 터널링 :
			-update : HTTP Get, http://myweb/users?method=update&id=terry (http get 메소드를 이용해서 실제로는 update를 구현)
			-select : HTTP Post, HTTP POST, http://myweb/users/, body={"getuser":{"id":"terry",}} (http post 메소드를 이용해서 실제로는 select를 구현)
			-이런식의 사용은 기존 http 인프라(웹케싱 기능등...)을 사용할 수 없게 만든다

		-result Code 값을 임의로 정의 : result 코드값은 http 해더에 기존 http result 코드 값을 최대한 사용해야 한다.





[http]
-보안
	-Access-Control-Allow-Origin : (옵션 : *, 특정 도메인)
		-CORS (Cross Origin Resource Sharing) : 다른 서버(도메인, 포트)의 리소스를 사용하는 매커니즘 (HTTP는 기본적으로 CORS를 허용했음, 지금도 html에서 img, css, js, 비디오파일은 기본으로 허용?)
			-CORS 인하여 사용자의 정보 보안 이슈 및 타 사이트가 무분별하게 타 사이트의 리소스를 사용하는 상황이 생겨 이를 위한 정책이 생김
				-same-origin policy : 브라우저에서 <script></script> 내부의 코드가 외부 서버로 request를 요청할때 reponse를 브라우저 단에서 차단하는 매커니즘 (js엔진표준스팩으로 브라우저들이 채택하고 있음)
				-ajax 통한 API 호출이 많은 추세에서 same-origin policy 가 문제가 있어 해결책을 제시함
				-해결책 :
					- Simple Request : 각 request 한번에 하나의 response를 주고 받는 것(매 request/response 마다 반복적으로 처리 되야 함)
						-요청시 GET, HEAD, POST 중 한가지만 사용
						-요청시 커스텀 해더를 사용하지 말것
						-Post 방식일때 Response의 Content-type은 application/x-www-form-unlencoded, multipart/form-data, text/plain 만 가능
						-응답 해더에 Access-Control-Allow-Origin:* 포함 (이것을 보고 브라우저가 판단하여 해당 response를 차단 하지 않는다. *대신 요청한 도메인을 넣어 준다)
							-API 서버가 Access-Control-Allow-Origin:* 를 항상 내려 주게 설정되어 있다면 이것이 브라우저 사용자의 보안 문제를 해결하기 위한 조치로 볼수 있을까???

					-Preflight Request : 예비 요청과 본 요청으로 나뉘어서 처리 (프로그램으로 절차를 만드는 것이 아니라 Header 값 조정을 통해 처리)
					-Request with Credential :
					-Request without Credential :

	-Set-Cookie: SESSION=1f5487cd-bbc5-43e6-b5bf-d476871fbd3a; Path=/kr/ko/; Secure; HttpOnly; SameSite=None
		-CSRF(cross-site request forgery) 또는 XSRF : 웹사이트 취약점 공격의 하나로, 사용자가 자신의 의지와는 무관하게 공격자가 의도한 행위(수정, 삭제, 등록 등)를 특정 웹사이트에 요청하게 하는 공격
			-흔한 예시 : A사이트에 게시판에 가짜 링크를 만들어 사용자 몰래 B사이트로 request 날리도록 속임
				-B사이트의 request가 회원 탈퇴 요청 API일 경우 B사이트는 단지 로그인 여부로만 처리를 한다고 하면 만약 사용자가 A사이트 전에 B사이트에 로그인 한 이력이 있고 세션 cookie 가 살아 있다면
				-cookie의 특성상 B사이트로 request 요청시 해당 B사이트의 cookie 값을 그대로 물고 감으로 자신도 모르게 회원 탈퇴 될수 있음
				-하여 브라우저에서 타 사이트 페이지 내에서 타 사이트로 request를 요청시 cookie 값을 넘겨주지 않도록 처리가 필요하게 됨
					-서버에서 Cookie 쿠키 생성하여 내려줄때 옵션에 SameSite=None 으로 되어 있다면 타사이트로 Cookie를 넘어가도록 허락한 것임
						-옵션:None(A사이트로 B 요청시 B사이트의 쿠키가 있다면 cookie도 전송), Strict(전송 불가), Lax(Strict에서 GET, a href, link href 일때 예외로 허용)
					-기타 : secure(https 일때만 쿠키 생성), httpOnly(도큐먼트의 !!자바스크립트 코드!!에서 해당 쿠키에 접속하는 것을 막음, 자바스크립트로 로컬에서 만들어진 값으로 위조됨을 방지?, 오직 http 요청에 의해서만 자동으로 주고 받음)

				-해당 옵션이 설정 되지 않은 경우의 동작
					-기존 chrome 80버전 이전에서는 None으로 동작, 80버전 이후에서는 Lax로 동작

		-cookie를 대체하기 위한 요소 : Web Storage(localStorage, sessionStorage)
			-cookie의 경우 서버 쿠키, 클라이언트 쿠기 구분없이 서버로 전송되지만 서버로 전송될 필요가 없는 정보를 보관할 필요성이 있을때 사용할 수 있다. HTML5 스펙에 포함된 요소로 cookie와 사용 방식이 매우 비슷하다
			-클라이언트 쿠키와 유사하게 자바스크립트를 이용하여 생성하며 (브라우저 지원여부 확인 필요, 대부분 되겠지?) cookie에 비해 저장 용량의 제약이 거의 없다. 
			-기본적으로 key/value 쌍의 형태로 저장되며 value는 단순히 텍스트 형태를 넘어 스크립트의 object 형태가 될수도 있다.
			-각각의 storage는 도메인 별로 생성되어 관리 된다
			-localStorage의 경우 만료일자가 넘거나 명시적인 삭제가 없으면 계속하여 저장할 수 있다.
			-sessionStorage는 cookie의 세션과 유사하게 해당 브라우저의 세션이 살아있는 동안만 저장된다.(임시 저장소의 개념, 브라우저가 다르면 같은 도메인의 경우도 데이터가 공유 되지 않는다)
			-자바스크립트에 의해 쉽게 변형 됨으로 중요한 정보에 활용해서는 않되고 적절한 방어 코드가 필요하다.		

	-CSRF 방지를 위한 Anti-Forgery Tokens (CSRF Token) : CSRF 방지를 위하여 서버는 페이지를 내려줄때 CSRF 방지 토큰을 함께 내려준다.
		-개념적 절차 :
			-해당값은 세션 생성시 랜덤한 값으로 발급하며, session에 저장하고 session의 라이프사이클과 동일하게 관리됨 (보통 로그아웃시 세션이 바뀌겠지??)
			-CSRF 토큰값은 브라우저의 cookie에 저장 되거나 매 페이지마다 hidden 값으로 내려온다.(둘다 갖고 있을 수도 있다)
			-해당 페이지가 POST, PUT, DELETE 등 중요한 request를 전송하는 경우 해당 CSRF 토큰값을 request 해더(Option필드??)에 넣어 함께 전송 (쿠키에도 있을경우 함께 올라감)
			-서버는 올라온 토큰값이 해당하는 서버쪽 세션의 값과 일치하지 않으면(둘다 있는 경우 cookie, 헤더나 모두 일치해야함) 403 Forbidden 에러를 내려 준다.

		-CSRF 공격과의 관계 : 예시
			-해커는 숨켜진 스크립트를 통해서 특정 값과 특정인의 cookie값을 특정 서버로 보낼수 있지만 헤더로 올라오는 CSRF 값까지는 알수 없기 때문에 403을 받게 될 것이다.
				-네이버에 로그인된 session 값이 살아있는 사용자가 같은 브라우저로 해커의 사이트에 들어 갔을때
				-헤커가 사용자 모르게 스크립트로 네이버쪽의 비밀번호 변경페이지로 request를 날릴수 있다 이때 네이버 세션이 살아 있기 때문에 새 비밀번호변경 양식과 동일하게 구현해서 날린다면 변경이 가능할수 있다(예시)
				-session값은 cookie로 자동 넘어가니 어쩔수 없지만 사용자가 사용했던 CSTR Token을 알수 없기에 전달 불가 결과적으로 403을 받는다.

		-실제 적용 예시 :
			-서버쪽 :
				-Spring Security에서 CSRF 토큰 적용을 할지를 정할수 있다(WebSecurityConfigurerAdapter??)
					-특정 url 패턴으로 예외 케이스를 적용할수도 있다.

			-클라이언트 코드 : 서버로 POST, PUT, DELETE 메소드 호출시 서버가 내려준 CSRF 토큰값이 request 해데에 포함되서 올라갈수 있도록 script 구성이 필요함 (submit, Ajax 포함)

	-TabNabbing : 유명 사이트에 피싱 사이트가 팝업으로 뜨는 링크를 만든 후 피싱싸이트가 원래의 유명 사이트(opener/parent)의 주소로 유명사이트와 유사한 피싱사이트로 옮기게 해 정보를 탈취하는 방식이다.			
		-피싱방식 : 로그인 상태 네이버에서 -> 팝업으로 피싱 사이트가 열리게 처리 -> 피싱사이트가 자신의 창을 열어준 opener 객체(네이버)를 이용하여 네이버 페이지와 유사한 화면으로 앞에 열려있던 실제 네이버 페이지의 url을 옮긴다(사용자모르게) 
			-> 가짜 네이버로 돌아왔을때 로그아웃 페이지가 떠있어서 그런가보다하고 재 로그인한다 (id/pw 탈취) -> 피싱 사이트는 정보 탈취 후 진짜 네이버 페이지로 redirect 해주면 원래 로그인되어 있었기 때문에 로그인 된것 처럼 보임

		-원인 : 팝업 창에서 opener 객체를 활용할 수 있기 때문이다. (링크(<A테그>에 target='_blank' 로 하고 기본적으로 opener 객체를 이용할 수 있음)
		-방지 : 링크의 target='_blank'를 사용할때 추가적으로 rel=noopener 또는 rel=noreferrer 옵션을 함께 준다. 그러면 opener의 location변경과 같은 자바스크립트 요청이 거부된다. 
		

-해더
	-Client Cookie &  Server Cookie : 생성하는 위치에 따른 차이, 서버에서 생성하느냐 바라우저에서 js 스크립트에 의해 성성 되느냐의 차이 (클라언트
		-공통점 : 어느 cookie든 해당 url에 대한 request 시 자동으로 모두 request 해더에 포함되어 올라감
		-서버 쿠키 보안 이슈 : 
			-httpOnly : 클라이언트에서 특정 쿠키를 변조하가나 하면 어쩌나? 그런 경우를 방지하기 위해서 cookie 옵션에 httpOnly 옵션을 사용할 수 있다. httpOnly 옵션이 붙은 쿠키는 클라이언트 즉 자바스크립트를 통해 읽거나 쓰지 못한다.
				-그러나 크롬 개발툴이나 기타 툴을 통해서는 값을 읽고 수정이 가능함
			-secure : http 상에서는 주고받지 않는다. https 상에서만 주고 받아지도록 설정할 수 있다. (secure 옵션이 있더라도 툴을 통한 조작이 있을 수 있기 때문에 중요한 정보는 다루지 않도록 한다.)
		
		-클라이언트 쿠키 보안 이슈 :
			-자바스크립트를 통해 생성된 클라이언트 쿠키는 Document.cookie 객체에 생성 됨으로 script를 통해 읽기 쓰기가 가능함으로 중요한 정보에는 적합하지 않다.
			
			

	-keep-alive : Http는 state less 프로토콜의 한계를 극복하기 위해서 http(application layer) 하위 래벨인 TCP Sockek 단에서(Transfer Layer) 단에서 약간의 connection 위지를 할수 있게 해준다.
		-HTTP 해더의 Keep-Alive 값이다, 서버의 설정을 통해 적용가능하다, 완전한 표준이 아니라서 서버에 따라 보여줄수도 안보여 줄수도 있다 (apache의 경우 설정하면 보여주고 nginX의 경우 response에 표기하지 않는다.)
		-서버가 내려주는 response 해더를 통해 서버 설정을 확인할 수 있다.
			-Connection: Keep-Alive (사용중)
			-Keep-Alive: timeout=5, max=100 (5초간 socket 연결을 유지하여 같은 client에서 들어오는 rquest를 같은 tcp 세션으로 유지할수 있다. max는 해당 세션으로 100번까지만 연장할수 있다는 의미)
				-물론 해당 기능을 사용하기 위해서는 client도 해당 기능을 지원해야 함(모든 브라우저가 지원함), https(SSL)을 사용하는 경우 handshake 과정이 추가됨으로 해당 기능이 없으면 매번 handshake 해야 함으로 성능이 저하되겠지..
				-대부분의 웹서버가 해당 기능을 default로 지원함
							
	
	-content-Type : request 또는 response 하는 데이터의 형식을 알려 준다
		-보통 request때는 www-url-form-encoded, multipart/form-data, application/json
		-보통 response때는 text/html;charset=UTF-8, application/json;charset=UTF-8

	-Accept : request 전용 해더로 respose 받고자 하는 데이터 형식을 알려주는 것 (REST 서버에 요청시 xml, json, text 등 클라이언트가 선호하는 데이터 형식을 알려 줄수 있다, 요청데로 응답하는 것은 아님)
	-Accept-Charset : utf-8
	-Accept-Language : ko, en-US
	-Accept-Encoding : br, gzip, deflate
	-Origin : 서버로 request를 보내는 현재 페이지의 주소 (요청 받은 서버가 Origin 값을 확인했을때 자신의 페이지에서 요청된것이 아니면 CORS 를 발생 시킬수 있다. Agent에서 채워주는 값인가?)
	-Referer : 서버로 request를 보낼때 이 request가 어느 페이지에서 요청되었는지를 남기기 위한 해더 이다. 
		-현재 페이지에 걸려! 있는 링크로 request를 보낼때 넘어가는 값이며 브라우저 주소창에 직접 url을 치는 경우는 브라우저 화면상에 보여지는 페이지에 대한 referer 정보가 넘어가지 않는다.		
		-referer 정보는 여러가지 용도(통계분석 등)로 활용될수 있는데 보안상의 이슈가 있기때문에 자신의 페이지에서 넘어가는 페이지로 referer 정보를 줄지 말지 또는 어느정도의 정보를 줄지를 자신페이지가 정한다.
		-referer 정보를 어떻게 얼마나(Referrer-Policy, 스펠이다름!) 줄지를 설정하는 방법은 Referrer-Policy 값의 설정에 따라 달라진다. 설정 방법은 html 본문의 meta 테그를 이용할 수도 있고 http 헤더를 이용할 수도 있다.
			-메타테그 방법 : <meta name="referrer" content="no-referrer" />, 해당 페이지의 html 본문에 작성 (헤더와 본문의 Referrer-Policy가 다르면 어느게 우선하지??)
			-http reponse 헤더 방법 : Referrer Policy: no-referrer
			
			-내려온 Referrer Policy 정책에 따라 해당 페이지에서 새로운 request가(링크) 발생했을때 request 해더에 referer값을 올려준다. (Referer: https://m.amorepacificmall.com/)
			-Referrer Policy 정책 종류 : https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Referrer-Policy#directives 참고
				-관련 용어 :
					-same site : 도메인만 같으면 same site로 판단(서브 도메인까지 같아야 함), ex: xxx.xxx.com 
					-schemeful same site : http 또는 https 까지 동일해야 schemeful same site로 판단
					-origin : http(s) + domain + :port 까지 모두 동일해야 orign로 판단
			

	-X-abcdefg : X- 로 시작하는 해더는 custom headers들로 많이 알려진 X-Forwarded-For, X-Forwarded-Host, X-Forwarded-Proto, X-Powered-By 등이 있지만 사용을 권장하지 않음
		-X-Forwarded-For(XFF) : XFF는 실질적으로 Http 해더 표준처럼 사용되며 서버에 요청한 실제 클라이언트의 ip를 확인하기 위해 사용한다.
			-최종 목적지인 WAS나 Web 서버 앞단에 기타 프록시 서버(apache, ngineX, HAProxy 또는 L4)가 있는 경우 이들이 대리하여 최종 서버와 (보통 ajp로) 통신하여 반환하게 되는데..
					-이런경우 최종 서버(was)에서 request.getRemoteAddr(); 할경우 실제 클라이언트 ip가 아니라 프록시 서버 또는 L4의 아이피가 나오기 때문이다.
					- X-Forwarded-For: client, proxy1, proxy2 (최초 ip가 실제 client의 ip가 되며 콤마로 구분하여 이후의 거쳐온 proxy 서버의 ip가 들어간다.)
					-XFF는 완전한 표준은 아니기 때문에 거쳐오는 proxy(ex. WebLogic Coonector)에 따라서 해당 규칙을 지키지 않고 다른 이름의 해더를 사용하는 경우가 있다. 그럼으로 아래의 해더를 모두 참조하는 것이 좋다.
						-X-Forwarded-For, Proxy-Client-IP, WL-Proxy-Client-IP, HTTP_CLIENT_IP, HTTP_X_FORWARDED_FOR

	-Set-Cookie: response 해더를 통해 전달되며 전달된 쿠키값과 옵션에 맞게 해당 브라우저에 쿠키가 저장된다.
		----------
		Set-Cookie: JSESSIONID=4a0bdcf2-7cec-42a5-9e39-0a192e8f83d9; Path=/kr/ko/; Secure; HttpOnly (쿠키명=갑; 해당쿠키의 기타 옵션들)
		Set-Cookie: _xm_webid_1_=-1615420287; Max-Age=7776000; Expires=Thu, 10-Jun-2021 07:33:44 GMT; Path=/ (두번째 쿠키정보.. 하나의 response에 여러개의 cookie가 동시에 내려와도 상관없음)
		----------
		-브라우저에 저장되있던 쿠키값은 동일 path(지정된도메인+path)로 request가 발생했을때 자동으로 해당 서버로 올라간다.(사람이관여하지않음, 브라우저스펙상 무조건 올라감) 
			-쿠키가 서버로 올라가는 방식 : request 헤더에 가지고 있는 쿠키의 key=value;.. 들이 올라간다. (옵션값은 안올라감)
				--------
				Cookie: JSESSIONID=4a0bdcf2-7cec-42a5-9e39-0a192e8f83d9; _xm_webid_1_=-1615420287; ....
				--------
		
		
		

-참고 :
	-Servlet: Java EE 스펙 중 일부로 웹 애플리케이션 서버에서 동작한다.(ver 4.0부터 http/2 지원?)
		-지금은 spring과 같은 여러 프레임워크 및 그에 따른 라이브러리들을 통해 구현방식이 다른 여러 형태가 존재함(예를 들면 @annotation 을 사용하여 기존 web.xml에서 설정하는 부분들을 대체 하는 등)
		-javax.servlet.Servlet(가장 원형 형태의 서블릿 !인터페이스) : java(디폴트?) 스팩에 정의된  인터페이스를 구현해야 한다
			-Servlet은 서블릿 컨테이너(WAS)가 서블릿에 대해 호출하는 메소드 init(), service(), destroy(), getServiceConfig(), getServiceInfo()를 정의한 인터페이스이다.
				-------------
				public class FirstServlet implements javax.servlet.Servlet {
					ServletConfig servletConfig;			

					@Override //container가 해당 서블릿 생성시 호출해 주며 web.xml에 작성된 해당 서블릿의 <init-param> 값들을 ServletConfig 형태로 전달해 준다.
					public void init(ServletConfig config) throws ServletException { 
						this.servletConfig = config;
					}
					
					@Override
					public ServletConfig getServletConfig() {
						return this.servletConfig;
					}	
									
					@Override // 클라이언트가 요청할 때마다 호출되는 메소드(실질적인 서비스 작업을 수행)로 container가 호출해 주면서 기본적으로 req 와 res를 전달해 준다. 
					public void service(ServletRequest req, ServletResponse res) throws ServletException, IOException {
						System.out.println("driver : " + servletConfig.getInitParameter("driver")); //web.xml에 정의된 해당 서블릿의 init-param값을 가져와 필요한 곳에 사용 할 수 있다.
					}
					
					@Override
					public void destroy() {
						System.out.println("destroy() called");
					}

					@Override
					public String getServletInfo() {
						return "version=1.0;author=butterfield;copyright=butterfield 2020";
					}
				}
				
		-GenericServlet : Servlet 인터페이스를 상속하여 C/S 환경에서 서버단의 Application으로서 필요한 기능을 구현한 추상 클래스 (기본 Servlet 클래스를 보완함, 사용은 유사함)
		-HttpServlet : GenericServlet을 상속하여 service()메서드에 HTTP 프로토콜에 알맞는 동작을 수행하도록 구현한 클래스이다. (GenericServlet 클래스를 보완함, 사용은 유사함)
		
		-관련 web.xml : 작성한 servlet 클레스를 container가 인식하여 사용할수 있게 처리하는 config 이다.
			-------------
			<!-- 서블릿 선언 -->
			<servlet> (작성한 서블릿을 container에게 알려주는 의미)
				<servlet-name>FirstServlet</servlet-name>
				<servlet-class>atoz_develop.com.FirstServlet</servlet-class> 
				
				<init-param> (해당 서블릿의 init메서드 호출시 해당 값들이 ServletConfig 를 통해 전달된다.)
						<param-name>driver</param-name>
						<param-value>com.mysql.cj.jdbc.Driver</param-value>
				</init-param>
				<init-param>
						<param-name>url</param-name>
						<param-value>jdbc:mysql://localhost:3307/knou</param-value>
				</init-param>
				<init-param>
						<param-name>username</param-name>
						<param-value>user</param-value>
				</init-param>
				<init-param>
						<param-name>password</param-name>
						<param-value>****</param-value>
				</init-param>
			</servlet>
			
			<!-- 서블릿을 URI과 연결 -->
			<servlet-mapping> (어느 서브릿이 어느 url에 매핑되는지를 알려주는 의미, 크라이언트가 container 설정에 없는 url을 요청시 본인이 처리하지 못하는 케이스임으로 404를 내리게 된다.)
				<servlet-name>FirstServlet</servlet-name>
				<url-pattern>/FirstServlet</url-pattern>
			</servlet-mapping>
			-------------
	
	-Handler : Spring 환경에서 보통 핸들러라 명칭하는 것은 컨트롤러를 의미하는 경우가 많으며 Handler 메쏘드로 명칭하여 실제 request와 response를 담당하는 컨트럴러내 url 매칭이 되어 있는 메서드를 칭하는 경우가 많음
		-xxxlHandlerMapping 클래스 : 서버가 reuest를 받아(서버적 처리를 이후) spring 영역으로 request를 
	
	-SESSION: 보통 말하는 세션은 쿠키의 SESSIONID와 매칭되는 사용자 정보를 저장하기 위한 HttpSession 이다.
		-서버(WAS, Serverlet Container)가 접속한 브라우저를 구분하기 위해 내려오는 랜덤 값으로, cookie를 통해 내려온다. tomcat 기본 키값은 JSESSIONID이며 SpringSession을 이용할경우 보통 SESSION으로 내려옴
		-SESSIONID 쿠키가 내려오는 시점 : 서버에 HttpSession이 생성되는 시점에 내려온다. 생성된 HttpSession 객체와 쿠키로 내려가는 SESSIONID값이 매핑되는 형태이다.
			-그럼 HttpSession이 servlet Container에 생성되는 시점은 언제일까? (기본적으로 session은 servlet container의 메모리에 생성되는 값이며 같은 container 내에서도 servlet context를 넘어 공유되지 않는다)
				-생성 시점은 세션 관련 메소드 request.getSession() 또는 request.getSession(true) 가 호출되는 시점이다. (이 메쏘드 호출 시점에 SESSIONID가 쿠키로 내려오며 실제 session 객체도 서버에 생성된다)
					-----
					HttpSession session=request.getSession(); 해당 request에서 session 객체를 가져온다.(만들어진 세션이 없는 상태라면 새로 만든다)
					String sessionId = session.getId(); 해당 세션의 sessionId(쿠키로 넘어논)값을 확인한다.
					session.setAttribute("attName", xxObject);  해당 세션 객체에 특정 object를 저장한다.
					xxObject = session.getAttribute("attName"); 해당 세션 객체에서 특정 object를 가져온다.
					----
		
		-세션과 유사하게 사용할수 있는 메모리 공유 방식
			-ServletContext: 웹 어플리케이션 전역에서 사용할 공동의 자원을 미리 바인딩하여 서블릿들이 이를 공유할 수 있도록 한다. 톰캣 컨테이너가 실행되면 웹 어플리케이션(war)에 한 개씩 Context 객체를 생성한다.
			-ServletConfig: ServletContext는 범위를 application으로 한다면, ServletConfig는 servlet 내부로 한정된다.
			-ThreadLocal : servlet container와 상관없는 JAVA에서 제공하는 기능으로 동일한 스레드에서만 공유되는 일종의 전역적 변수이다. 그
				-그러나 웹 서비스에서 Request는 스레드기반이므로(쓰레드풀) 동일 쓰레드를 이용하여 들어온 요청에 대해서는 동일한 ThreadLocal 변수를 참조할 수 있습니다.(재사용시 반드시 remove를 통해 초기화 필요)
	
		


		
	-cookie :
		-RFC 기준 에이전트의 cookie 처리
			-At least 4096 bytes per cookie (as measured by the sum of the length of the cookie's name, value, and attributes).
			-At least 50 cookies per domain.
			-At least 3000 cookies total.
			-!!! I note this does not mean that browsers support 50 cookies * 4096 bytes == 204,800 bytes == 204KiB per domain.
			-!!! I find that Safari and Chrome start to reject cookies if the total data for a domain exceeds something between 5-8KB
			-위의서 실제로는 5-8k 까지 쿠키가 전달 된다는 의견은 서버의 http 해더 최대값에 걸리기 때문으로 예상함 (web 서버의 기본 설정 해더 최대값은 8k 임, 헤더의 최대값은 was의 server.xml에서 수정 가능)

	-request시 url에 추가 되는 파람은 어떻게 전달되는가?
		-모든 url 파람은 http 해더의 Request URL 영역을 통해 전달 됨, 다시 말해 url 파람이 길어 지면 head의 길이가 커지고 서버의 최대 허용 head 사이즈가 넘으면 문제가 될수 있음
		-http 스팩상 url의 최대 길이는 2k,

	-서버의 400 에러 : Bad Request
		-단일 쿠키의 최대 허용치 4k를 넘으면 발생 할 수 있음
		-http의 header의 최대 크기(서버에서 제한하는, 보통 8k)를 넘어서는 경우 발생 할수 있음, 해더크기는 cookie 및 기타 헤어 옵션, url 파람등 모든 값의 합산으로 정해짐.





[API 서버 플랫폼]
-정의 : API 서비스를 운영할 수 있도록 구축에 필요한 기반(공통) 기능을 제공(판매)하는 시스템(서비스)
	-구성 :
		-API G/W : 진입 포인트
		-API 포털 : 개발자를 위한 문서 및 샘플 코드를 제공
		-API 모니터링 : 서비스 상황 및 관리 기능 제공

-서비스 플로우 :
	-API 인증 : 인증된 API 호출인지 판단하기 위한 Authentication 기능, (API키 또는 OAuth 기반의 인증), Admin 웹을 사용하기 위한 인증도 포함
	-SLA management(Service Level Agreement) : 해당 서비스의 성능(?), API 호출수,  장애(?) 상황등에 대한 보장 이다
	-Mediation : 요청된 API에 대한 변형을 가하는 것
		-라우팅 :
			-요청된 해더의 API버전에 따라 라우팅 처리..
			-요청된 해더의 국가 코드에 따라 라우팅 처리..

		-Function adding : 기존 클라이언트나 서버 변동 없이 처리 가능
			-주문API에 포인트 적립 API를 추가한다든지..

		-Message Transformation : request 메시지를 변경해 준다.
			-XML을 Json으로 변경 하거나, Json 형태나 필드명을 수정하거나..

	-모니터링 : 현황 체크를 위한 어드민 기능 제공
	-Monetization : 유료화 하기 위한 API 과금 정책, 호출 건수 등등 처리 (그를 위한 기로 로그 데이터 수집)
	-포털 : 개발 문서 및 관련 가이드 제공 사이트
		-Swagger 가 대표적 오픈 소스
			-API 메뉴얼 자동 생성, 테스트 사이트 생성 기능 제공, API 테스트 request 기능 등 제공

	-API Governance : API 개발 부서들 간에 규격에 대한 표준이 없어서 발생하는 문제를 해결하기 위해 통제성을 확보
		-어느 부서는 버전을 해더에 넣고 어느 부서는 url 에 넣고 하는 등의...




[암호화]
-Hash : 데이터를 고정된 길이의 문자열로 변환하는 역할, 복호화 불가, 해당 데이터의 검증용으로 사용
	-알고리즘 : MD5, SHA1, SHA2(256~512bit), SHA3(신형? 좀 내용이 다름)..
	-활용 :
		-비밀번호 확인용 (비밀번호는 노출되지 않지만 동일한지는 확인 가능)
		-데이터 무결성(인증) 확인용 : 통신구간에서 데이터의 유실이 없는지(정확한 원본이 맞는지) 데이터의 해쉬값을 함께 보내 재 확인해 볼수 있다.
			-문제점 : 해커등에 의해 데이터가 위변조 되고 해쉬값까지 새로생성하여 전달된다면 수신자는 위변조 사실을 알수 없다.
				-해결점 : 송신자가 데이터를 해쉬할때 수신자와 공유한 비밀키를 포함하여 해쉬한 후 비밀키를 제외한 "실데이터" + "실데이터+비밀키의 해쉬코드" 를 보내는 방식으로 처리 가능 (수신자는 공유된 비밀키를 추가해서 해쉬후 비교해 본다)
					-문제점 : 데이터를 위변조 하지는 않았지만 부정하게 동일한 데이터를 수신자에게 전달할수 있다.
						-해결점 : 데이터에(해더에??) timestamp를 추가하여 오래된(+-1분??) 요청은 무시하도록 처리 할수 있다.

	-코드 : 각 해쉬 클레스를 사용하여 해쉬 코드를 생성 후 16진수로 리턴해 준다. (같은 알고리즘을 이용한다면 최종 해쉬값의 길이는 항상 일정 하다)
		MD5 : MessageDigest md = MessageDigest.getInstance("MD5");
		SHA-256 : MessageDigest md = MessageDigest.getInstance("SHA-256");




-Encryption : 데이터를 알아볼수 없도록 변환, 복호화 가능, 해당 데이터의 내용을 보호하는데 사용
	-주요 용어 :
		-encrypt : 암호화 하는 행위
		-decrypt : 복호화 하는 행위
		-plain text : 복호화된(또는 암호화 이전값) 텍스트
		-cipher text(사이펄) : 암호화된 텍스트
		
		-Symmetric key(pre shared key) : 대칭형 암호화에 사용되는 키
		-Asymmetric key : 비대칭형 암호화에 사용되는 키
	
	-대칭형 알고리즘 : DES, SEED(한국 KISA), AES(128~256)..
		장단점 : 상대적으로 속도가 빠르다, 그래서 장문의 데이터를 암호화 하는데 유리, 하나의 키만 존재함으로 전달된 비밀키가 노출되면 누구나 복호화 될수 있다.
		코드 : 시크릿 키값(맘대로설정)으로 바이트어레이를 만들어 암호화에 이용, 16byte면 AES128, 32byte면 AES256이 된다. 암호화된 데이터를 Base64인코딩(디코딩)하여 리턴(웹에서 주로 사용해서 그런가??)
			AES256 :

	-비대칭형 알고리즘: RSA(SSL, TLS), Rabin..
		장단점 : 상대적으로 속도가 느리다, 그래서 짧은 데이터를 암호화 하는데 유리, 비밀키가 쌍(public, private) 으로 존해함 그래서 전달된 public 키가 노출되어도 복호화 되지 않고 private 키를 갖은 서버만 가능
			-정확히는 public키로 암호화된 값은 private키로 복호되며 반대로 private키로 암호화된 값은 public 키로 복호된다.(하지만 보통 이렇게 private 키로 암호화 하진 않는다.)
		코드 : KeyPair 클레스를 이용하여 한상의 키를 만들어 낸다. 암호화할때는 public키로 하고 복호화할때는 private 키를 이용한다. 암호화된 데이터를 Base64인코딩(디코딩)하여 리턴(웹에서 주로 사용해서 그런가??)
			RSA : KeyPair keyPair = gen.genKeyPair();



[CGI]
 -CGI : Common Gateway Interface, 웹서버가(apache)가 동적 결과를 만들어내지 못하는 점을 보안하기 위해 웹 서버 프로그램과 외부 프로그램과의 연계법을 정한 것이 CGI이다 (웹서비스 초기 시대의 방식?)
  -CGI는 어디까지나 인터페이스이며, 특정 플랫폼에 의존하지 않고, 웹 서버 등으로부터 외부 프로그램을 호출하는 조합을 가리킨다.(CGI를 경유해 실행되는 프로그램을 CGI 프로그램이라고 부른다.)
	-기본적으로 개발 언어의 구분없이 사용이 가능하나 주로 펄, 파이선, 루비 등이 사용 된다
	-요즘?의 추세는 웹서버의 프로세스로서 인터프리터를 상주시킴으로써, CGI로부터 프로그램을 호출해 부하를 줄임으로써 성능을 개선한 자바 서블릿이나 mod_perl, mod_php, mod_python, FastCGI 등도 공개되었다. 
		-mod_xx(modification) 방식은 웹서버에 해당 언어를 직접 처리할수 있는 인터프리터 모듈을 추가하는 방식이다.(그냥 CGI의 경우, 파이썬의 경우.. 웹서에 xx.py 파일이 있을때 이 파일에 대한 처리는 별도 설치된 파이썬 인터프리터가 처리)
	
	-CGI 동작 방식 및 흐름 :
		-클라이언트 http request 요청, get 데이터는 CGI 프로그램의 환경변수로 활용하고 post 데이터는 CGI 프로그램의 표준입력으로 활용하는 것이 CGI 표준의 핵심? 이다.
				-ex : uri = http.xxx.com/companyInfo?nation=korea&companyName=xxCompany... (body : id=xxId, pw=xxpw, ....)
				
			-웹서버는 들어온 request에 대해 companyInfo에 해당하는 CGI가 있는지 확인해서 해당 CGI를 통해 CGI 프로그램을 실행함 (입력된 nation=korea&companyName=xxCompany 쿼리 스트링은 해당 CGI를 실행할때 param으로 작용됨)
				-CGI 프로그램이 쿼리 스트링값을 참조하여 실행되면 이후 body 값을 입력값으로 받아 들여 그에 따른 결과를 반환한다.
					-당시? 대부분의 클라이던트 프로그램이 브라우저 이었기 때문에 CGI 프로그램이 반환하는 결과값은 보통 html 내용이었다. (이미지데이터가 바로 내려가는 경우도 있을 수 있음)
						-Pear ex: (해더)print "Content-type: text/html\r\n";... (body)print "<html>..<body><h1>xxCompany 회사 정보</h1><br>블라블라.. </body>..</html>" 
			
			-웹서버는 CGI 프로그램이 반환한 결과를 거의 그대로(http status 정도의 변형) 클라이언트 쪽으로 내려 준다.
		-클라이언트는 내려받은 html 문서를 브라우징 하여 사용자에 보여 준다.

	-fastCGI : 상호 작용 프로그램을 웹 서버와 통신하기 위한 바이너리 프로토콜이다. FastCGI는 초기 공용 게이트웨이 인터페이스(CGI)의 변형이다. 
		-FastCGI의 주 목적은 웹 서버와 CGI 프로그램 간 통신 시 발생되는 부하를 줄임으로써 서버가 한 번에 더 많은 웹 페이지
 




[Directory Service (Name Service)]
	-개념 : 





 
[Apache WEB Server]
-개념 : Http 통신을 지원하는 web 서버

-명칭 : 적용 운영체제에 따라 httpd(http deamon, RHEL 6.2) 또는 apache2(Ubuntu)라는 이름으로 설치 된다. (apache2가 좀더 세로운 버전 인듯?? 기본설정의 편리함, 디테일한 추가 옵션등?)
-상품 점유율 : apache, enginX, google Web, IIS...
	-enginX : 최근 아파치 다음으로 가장 많이 사용되는 web 서버로 아파치가 초대규모 트래픽을 지원하지 못하는데 비해 enginX는 초대규모 트래픽을 감당할 수 있다. (아파치와 enginX을 함께 사용하는 추세)
	
-주요 features :
	-Handling of static files, index files, auto-indexing, and content negotiation : static 파일들을 client에 제공한다.(기본적인 web 서버 기능)
	-.htaccess per-directory configuration support :
	-Perl, PHP and Lua scripts are already build :
	-Loadable Dynamic Modules :
	-Apache is compatible with IPv6 : 
	-Apache Server supports HTTP/2 :
	-gzip compression and decompression :
	-FTP connections are possible with proper module :
	
-기타 :
	-apache 웹 루트의 폴더는 보통 public_html 또는 www 로 네임한다.
	-hotlinking : 타 사이트의 리소스(이미지, css, js 등)를 링크를 통해 바로 끌고 가는 형태의 링크(타 사이트의 서버 및 트레픽 리소스를 사용하게 됨으로 옳지 않음)
	


[tomcat]
-서버 프로파일 설정 :
	-위치 : tomcatHome/bin/setenv.sh
	-내용 : JAVA_OPTS="$JAVA_OPTS -Dspring.profiles.active={profile_name}"
	
	-application-xxx.yml : 기본이 되는 yml 파일로 해당 프로파일에서 특정 프로퍼티 벨류를 못 찾을 경우 application.yml 파일에서 찾게 되있다.
		-ex : env 가 stg 일경우 
			-application-stg.yml에서 환경 프로퍼티를 찾게 되있음 만약 해당 yml에서 찾을 수 없는 값이 있는 경우 기본 파일인 application.yml 에서 찾게 됨
			
-server.xml 과 web.xml의 관계
	-server.xml은 서버 전체의 큰틀(?)에서의 설정을 담당하고 web.xml은 해당 web어플리케이션(WAR)의 동작과 관련한 설정(description)을 담당한다. 
		-그래서 server.xml은 tomcat 내부 conf 디렉토리에 위치하고 web.xml은 각각의 war파일에 존재한다 (war로 배포하지 않는경우 각 웹app 의 webapp/WEB_INF 내부 있음)

-Apache + mo_jk(Apache-Tomcat Connector Module) + tomcat 구성 :
	-배경 :	
		-Apache : 오직 정적인 컨텐츠(파일형태, html, img, js, css 등)만을 내려주도록 설계된 웹서버로 초창기 웹서비스 시절에는 이것만으로 충분했기 때문, 
			-이후 다이나믹한 컨텐츠를 내려주기 위해 tomcat과 더블어 사용됨, 여전히 static한 컨텐츠를 내려줘야하는 부분이 있고 이를 부하분산 차원해서 지원, 또 보안상 tomcat을 뒤에 둘수 있고 mo_jk등을 통해 여러 형태의 로드벨런싱도 가능하게 함
			
		-mo_jk : 아파치 파운데이션에서 제공하는 아파치와 톰겟을 연결하게 해주는 커넥터 역할, .so 파일로 apache 내부에 블러그인 형태로 넣어 주면 됨(추가적인 config는 필요)
		
		-tomcat : 아파치가 단순히 static한 컨텐츠를 내려주는 서버라면 tomcat은 서블릿로직을 이용하여 다양한 결과를 실시간으로 만들어 내 내려 줄수 있다. 아파치가 없더라도 static한 컨텐츠도 내려줄수 있음(apache가 이부분에서는 더 잘하지만..)
			-servlet(java servlet) : tomcat이 제공하는(정확히는 java EE 스펙의 일부) tomcat에서 다이나믹한 웹 기능을 구축하기 위한 APIs 또는 그들을 이용해 만든 클래스(=Controller) 이다(CGI,PHP등이같은맥락). 
				-그래서 tomcat을 Servlet container 라고도 함
			-jsp : HTML 내에 자바 코드를 삽입하여 동적 웹페이지를 생성할수 서버 사이드 스크립트 언어이다 (servlet과 마찮가지로 java EE 스펙이며, ASP, PHP, .Net과 같은 맥락)
				-실제 jsp의 동작을 보면 실행시 jsp 코드를 java Servlet으로 변형하여 동작한다.(html과 섞어 쓰기 편하도록 만들어진 스크립트 언어정도의 역할이다)
			
			-JSTL(JavaServer Pages Standard Tag Library): 
			
	-Step : https://www3.ntu.edu.sg/home/ehchua/programming/howto/ApachePlusTomcat_HowTo.html
		-1. Install Apache HTTP Server (run on port 7000)
		-2. Install Tomcat (run on port 8080) + 예시를 위해 server.xml 에 /examples 와 /ws 두개의 컨텍스트 추가
		-3. Download the Apache-Tomcat Connector Module : apache와 tomcat을 연결하기 위한 adapter 모듈이다. 이 모듈은 TCP 바이너리 프로토콜인 AJP1.3(tomcat쪽에 해당 포트가 8009가 오픈되있어야 한다)을 사용한다.
			-다운받은 mod_jk.so 모듈은 아파치쪽 ..\apache\modules 에 저장되야 한다.
			-mod_proxy : ???
		
		-4. Configure Apache : mod_jk가 로딩되고 초기화 될수 있도록 아파치 설정이 필요
			-

		



-server.xml : 톰켓 동작 전반에 대한 설정으로 기타 초기값 및 서비스 구성에 대해 정의 한다. https://tomcat.apache.org/tomcat-5.5-doc/config/engine.html
	-Server : 가장 최상위, 서버를 정지시키는 명령어와 명령을 받기 위한 포트를 구성할 수 있다 (ex: port="8005" shutdown="SHUTDOWN" ), 클래스를 추가하여 shutdown을 위한 특정 클래스 구성 가능
		-Listeners :
		-Global Naming Resources :
			-Resources :

	-Service : 논리적인(사람이 인식하는) 서비스 단위를 구성한다. (ex: 네이버 메일, 네이버 메모, 네이버 웹튼..)
			-Service 내부에 connectors를 통해 서비스 가능한 port 번호가 정의 됨으로 별도의 웹서버 없이 바로 was로 연결되는 서비스의 경우 80포트를 사용하기 위해서는 service가 하나만 존재해야 한다.
			-톰캣의 전체 로그에서 서비스 명으로 구분되어 진다. (물리적으로 동일한 서버를 사용하지만 각각의 독립된 서비스로 구분되어지는 단위? 실제로는 서비스를 여러개 두기보단 tomcat 자체를 분리하여(독립된server.xml) 사용하는듯..)
			
		-Connectors : 여러개의 커넥터를 갖을수 있다. 해당 커넥터의 포트로 들어온 request를 해당 Engine으로 전달해 준다. http(http1, http2), ajp(web서버를 통해 들어오는 요청) 두 커넥터를 동시에 사용 할 수 있다.
			-HTTP Connector : tomcat은 servlet container의 역할을 매인으로 하지만(서블릿을통한 다이나믹한 결과를 제공) http connector를 통해 브라우저로 부터 들어오는 http 요청에 대한 응답도 처리할 수 있다.
				-http 기본 커넥터로 보통 8080, 아파치와의 연동을 위해 ajp 포트를 쓴다면 사용하지 안하도 됨, 많은 추가 attr를 갖는다(ex: maxHttpHeaderSize)
				-보통은 앞단에 아파치서버를 두고 static한 컨테츠에 대한 처리를 담당하고 아파치가 proxy 역할을 담당하여 다이나믹한 요청에 대해 tomcat의 AJP 포트로 요청을 한다.(각각의 부하 분산의 의미도 갖는다)
			
			-AJP(Apache JServ Protocol) Connector : apache 연동을 통해 들어오는 request를 받기위한 커넥터, 아파치 연동이 없으면 사용하지 않아도 됨,
				-AJP (Apache JServ Protocol) : Web 과 WAS 를 연결하기 위한 바이너리 타입의 프로토콜이다. AJP 프로토콜을 모든 WEB나 WAS에서 지원하는 것은 아니지만 많이 지원하며 apach와 tomcat이 대표이다. (오랜된 만큼 안정적)

			-SSL Connector : ssl/tls를 사용하는 request를 위해 구성할 수 있다. 인증서 정보등의 attr를 갖고 있다.
			-!! HTTP, AJP에 있는 redirectPort는?? : ssl/tls로 들어오는 요청이 있는경우 리라이렉트 해주는 포트, SSL Connector가 살아 있어야 잘 되겠지??

		-Engine : 실제 request(Engine은 request의 header를 사용하는 듯?) 처리를 진행하는 진입점으로 적절한(주어진) host(virtual, 실제 리소스가 있는)와 함께 처리를 진행 한다.
				-attr : defaultHost=request를 처리하기 위한 기본 host 네임(아래 호스트 엘레먼트 이름과 연결됨), name=로깅을 위한 식별자, jvmRoute=로드벨런싱처리시 session 생성 관련
			-Cluster : 서비스 2중화 구성을 위한 요소로 리소스 및 session 에 대한 이중화 처리 설정으로 복잡성이 높으며 보통 기본값 사용을 권장함
			-Realm : ???서버를 JDBC, JNDI(LDAP)과 같이 다른 서비스와 연결하기 위한 요소???

			-Host :	도메인과 맞물리는 하나의 가상 호스트를 생성하는 개념이다.
					-attr인 name으로 들어온 도메인에 대해서 내가 (webApp,실제서비스코드)가 담당하겠다는 의미, Engine이 request의 해더까진 분석할수 있기 때문에 적적할 호스트로 줄수 있겠지??
					-Engine 엘레먼트의 defaultHost로 지정 호스트는 반드시 존재 해야함.
					-Alias 엘레먼트를 통해서 하나의 host(virtual)에 여러 도메인을 연결할 수도 있다.
					-<host name="xxx.com" : xxx.com으로 들어온 요청인 경우 해당 호스트에서 처리하겠다는 의미 (호스명은 대소문자 구분하지 않음)
					-local PC에서 호스트 파일을 수정후 브라우저에 가상 도메인을 입력하여 테스트 해볼수 있다.

					-attr인 appBase : 해당 호스트가 사용할 웹어플리케이션!들!(!!여러개의 war들)의 위치를 알려 준다. 절대 경로 사용가능, 상대 경로인 경우 $CATALINA_BASE 부터 시작
						-!!다시말해 하나의 Engine은 여러개의 호스트를 갖을 수 있고 또한 여러개의 war파일들로 동작할 수도 있다.

					-attr인 unpackWARs : true면 war파일이 생기면 war를 풀어서 사용, false면 war파일을 풀지 않고 사용(풀지 않고도 사용 가능 한듯??...)
					-attr인 autoDeploy : 통캣이 실행중인 경우 재시작 여부로 true면 새로운 변경이 발생시 자동 재시작, false면 자동으로 재시작 하지 않음

				-Context : Host로 들어온 특정 url 패턴에 대해서 어떤 war가 처리할지를 정한다. 하나의 Host에 여러 contex가 존재할 수 있다.
					-!! context가 여럿인 경우 server.xml에 정의 하지 말고 별도 파일로 정의하라고 권하는것 같음(server.xml에 정의해도 동작 함)
					-$CATALINA_HOME/conf/context.xml 에 작성한 경우 모든 webApp들이 로드(사용?)할 수 있다.
					-$CATALINA_HOME/conf/[enginename]/[hostname]/context.xml.default 로 작성하면 해당 호스트에 속하는 webApp들이 로드(사용?)할 수 있다.
					-$CATALINA_HOME/conf/[enginename]/[hostname]/foo#bar.xml 로 작성하면 context path가 /foo/bar 인 애들의 것이다.(???) (/에 대한 파일은 ROOT.xml)
					-webApp가 war로 배포되고 /META-INF/context.xml 가 존재하면 $CATALINA_HOME/conf/[enginename]/[hostname]/로 카피하고 context에 맞게 이름을 변경한다.
						-서버쪽 $CATALINA_HOME/conf/[enginename]/[hostname]/ 에 이미 파일이 존재하는 경우는 옮기지 않는듯??? 좀더 확인 필요
						-/META-INF/ 정채가 뭐지??

					-attr인 path는 uri를 통해 진입하는 path의 시작점이다.
						-<Context path="/" docBase="ROOT" : xx.com/로 진입시 처리해 주는 webApp(war)정의, 상대 경로의 경우 appBase 하위에서 찾는다.
						-<Context path="/myApp" docBase="D:/html/myApp" : xx.com/myApp/로 진입시 처리해 주는 webApp(war)정의, 절대 경로도 사용할 수 있다.
						-!! Spring Boot에서 yml 환경 설정을 통해 정의 할수도 있다.
							-server:
								-port: 8080 //서버 포트
								-context-path: /kr/ko //컨텍스트 페스
								
					-attr인 reloadable가 ture인 경우 /WEB-INF/classes/ 와 /WEB-INF/lib 의 변경을 실시간으로 감지하여 반영해 준다. (상용에서는 사용 비권장)
					-attr인 privileged ture인 경우 해당 context에서 다른 context의 servlet을 로딩할수 있다???

					-Resource : !!!???


				-Valve : Host나 Context 또는 Engine 영역의 request processing pipeline 단에서 특정 작업을 처리하는 component들에 대한 설정을 명시한다. (파이프라인에서 동작하는 벨브??)
					-여러 Valve가 존재하며 각각의 역할이 있다. (사용하고 싶은 것들에 대해서만 정의 하면 된다, 상대 경로가 필요할 경우 $CATALINA_HOME = $CATALINA_BASE 사용 가능)
						-Access Log : 엑세스 로그와 관련된 설정
						-Remote Address : request를 보내는 ip에 대한 필터링을 처리할 수 있다.
						-Remote Host Filter : request 도메인에 대한 필터링을 처리할 수 있다. (레퍼럴을 보고 판단하나?)
						-Request Dumper : 디버깅을 위해 request 처리에 대한 상세한 정보를 남기나 문제가 있어 deprecated 됨
						-Single Sign On : ??? tomcat이 자체적으로 가지고 있는 인증기능(conf/tomcat-users.xml을 통한?)이 있는데
								-이것들은 기본적으로 host 내의 각각의 context 마다 별도 인증됨
								-Single Sign On 통해 같은 호스트상의 서로 다른 context 끼리도 인증을 연결해 주기위한 처리???
								-!!어떤 내용인지 realm 과 session의 동작과 더블어 좀더 확인이 필요!!!

						-Basic Authenticator : tomcat이 제공하는 기본 인증 기능(Basic Authenticator)에 대한 설정, 설정안해도 기본제공됨, 기본 셋팅에서 수정 필요시 재 정의
							-Basic Authenticator 설정 기본 : conf/tomcat-users.xml에 Role과 User/PW를 설정하여 사용가능
							-보통 Tomcat 관리 페이지(기본으로 제공되는 ROOT war 기능)를 이용할때 tomcat-users.xml를 이용할 수 있다.
							-?? http의 Basic Authentication 과 session 그리고 Role, User의 매칭, 그에따른 크리덴셜 관리가 실제 어떻게 이루어 지는지 좀더 살펴 봐야 함

						-Digest Authenticator : Basic Authenticator과 마찮가지로 tomcat이 제공하는 기본 인증과 관련된 기능(설정안해도 기본 제공)
						-Form Authenticator : Basic Authenticator과 마찮가지로 tomcat이 제공하는 기본 인증과 관련된 기능(설정안해도 기본 제공)
						-SSL Authenticator : Basic Authenticator과 마찮가지로 tomcat이 제공하는 기본 인증과 관련된 기능(설정안해도 기본 제공)

	-GlobalNamingResources : ????


	-환경 변수 :
		-JAVA_OPTS : JAVA VM 의 메모리 설정과 관련 있는 옵션이다. tomcat이 별도로 설정하지 않는 경우 JAVA_OPT 설정을 따라간다. 톰캣만의 독자 적인 설정을 하고 싶으면 CATALINA_OPTS에 적용하면 된다.
		-CATALINA_HOME : tomcat 설치 경로

	-web.xml : ???



[Proxy]
-Forward Proxy : 사내망에서 외부 접속을 할경우 직원의 request를 캐치해서 외부로 연결해주는 중계자의 역할, 아웃바운드에 대한 프록시 역할 (응답 또한 proxy 서버를 통해 받는다)
	-보안 및 관리적 측면 : 보안 및 관지적 측면에서 외부 접속에 대한 차단 및 관리가 가능하다 
		-특정 사이트 접속 금지, 특정 사이트의 특정기능(이메일) 접속 금지, 특정인에 대해서만 접속 차단 및 사용이 가능하게도 설정 가능 (솔루션 예 : Palo Alto Networks 서버)
		
	-cache 측면 : 일반적으로 proxy서버는 케시 기능을 갖고 있어서 자주 요청되는 request에 대해서 캐시정보를 보유하여 빠르게 처리가 가능 하다.
	

-Reverse Proxy : 외부에서 내부(ex:WAS)로 request 요청시 Reverse Proxy를 거쳐서 들어온다. 인바운드에 대한 프록시 역할 
	-보안 및 관리적 측면 : 외부로 부터 내부 주요 서버들을 보호하기 위해 사용한다. 외부와 내부의 중간 네트워크 단계(DMZ)에 리버스 프록시를 두고 이를 통해 내부 중요 서버(WAS, DB)를 보호한다.
		-DMZ에 올라가는 서버 예 : Proxy(Apache, Nginx), 메일, FTP 등
		-Proxy 서버 뒤의 WAS 서버에서 실제 클라이언트의 ip 확인이 필요하다면 HTTP 해더의 X-Forwarded-For(XFF) 필드를 참고 할수 있다. (WAS에서 그냥 REMOTE_ADDR를 사용시 Proxy ip가 나옴)
		
-Proxy와 GateWay 의 의미상의 차이 :
	-Proxy는 보안 및 관리적 측면에서 by pass를 할지 말지, 로드벨런싱 및 장애 회피를 어찌 할지 에 대한 처리 및 cache 기능이 강한 반면 (간혹 gateway 처럼 데이터의 변형을 가하는 경우도 있다.)
	-GateWay는 서로 다른(프로토콜이 맞지 않는?) 서버를 연계할때 어답터의 역할처럼 데이터를 변형하여(?) 서로 이해하는 형태로 변형하기 위한 역할적 측면이 크다.
	







[DHCP 서버]
-DHCP(Dynamic Host Configuration Protocol) : 호스트의 IP주소와 각종 TCP/IP 프로토콜의 기본 설정을 클라이언트에게 자동적으로 제공해주는 프로토콜
	-이 프로토콜을 이용하여 정보를 제공, 관리하는 주체를 DHCP 서버라 한다. (windows, linux와 같은 서버에 설치된 서비스 일수도 있고 해당 기능을 포함한 라우터, 공유기가 될수도 있다)
	-DHCP에 대한 표준은 RFC문서에 정의되어 있으며, DHCP는 네트워크에 사용되는 IP주소를 DHCP서버가 중앙집중식으로 관리하는 클라이언트/서버 모델을 사용하게 됩니다. 
	-DHCP지원 클라이언트는 네트워크 부팅과정에서 DHCP서버에 IP주소를 요청하고 이를 얻을 수 있다.

	



[DNS 서버]
-DNS 정의 : ip->이름으로 (sub.name.com A x.x.x.x)
-역사 : DNS(1983년시작) 서버 이전에는 Stanford Research Institute 에서 유명 사이트에 대한 host파일(ip)을 관리했고 사람들이 해당 파일을 다운받아 자기의 host 파일을 받아서 접속을 했다.
-DNS 서버 운영 :
	-자체 서버 : 외부로 public하게 오픈할 수 있음
		-조직이 큰 경우 자체 DNS 서버를 운영할 수 있다.
		-이점 :
			-pc에 사내 자체 DNS만 사용하게 강제하여 보안 및 관리적 측면외에 불필요한 외부 접속을 차단할수 있다.
			-사내 내부 ip들에 대해서도 직접 도메인을 할당하여 사용할 수 있다.
			
	-public DNS : 외부로 공개적으로 오픈된 일반적인 DNS (기관이나 ISP에서 운영하는거???)
	
	-온라인 서비스 서버 이용 :
		-보통 도메인을 구매하면 구매 대행자사(가비아)가 해당 도메인의 기본 DNS의 역할을 해준다. 보통 대행사의 my페이지등을 통해서 서브 도메인 추가 또는 ip 셋팅등의 처리함. 
		-구매한 도매인의 DNS 서버를 바꾸고 싶다면?
			-구매 대행사의 페이지에서 DNS 바꾸는 메뉴를 보통 제공함 (해당 도메인의 DNS ip 또는 DNS도메인 명을 입력하게 함)
				-위와 같이 대행사를 통해 DNS 서버를 변경했으면 변경한 새 DNS 서버에 해당 도메인에 대한 A 레코드를 추가해 줘야 함 (새 DNS쪽 : sungilry A x.x.x.x )
				
	-편리한 부가 기능을 제공하는 온라인 DNS 사이트 : 
			
-DNS 요청 흐름
	-client(sungil.com요청)->local host 파일 확인, 없으면 기본(local) DNS 서버로 요청, 기본 DNS 서버의 주소는 어떻게 알지??(ISP(통신사)업체가 랜 접속시 기본 DNS 서버 정보도 셋팅한다(자동(DHCP)/수동))
		-client-> 자신의 기본 DNS에 문의(기본 DNS는 보통 통신사의 DNS가 된다)
			-기본 DNS가 확인해서 실제 ip를 알고 있으면 실제 아이피를 내려주고 자기도 모르면 Root DNS에 문의(모든 DNS는 Root DNS 정보는 기본적으로 가지고 있다)
				-Root DNS는 .com, .net 등 각각을 담당하는 top레벨 DNS 서버의 정보를 알고 있음, Root는 .com을 담당하는 topDNS 정보를 다시 기본DNS에 내림(a.gtld-server.net NS x.x.x.x)
					-기본 DNS는 다시 top DNS에 문의
						-Top DNS가 실제 ip를 알면 알려주겠지만 top DNS는 몰르겠지(??) 그래서 그 주소를 알고있는 하위 DNS 서버 정보를 다시 알려줌(ns.kt-idc.com NS x.x.x.x)
							-기본 DNS는 다시 하위 DNS(보통 우리가 도메인을 구입하고 등록 대행해 주는 회사(Registrar)가 됨)에 문의
								-하위 DNS가 비로서 해당 도메인의 실제 주소를 알려줌 (sungil.com A x.x.x.x), 만약 모른다면 알고 있는 하위 DNS를 또 알려주겠지??(ns.sk-idc.com NS x.x.x.x)
									-기본 DNS는 해당 도메인의 실제 ip를 받았음으로 최종적으로 어플리케이션으로 내려 준다.
										
	-각 DNS는 확인 요청이 들어와서 하위 DNS를 통해 최종 ip를 얻게되면 자신이 해당 정보를 케시하여(얻은 정보의 TTL 시간동안) 다시 요청이 들어 왔을때 하위 DNS에 묻지 않고 바로 실 ip정보를 내려준다??

-도메인 생성 및 DNS 서버와 연결되는 과정 (행정적 측면)
	-관련 주체 :
		-ICANN : 전세계 DNS 정보를 관리하는 비영리 단체로 root DNS를 운영함(a.root-servers.net) 
		-등록소 (Registry) : ICANN 의 하위인 Top 레벨 DNS 서버를 관리하는 기관 또는 기업? (.com, .net 등 top레벨 도메인에 따라 분리 운영되는 듯??)
		-등록 대행 업체 (Registrar) : 실제 개인들로 부터 원하는 도메인 구매 과정의 처리를 진행해주는 기업(ex가비아)
			-도메인 구매 가능 여부 확인 및 구매 행정(내부적으로 상위 기관으로 돈을 내고 제출하는 자료가 있겠지??, 물론 전산으로 처리되겠지만)
			-구매 처리가 되면 해당 도메인과 실제 서버를 연결해 주기 위해 하위 DNS에 등록이 필요한데.. 보통 등록 대행 업체가 자체 DNS를 운영하여 자신 고객의 도메인에 대한 DNS 기능을 해준다.
			-고객이 새 도메인을 구매하면 자신의 DNS에 해당 도메인과 고객 서버의 ip를 매핑해 주고(물론 관리 페이지를 통해 고객이 직접 하겠지) 해당하는 top 레벨 DNS에대 해당 도메인의 하위 DNS가 자신임을 알려논다.
			
		-개인 : 특정 도메인을 사용하고 싶은 사람

-주요 DNS 레코드 타입 : DNS에 기록되는 여러 형태의 데이터 타입을 정의 함
	-A(address) : sungilry.com A x.x.x.x (해당 ip는 실제 sungilry.com의 최종 서버 ip임)
	-CNAME(canonical) : my.sungilry.com CNAME sungilry.com (my.sungilry.com 은 sungilry.com의 링크 도메인이 된다. 실제 ip를 확인하기 위해서는 sungilry.com을 확인하면 됨)
		-여러게의 이름을 같은 서버(같은 ip)로 매핑하고 싶을때 가각의 도메인에 각각 ip를 할당하면 나중에 실 서버의 아이피가 바뀌면 모든 도메인 메핑을 바꿔줘야 함으로 대표를 세우고 나머지가 링크하는것이 편함)
			-a.com CNAME sungilry.com , b.com CNAME sungilry.com , c.com CNAME sungilry.com , sungilry.com A x.x.x.x 하면 나중에 sungilry.com A x.x.x.x만 바꾸면 모두 적용됨
	
	-MX(mail exchange) : SMTP 서버가 전자 메일을 적절한 호스트로 라우팅하기 위해 사용(도메인에 대해 둘 이상의 메일 교환 서버가 있으며 각 도메인에 우선 순위가 설정됨) 추가 확인 필요!???
	-NS(name server) : sungilry.com NS x.x.x.x (해당 도메인의 주소를 알고 있는 DNS ip를 알려줌, 해당 DNS로 가서 다시 물어보라는 의미, 해당 DNS에서 더 하위 DNS를 내려 줄수도 있음??)

-기타 DNS 옵션
	-TTL (time to live) : local DNS가 서버의 ip를 획득했을때 (타 DNS로 부터) 얼마동안 그 데이터를 캐시 할지의 시간(Sec)이다
		-짤게 300정도, 짧으면 ip 변경시 다른 DNS로의 전파가 빠르지만 평소에 변경이 없더라도 300이후에 타 DNS의 요청이 들어오기 때문에 결국 사용자의 접속 속도는 느리게 느껴질 수 있다.
	
-nslookup 명령어 : 
	-참고 :
		-모든 명령어시 기본 DNS 정보는 함께 보여줌
		-권한 없는 응답 : local(기본) DNS가 다른 DNS로 부터 가져온 정보를 내려줬다는 것임
	
	-nslookup sungilry.com : sungilry.com의 아이피 주소
	-nslookup -type=ns sungilry.com : sungilry.com의 공식(A레코드를 실제로 갖고 있는) DNS 서버 정보를 알려줌, 그런데 실제로 나올때도 있고 안나올때도 있음..???
	-nslookup -type=any sungilry.com : 모든 정보를 보여준다는데 실제는 별 내용이 없음 ???
	
-DDNS : ????	

-기타										
	-hosts 파일 : 해당 컴퓨터만을 위한 일종의 DNS 기능을 수행한다.
		-활용 :
			-로컬에서 사내 DNS가 별도로 없는 환경에서 lan으로 연결된 사용자 pc를 호스트 네임으로 접속할 수 있게 해준다.
			-서버 테스트를 위해서 특정 ip로 실도메인과 동일한 방법으로 연결될 수 있도록 해줄수 있다.
			-사내 솔루션을 통해 host 파일을 조정하여 보안상?의 이유로 특정 사이트(mail.naver.com.. 을 127.0.0.1로 매핑해버림)에 들어가지 못하게 처리할수 있다.(DNS로 하는 방식처럼)
			-특정 도메인(네이버, 옥션..)의 실제 ip를 설정하여 public DNS를 타지 않게 할수 있다(접속 속도가 다소 빨라지겠지.. 실제로 사용은 안할듯..)
			
		-위치 :
			-windows 계열 : C:\Windows\System32\drivers\etc\hosts
			-linux 계열 : etc/hosts 
				-sudo nano etc/hosts

		-내용 : 100.100.100.100 mypage.com										
	
	
	-유명 DNS 서버 : 1.1.1.1 (자체 측정 자신이 가장 빠르다 함)
	
	
	
	
[CDN]
-개념 : 기본적으로 사용자가 원격지에 있는 서버(Origin Server)로 부터 Content(예. Web Object, Video, Music, Image, Document 등)를 다운로드 받을때 가까이 있는 서버에서 받는 것보다 시간이 오래 걸리므로, 
		-사용자와 가까운 곳에 위치한 Cache Server에 해당 Content를 저장(캐싱)하고 Content 요청시에 Cache Server가 응답을 주는 기술입니다.
		-CDN은 오리진이라고도 불리는 콘텐츠 서버와 엔드유저(클라이언트) 사이에서 컨텐츠를 전달하는 역할을 합니다

-CDN 캐싱 방식 :
	-Static caching : origin 서버의 컨텐츠를 한번에 모두 cache 서버로 복사해 두고 서비스하는 방식(국내 CDN이 주로 사용하는 방식, origin 패치후 강제적으로 다시 읽어 가도록 CDN 사이트에서 조절 가능) 
			-각각의 Content는 일정 시간이후 origin 서버로 부터 다시 복사해 오게 설정 할수도 있다.

	-Dynamic Caching : Origin Server에 있는 Content를 운영자가 미리 Cache Server에 복사하지 않음 
			-사용자가 Content를 요청시 해당 Content가 없는 경우 Origin Server로 부터 다운로드 받아 전달한다.
			-각각의 Content는 일정 시간이후 Cache Server에서 삭제될 수도 있다.
				
-플로우 : 
	-sungilry.com 사용자는 해당 도메인을 CDN DNS에 등록 하거나(sungilry.com 의 실제 주소(A레코드)를 CDN DNS가 관리 하는 것임) 
			-보통은?? 해당 도메인의 DNS 서버에 CDN으로 부터 할당 받은 CDN 서버 도메인을 CNAME 레코드를 통해 연결해 주도록 처리한다. 
					-나의 DNS에 : sungilry.com NS sungilry.com.cdn.com (sungilry.com 으로 요청시 실제 CDN 서버로 진입 할수 있도록)
			
	-고객이 sungilry.com request하면 PC는 Local DNS에 해당 ip를 물어보게 되고 DNS는 결국 CDN의 주소인 sungilry.com.cdn.com 의 ip를 주게 된다.
		-!!! 여기서 CDN DNS는 sungilry.com.cdn.com의 주소를 줄때 요청자와 가장 가까운 CDN 서버의 정보를 주겠지?(CDN DNS에 sungilry.com.cdn.com 의 A레코드는 지역별로 분산된 여러 ip가 있겠지???)
				-??? 근데 CDN DNS는 어떤 방식으로 고객에게 가장 가까운 CDS 서버의 ip를 내려 줄까??? GLBS(Global server load balancing) ???? 확인 필요
					-일반적으로 DNS는 하나의 도메인에 여러 ip를 할당 할수는 있지만 장애 회피(사실 한쪽에 장애가 난다고 인지하지는 못함, 2개의 ip라면 50%는 장애 서버로 접속되겠지..) 및 단순 로드벨런싱의 역할만 함
			
		->고객은 가장 가까운 CDN 서버의 ip를 받게되고 해당 서버로 request를 보내게 된다.
			-> request 받은 CDN은 해당 리소스를 갖고 있으면 바로 전달, 없으면 근처 CDN 에서 찾아서 전달, 거기도 없거나 너무 오래 됐으면 origin 서버로 부터 다시 받아 내어 전달해 준다.
				-origin 서버로 resource를 새로 요청하는 것을 cache fill request라 한다.
				-!!! CDN은 기본적으로 중간 캐시 서버로써만 역할을 한다. 일예로 cache fill request에 대해 origin이 에러를 전달하면 CDN은 그대로 에러를 내릴 뿐 다른 별다른 처리를 하는 것은 아니다.
				
-실제 CDN 서버의 동작 방식(추측??)
	-client sungilry.com 요청 -> DNS를 통해 가장 가까운 해당 고객의 CDN 서버 ip 획득
		->획득한 CDN ip로 요청 -> 1차 진입된 CDN 서버는 실제 해당 고객의 cache 서버는 아닌것 같고 실제 고객들의 cache 서버로 진입해 주기 위해 지역별로 구분되어 있는 (리버스)프록시 형태의 서버로 보임
				-?? 위 획득한 cdn ip는 예를 들자면.. 서울 지역의 쇼핑몰 사이트 고객들의 cache 서버로 연결해 주는 프록시 서버?? (request된 도메인에 따라 해당 고객의 cdn 캐시 서버로 분기되는듯)
				
		-위 과정에서 발생되는 의문??
			-SSL : https 접속의 경우 SSL은 어느 단계에 적용되야 하는가?? 프록시 서버?? 케시 서버?? 아님 origin 서버??
				-접속하는 Agent가 ssl 확인 과정을 어느정도로 꼼꼼히 하는가에 따라 다른것 같음, 프록시단에서 부터 일치해야 하는경우도 있어보이고 캐시서버만 일치하면 되는 경우도 있어 보임, 추후 좀더 확인 필요???!!!
				
	
	-이미지 캐싱 관련 : CDN이 캐싱하는 컨텐츠와 관련해서 이미지가 차지하는 비중이 큰 만큼 몇몇 부가 서비스를 제공함
		-이미지 리사이징 : origin의 이미지를 캐싱하면서 클라이언트의 요청시 다향한 크기로(주로 큰 아미지를 올려 놓고 다운사이징) 리사이징 하여 내려 준다.
		-실제 동작벙식 예 : 
			-CDN으로 부터 자신의 이미지 케시 서버의 주소를 할당 받는다 images-kr.sungilry.com (cdn 이미지 케시 서버 ip와 연결돼있겠지??)
			-html 소스에 이미지 파일 호출 경로를 위의 주소로 처리하고 파람값을 추가하여 원하는 이미지 크기를 요청 할수 있다.
				-<img src=https://images-kr.sungilry.com/products/cate1/111070101028_01.png?shrink=155:155&1595812564983>
					-?shrink=155:155 : 원하는 이미지 픽셀 값
					-&1595812564983 : 보통 cdn 을 이용하는 경우 서버 패치를 위해 코드를 빌드할때 static 파일(이미지, js, css등)들의 호출 url에 위와 같이 랜던값의(보통 빌드일시형태) 파람을 붙여
							-CDN이 새로운 파일로 인식하여 다시 읽어 가도록 처리를 한다. (CDN 뿐만 아니라 브라우저도 자체 캐시를 사용하지 않도록 하기위함도 있다)
							
										

[Node.js & NPM]
-설치 :
	-node.js 홈페이지를 통해 node.js 설치가 가능하며 보통 node.js를 설치하면 npm이 함께 설치됨. (node -v : 설치된 node.js 버전 확인, npm -v : 설치된 npm 버전 확인)

-node.js :
	-개념 :
		-As an asynchronous event-driven JavaScript runtime, Node.js is designed to build scalable network applications
		-Chrome V8 JavaScript 엔진으로 빌드된 JavaScript 런타임입니다. Node.js는 이벤트 기반, Non 블로킹 I/O 모델을 사용해 가볍고 효율적입니다. (chrome을 기반으로 한 jvm의 개념과 유사한 런타임 환경)
		-chrome base의 태생으로 실시간 웹 어플리케이션을 만들기에 적합하고 lock과 직접적인 i/o를 수행하지 않기 때문에 쉽게 확장 가능한 서비스가 개발 가능하다.
		-특정 js 파일을 실행할 수도 있고 특정 스크립트를 입력하여 실행할 수도 있는 cl 클라이언트를 제공한다. (일종의 컴파일러의 개념도 있어 보인다)

	-command :
		-node : 직접 스크립트를 작성하여 테스트 해볼수 있는 cl 환경을 제공한다.
		-node abc.js : abc.js 파일을 실행해 준다.
-npm(Node Package Manager) :
	-개념 :
		-Node Package Manager, 리눅스의 apt와 유사한 개념으로 javascript 모듈의 완성도를 확인 하여 storege에 올리는 관리 주체로서 사용자는 cl 클라이언트를 이용하여 다운 및 인스톨이 가능하다.
		-npm 을 통해 관리되는 패키지들은 브라우저 및 node.js 환경 (또는 그러한 개발환경)에서 사용하는 라이브러리, 컴포넌트 개념이다.
		-본인이 원하는 패키지를 직접 만들수 있도록 프로젝트(?) 개념을 제공하고 있는듯 (package.json 파일이 프로젝트 파일??),

	-package.json : 패키지를 정의 하는 메타파일(프로젝트 파일??)

	-package-lock.json : 패키지의 내부 dependency(그 dependency 마다 내부에 또 있구..) 마다 버전들이 있는데 그 하위 버전들까지 최상이 패키지는 알기 어렵다,
		-그리고 그 버전도 특정 버전이 아니고 범위로 지정되는 경우도 많아서 현재 나의 패키지를 위해 하위 패키지들이 어떤 버전으로 설치되어 있는지 알기 어려움,
		-그러한 일련의 모든 패키지 디펜던시 트리를 제공해 주는 역할을 한다. package.json 파일이 변경되는 시점에 변경된 내용을 기반으로 현재 설치된 정보를 재 정리 하게됨
		-dependency 모듈을 함게 배포하지 않는 경우 반드시 해당 파일도 같이 배포되야 해야 안정적임, (package-lock.json 파일도 git을 통해 관리 할것)

	-command :
		-npm init -y : 해당 폴더에 package.json을 생성해줘서 패키지를 구성할 수 있는 토대를 만들어 줌. 추가로 패키지를 인스톨하게 되면 node_modules(설치된 추가 패키지 저장 폴더) 및 package-lock가 생성
		-npm install mocha --save-dev : mocha라는 디팬던시를 설치해 주고 package.json에 반영해줌, --save(패당 패키지에서만 유효함) -dev(프로덕션 빌드시 포함안됨, 개발할때만 쓰겠다는..)
		-npm install mocha -g : mocha를 전역 install하겠다는 의미(사용자경로/AppData/Roaming/npm에 설치됨), 링크를 통해 특정 패키지에서 끌어 쓸수 있음
		-npm link mocha : 전역 설치된 패키지를 끌어다 현재 패키지에 적용할 수 있음

		-npm list : 현재 패키지에 구성된 트리
		-npm list -g : 글로벌 패키지 구성 트리
		-npm list -depth=0 : 1 댑스 까지만



[Central data repository]
	-개요 : 조직이 커지고 여러 프로젝트간 의존성과 복잡성이 늘어남에 따라 쉽고 조직적인 데이터 관리가 필요하게 되어 생성됨
		-여러 필요 lib(jar)를 저장하고 있는 하나의 lib Repository 이다, 각 lib에 대해 버전별로 관리를 하며 각 개발 pc및 빌드서버, 서비스 서버등에서 필요시 해당 lib를 중앙 repository로 부터 내려 받을 수 있다.
		-대표 상품 : sonatype Nexus
		
		
	-Nexus : maven, gradle 프로젝트 등에서 사용할 수 있는 대표 무료 repository 이다.
		-사용 방식에 따른 구분 : 서버의 논리적 위치에 따른 구분으로 자식이 보유하고 있지 않은 데이터를 요청 받으면 상위또는 동일 다른 서버에서 끌어 올수 있다.
			-Proxy Repository : 원격(public)에 원본 Repository를 두고(어떤 repository 상품이든) 중간 캐시 서버의 위치에 설치하여 사용하는 방식 
			-Virtual Repository : 여러개의 Repository를 그룹으로 구성하여 하나의 URL로 서비스 하도록 구성하여 사용하는 방식
			
		-저장 데이터 형식에 따른 구분 :
			-Snapshots : 조직에서 정식 릴리즈가 아닌 테스트를 위한 용도로 수시로 배포되는 데이터 저장소, 정확한 버전을 갖지 않고 snapshots 이란 명칭의 버전으로 관리된다.
			-Release : 조직에서 정식 릴리즈를 통해 배포된 데이터가 저장되는 저장소, 각 릴리즈 버전이 명확히 구분되어 관리된다.
			-3rd party : 제3의 벤더가 제공한 release 버전을 관리하는 저장소
		
		
		
		



[프로젝트 관리 툴]
-jira : 아틀라시안 에서 만든 프로젝트 관리 툴로 이슈 및 버그 추적, 칸반 보드등을 지원 한다.
	-구성요소 :
		-프로젝트 :
			-데이터 형식 :
				-이슈 :

			-뷰여 형식 :
				-백로그 :
				-작업중인 스프린트 :
				-배포 :
				-보고서 :
				-이슈 :
				-컴포넌트
				-WBS Gantt-Chart :

		-보드 : 프로젝트의 뷰어 형식의 구성 요소 이기도 하면서 프로젝트를 초월하여 구성도 가능하다.
			-대시보드 :
				-시스템 대시보드 : 기본으로 제공되는 대시보드로 프로젝트 목록 및 나에게 할된된 이슈등을 보여준다.
				-개인 대시보드 : 대시보도 관리를 위해 본인이 원하는 항목으로 구성된 대시보드를 만들 수 있다.
			-개인보드 : 직접 구성한 보드

			-WBS Gantt-Chart :

	-용어 :
		-scrum :
		-scrum team : 이러한 조직
		-product owner : 제품 책임자
			-product backlog : product owner 가 관리하는 해야할 일 목록
		-sprint : 특정 사이즈의 업무 주기
			-sprint backlog : sprint 마다 해야할 일 목록
		-increment : 매 sprint 마다의 결과물
		-scrum master : 팀이 과제를 완수할 수 있도록 지원 및 인도


[DB]
-백업 :
	-문리백업 : DB파일 자체를 복사
	-논리백업 : sql문 형태로 복사




[인증서]
-용어 : 
	Cipher Suites : 해당 호스트(서버 또는 클라이언트)가 사용 가능한 암호화 방식 내역
	Credential : 인증정보로 상황에 따라 id/ps가 될수도 있고 인증토큰이 될수도 있고 기타 인증서 정보가 될수도 있다.
	
-인증서 명칭 : 공인인증서, 공개키증명서, 디지털증명서, 전자증명서, 전자서명 등 여러 행태로 불린다.
-기본동작 : 
	-공개키는 사람들에게 공개된 키로 자신의 데이터를 공개키로 암호화 하여 전송한다.
	-비밀키는 주체자가 보관해야 해야하는 키로 공개키로 암호화된 데이터를 복호화 할수 없다.
	-공개키로 암호화 내용은 공개키로 복호가 안된다. 비밀키로 암호화한 데이터는 비밀키로 복호가 단된다.
	-공개키로 암호화한 데이터는 비밀키로 복호된다. 
	-비밀키로 암호화한 데이터는 공개키로 복호 된다.(인증서의 인증여부를 확인하는 용도로 사용하며 실제 서버 인증서에서 비밀키로 생성된 데이터가 클라이언트에 내려가지는 않는다??)
	
-인증서의 역할 :
	-본인(사람 or 서버) 확인 : 인증서가 공인된 기관으로 부터 인증 받았음을 증명함으로 해당 인증서를 갖은 사람은 실제 그사람임을 증명함 (인증서 발급시 여러 개인 정보를 요구함, 서버의 경우 도메인 및 회사 정보)
	-데이터의 암호화 : 인증서의 공개키 및 비밀키를 통해 인터넷 상에서 주고 받는 패킷을 암복호 함

-개념 : TLS(SSL)를 위한 서버인증서나, 은행, 온라인결제, 관공소 업무를 위한 개인인증서 또는 특정 사이트를 로그인하지 않고 들어가기 위해 로컬pc에 저장하는 로그인인증서(?)나 그 기본 개념은 동일하다.
	-개인 인증서를 서버 인증서로 사용하는 것은 이론적으로 가능 하지만 국내 기관에서 발행한 개인 인증서를 서버 인증서로 사용하지는 않는다.(국제 표준을 따르긴 하지만 한국인증서는 좀 특징이 있어서..)  서버 인증서의 경우 해외 인증기관 것을 사용한다.
		-한국적 특징은 관련법?에 따라 파일의 보관 저장 위치등이 좀 독특하며 그래서 추가적인 엑티브X 설치등의 불편함이 생기는 것이다. (그래서 이후 웹 표준인 브라우저 인증(저장)방식이 추가로 생기기도 했다)
		-또한 국내는 관련법에 따라 인증서의 종류가 좀더 있다(은행, 기본관공서용 vs 조달청, 특허청용 등등)

-구현 방식 (스펙) : 대표적인 구현 방식은 공개키 기반 구조(PKI) 방식이며 인증서를 발행하고 개인키와 공개키를 안전하게 나누어주는 역할을 담당하는 신뢰된 3자(인증기관)의 존재를 전제로 하고 있는 방식이다.
	-X.509: PKI 방식 인증서의  ITU-T 표준 방식 이다. https://www.venafi.com/blog/how-does-browser-trust-certificate
		-버전 :x.500 v1을 시작으로 x.509 v3버전으로 진화 (v3에는 Extension 을 이용해 데이터를 추가하는 기능이 포함됨)
		-주요 항목 :
			-issuer(발급자) : 해당 인증서의 발급자 (보통 인증서의 경우 자신의 인증서에 자신을 발급한 ICA, 그상위의 ROOT CA를 포함하여 구성)
			-public key(공개키) : 주체자에게 전달할 데이터를 암호화할 키값
			-issuer (발급자,기관) : 인증서를 발행한 인증 기관
			-fingerPrint (지문) : 해당 인증서 정보를 hash 한 값
			-signature(서명) : 해당 인증서의 fingerPrint 값을 private 키로 암호한 값(해당 인증서의 public 키로 복호화 했을때 fingerPrint와 동일하면 위조되지 않았음을 나타낸다.) !! 서명값은 사람이 보는 용이 않임으로 ssl 정보에 보통 표기 되지 않는다.
				-해당 인증서 자체의 위조 여부는 해당 인증서의 상위 인증서에서 동일한 방식으로 확인(Chain of Trust)
			
			-subject(신청시 CN값, 주체) : 인증서의 소유자 (사람이나 서버(도메인))
			-DNS Name(신청시 SAN값, 주체 대체 이름) : V3 확장 필드로 멀티 도메인 인증서인 경우 포함할 도메인 네임들(FQDN)

		-인증서의 트리 구조 : 인증서는 인증서를 인증해준 각 상위 CA의 인증서를 포함해야 한다??
			-인증서 경로 : naver.com의 인증서 안에는 상위 인증기관(GeoTrust RSA CA)의 인증서가 있고 해당 인증서 안에는 또 그 인증서를 인증한 인증서가 있어야 한다.(보통, 인증서-중간ICA인증서-RootCA인증서)
				-보통(CA -> ICA -> RootCA), 이러한 원리를 Chain of Trust 라고 한다.

		-인증서의 인증 : 운영체제, JVM, 브라우저등은 모든 ROOT CA의 인증서 정보 미리 갖고 있으며 이를 통해 최종 Root 인증서의 위조 여부를 판단할수 있다.
			-인증서의 유효성 검사 :
				-해당 인증서의 위변조 여부 :
					-인증서 내부에는 인증정보들을 해시한 후 인증 발급한 기관의 비밀키로 암호한 지문정보가 있다. 이 지문정보를 상위 CA의 공개키로 복호 했을때 해당 인증정보의 해쉬값과 동일한 값이 나오면 위변조 되지않은것으로 판단한다.
						-Root 인증서까지 확인을 한다 (근데 Root인증서의 인증은 Root 인정서의 공유키로 셀프 인증 한다는것 같은데.. 그러면 어찌 믿지?? 브라우저가 이미 가지고 있는 ROOT인증서의 공개키로 확인 할까?? 타 Root CA 공유키를 쓴다고도함)
							-답 : windows를 예로 시스템메뉴-컴퓨터인증서관리 에 신뢰할 수 있는 루트 인증 기관 목록에 ROOT CA들의 인증서가 있음. 해당 인증서가 일반 인증서들의 Root 인증서와 동일함. 즉 둘의 공개키를 비교하면 정본 인지 알수 있다

				-해지 및 패기 여부 : X.509는 인증서의 유효성(정식발급의 여부가 아니라 패기여부)을 판단하기 위한 CRL (certificate revocation list) 구현을 위한 표준도 포함한다
					-CRL은 해지, 패기된 인증서 목록을 받아와서 확인하는 것
					-OCSP는 서버를 통해 확인 요청 하는것, IETF에서 승인된 인증서 유효성 점검 방법은 OCSP(Online Certificate Status Protocol)이다. ??? OCSP에 대해 더 확인 필요!!
				
		-인증서 파일 종류
			-.CER : 암호화된 인증서, 복수의 인증서도 가능
			-.PEM (Privacy Enhanced Mail) : Base64로 인코딩 된 인증서로 "-----BEGIN CERTIFICATE-----"와 "-----END CERTIFICATE-----" 가운데에 들어간다.
				-PEM은 인증서를 위한 파일 포맷은 아니고 어떠한 데이터(바이너리)든(인증서든, 키파일, csr등) base64로 인코딩하여 텍스트 형태로 바이너리를 주고 받기 위한 파일 포멧이다. -----BEGIN -----END는 해당 데이터가 어떤 정보를 갖고 있는지 알려주는 해더의 의미이다.
				
			-.DER, .P7B, .P7C, .PFX, .P12 … : ????
			
		-인증서 관련 파일
			-.csr (Certificate Signing Request) : 인증서 생성을 위한 정보(private 키정보, 사용알고리즘 등) 를 담고 있는 파일로 보통 PEM 포멧의 형태임
			-.key : 보통 private key 정보를 갖고 있는 파일로 보통 PEM 포멧의 형태임. key 파일은 생성시 파일 자체에 암호를 걸게됨.


-개인 인증서 : 개인 인증서 또한 public key, private key로 구현되며 서버인증서와 거의 동일한 구조이다. 은행 및 전자 상거래 활용에서 어떤 방식으로 활용되는지는 확인 필요??


-코드 사인 인증서 : 어플리케이션(바이너리) 빌드시 해당 어플리케이션이 위조되지 않았는지를 확인하기 위한 방법
	-코드사인 = (어플리케이션 바이너리 + 어플리케이션의 바이너리 해시값을 인증서(공인)의 private key로 암호(서명값,signature)한 값 + 인증서(공인))
		-확인절차 : 코드사인된 파일을 어플리케이션, signature값, 인증서로 분리하여 signature 값을 인증서의 public key로 복호화 해서 실제 어플리케이션의 해시 값과 같은경우 변조가 없는 것으로 판단 (인증서의 위조여부는 기존 인증서와 동일한 절차로 확인)


-서버 인증서
	-인증서의 심사 레벨에 따른 구분 : 인증서의 인증 심사 수준?
		-DV (Domain Vailidation) 인증서 : 인증서의 주체 정보에 해당 인증서를 발급받은 도메인 정보가 나옴 (인증서를 발급해줄때 발급자가 해당 도메인의 소유자인지만 인증했다는 의미, 해커등이 속이고 있다면 해당 인증서가 내려 오지 못했음)
		-OV (Organization Validation) 인증서 : 인증서의 주체 정보에 해당 인증서를 발급받은 도메인 및 회사 정보가 나옴(특별히 나오는 내용은 많치 않은것 같고 발급시 회사 정보도 확인했다는 의미)
		-EV (Extended Validation) 인증서 : OV 인증서와 거의 동일한데 심사시 좀더 철저한 검증은 했다는 의미로 신뢰가 필요한 사이트(은행등)에서 주로 사용, 브라우저에따라서 녹색안전 표기가 되기도 하는 듯, 보통 OV보다 좀더 강화된 암호방식 사용

	-인증서의 주체 도메인 따른 구분 : 해당 인증서가 인증하는 도메인 정보의 제약
		-Single-Domain : 하나의 도메인에 대해서만 인증하는 인증서
		-Multi-Domain(MDC, UCC, SAN) : 여러 도메인에 대해서 인증가능한 인증서, 인증서 신청시 DCV 값으로 입력한 도메인들 이며 모두 FQDN 형태로 입력해야 한다. (보통 최대 250개 까지 가능)
		-Wildcard-Domain : *.xx.com 형태로, 특정 도메인의 서브 도메인을 모두 포함할 수 있는 인증서

	-Handshake 과정 (실제는 약간 더 상세함)
		-1. Client Hello (Client->Server) : 클라이언트가 client hello를 보냄으로 연결을 시도, 자신이 사용할 수 있는 암호화 방식 목록(Cipher Suites)을 서버로 전달한다.
		-2. Server Hello (Server->Client) : 서버가 클라이언트에 Server hello로 답변한다. 전달 받은 Cipher Suites 중 앞으로 사용할 암호 방식을 선택하여 응답해 준다(아무것도 사용할수 없는 경우 alert 메시지가 내려감)
			-Certificate : 서버의 인증서를 내려준다. (이때 하나의 ip에 여러 vHost로 서버가 운영중인 경우 실제 해당 도메인의 인증서를 내려줘야 한다.. 이때 서버가 보고 어느 호스트의 인증서를 내려줄지 판단하는 해더가 SNI 값이다!!!!)
			-Server Hello Done : Server Hello가 완료됨을 알려준다.
		
		-3. Client key exchange (Client->Server) : 클라이언트는 이후 대칭키 방식에 사용할 암호키(Pre-master Secret)를 생성하여 내려 받은 인증서의 공개키로 암호화 하여 서버로 전달
				-비대칭키 방식은 복호에 비용이 많이 들기때문에 계속해서 인증서를 이용하여 데이터를 주고 받는것이 아니라 대칭키 암호를 전달하는데만 사용하고 이후 실제 통신에서는 이 대칭키를 이용하여 암복호를 진행한다.
		
		-4. Encryted Handshake Message (Client->Server) : 협상한 암호 방식과 공유된 대칭키를 통해 실제 암호화한 데이터를 서버로 최초 전달하는 메시지 (일종의 테스트)
		-5. Change Cipher Spec, Finishe (Server->Client) : 서버쪽도 협의된 내용으로 암호화된 데이터를 내려주고 최종 Handshake를 끝낸다.
		
		-??? http는 state less 프로토콜로 request 마다 새로운 connection이 생기는데 그럼 매 request마다 SSL의 handshake 과정을 거치나???
			-그래서 Http는 state less 프로토콜의 한계를 극복하기 위해서 http(application layer) 하위 래벨인 TCP Sockek 단에서(Transfer Layer) 단에서 약간의 connection 위지를 할수 있게 해준다.
				-HTTP 해더의 Keep-Alive 값이다, 서버의 설정을 통해 적용가능하다, 완전한 표준이 아니라서 서버에 따라 보여줄수도 안보여 줄수도 있다 (apache의 경우 설정하면 보여주고 nginX의 경우 response에 표기하지 않는다.)
				-서버가 내려주는 response 해더를 통해 서버 설정을 확인할 수 있다.
					-Connection: Keep-Alive (사용중)
					-Keep-Alive: timeout=5, max=100 (5초간 socket 연결을 유지하여 같은 client에서 들어오는 rquest를 같은 tcp 세션으로 유지할수 있다. max는 해당 세션으로 100번까지만 연장할수 있다는 의미)
						-물론 해당 기능을 사용하기 위해서는 client도 해당 기능을 지원해야 함(모든 브라우저가 지원함)
						

-인증서 생성 개요: private key, CSR파일, certificate(인증서 파일), 아래 확장자는 생성 tool 및 인증기관에 따라 달라진다.
	-공인인증서 : 
		-모든 과정을 인증대행 기관 사이트를 통해 처리할수 있도 있고 사설인증서 만드는 방법과 병행할 수도 있다. (private key 및 CSR 파일은 사설 인증서를 만드는 tool을 이용해 만들고 CSR 파일을 공인증서 만드는 사이트로 전달하여 공인 인증서를 만들수도 있음)
			-공인인증서를 만들기 위해서는 물리적인 파일 생성과 별도로 요청자가 특정 도메인의 소유자가 맞는지를 확인하는 절차가 추가됨 (확인 방법은 여러 형태가 있으며 이를 DCV(Domain Control Validation) 인증이라 한다.
	
	-사설인증서 : openSSL 또는 java Keytool을 이용하여 생성 가능
		-생성과정 :
			-private key 생성 : key 파일명 지정(xx.key), 파일 비밀번호 설정가능
				-CSR 파일 생성 : 미리 생성한 key 파일에 추가 정보(요청자 정보, 도메인 정보등)를 포함하여 인증서를 생성하기 위한 중간 파일(xx.csr)을 생성 --> 자신이 만든 CSR 파일을 공인인증 기관으로 전달하여 공인인증서를 생성할 수도 있다.
					-key 파일 및 csr 파일 그리고 추가 정보(유효기간 등..)를 포함하여 인증서 파일(cert.pem)을 생성
				
	
	
-keyStore :
	-사전 개념 :
		-certificate : (일반적으로)특정 private key 대응하는 public key를 소유하고 있는 인증서(기타 암호 방식 및 인증 정차에 대한 정보를 포함하고 있다)
			-certificate chain : 특정 private key에 대응하는 certificate 그룹(?)
	-keyStore 개념 :	certificate 및 certificate chain 그리고 그에 대응하는 private key를 관리하는 인증서정보 보관소??
	
	-시스템 별 keyStore : 
		-원도우 Windows-MY(사용자들의 인증서및 개인키, 루트인증서들은 Windows-ROOT에 별도 저장) : 윈도우 시스템이 관리하는 keystore 타입이다. (윈도우의 네이티브 keyStore로 java등 외부 API에서 직접 접근할 수 없다.)	
			-private key, certificate, certificate chain 등을 저장 관리한다.(!!!??? private key, certificate, certificate chain은 keytool등에서 생성하는 것 같고 Windows-MY API에서 직접 생성하는 것 같지는 않음)
			-java를 통한 접근 : java 기본 API로는 접근 불가하면 window에서 제공한 SunMSCAPI(<JAVA_HOME>\lib\security에 위치)를 통해 사용이 가능하다.
			-https://www.pixelstech.net/article/1452337547-Different-types-of-keystore-in-Java----Windows-MY
		
		-자바 KeyStore (JKS) : Java JDK가 관리하는 인증서 보관소 이다 (특별한 위치를 지정하지 않으면 사용자의 홈디렉터리에서 .keystore 파일)
			-저장 항목 : 개발적 측면에서 Java 는 KeyStore 라는 인터페이스(java_home/jre/lib/security)를 통해 Encryption/Decryption 및 Digital Signature 에 사용되는 Private Key 그에 대응하는 Public Key 및 Certificate 를 추상화하여 제공하고 있다.
			-keytool : keystore를 관리하기 위해 JDK가 제공하는 CLI 유틸(openSSL과 유사), keytool로 인증서의 priviate key를 추출할 수는 없다. (하지만 다른 3rd 툴을 이용하여 추출은 가능 jksExportKey, KeyStore Explorer(key tool의 GUI버전)등등)
				-java keytool 활용 :
					-keytool을 이용해서 keystore 파일을 만들경우 다양한 파일 형태로 만들수 있다(keystore의 파일 표준은 여러 형태가 있다. jks_keystore, pkcs12_keystore 등등)
					-JAVA가 인식하는 ROOT CA 저장소에 특정 인증서를 추가 시킬 수 있다. (특정 root CA 인증서를 jvm에서 인자하지 못한다면 root 인증저장소에 수동으로 추가 할수 있다. 특별한 케이스일 듯?)
					
				
		
	-관련 편의 기능 : 
		-Mac (OSX) : 
			-Keychain : Keychain is the password management system in macOS, developed by Apple.(mac, IOS용 사용자와 관련된 비밀번호등을 관리하는 OS 레벨의 인터페이스 및 그 기능을 CGU로 제공, 말그대로 열쇠꾸러미)
				-개념 : 시스템에 로그인한 사용자가 다른 여러 용도로 사용하기 위한 비번을 저장해 놀수 있는 OS 레벨의 키 저장함, 사용자가 시스템에 로그인하면 해당 로그인 상태에서 특정 비밀번호등을 특정 앱으로 제공해 주는 인터페이스를 제공함.
				-사용자별 자장 위치 : ~/Library/Keychains/
				-저장 데이터 및 암호화 : 다양한 데이터를 저장 가능(타이틀, url, password, Secure Notes 등)함. password, Secure Notes의 경우 Triple DES 로 암호화 된다.
		
		-Windows :
			-자격 증명 관리 : 
				-windows 자격 증명 : 일반 자격 증명과 거의 동일한데 차이점은???
				-인증서 기반 자격 증명 : 도메인 또는 네트우크 주소에 인증서를 매핑하여 해당 위치로 이동시 시스템이 저장된 계정 정보를 제공하여 편리하게 연결해 주는 기능
				-일반 자격 증명 : 도메인 또는 네트우크 주소에 id, pw를 매핑하여 해당 위치로 이동시 시스템이 저장된 계정 정보를 제공하여 편리하게 연결해 주는 기능				
				-웹 자격 증명 : ???
		

[컴파일]
-용어
	-x86 : cpu 칩셋의 품번에서 유례한 것으로 x86 품번 계열의 칩셋은 32bit 명령어 체계를 이용했다. 운영체제 32bit를 지원
	-x64 : cpu 칩셋의 품번에서 유례한 것으로 적확한 명칭은 x84-64 이다. 해당 계열은 64bit 명령어 체계를 이용하며 운영체제 64bit를 지원


[Network]
-배경 : 
	-Ethernet : 네트워크 구성 방식의 하나로 현재의 인터넷을 구성하는 방식이다. 네트워킹 초기 시대에는 FDDI and ATM 등 여러 형태의 네트워크 구성 방식이 있었으나 현재는 Ethernet이 지배적이다.
	-IPS(Internet Protocol Suite) : 인터넷에서 컴퓨터들이 데이트를 주고 받는데 사용하는 프로토콜 모음으로 TCP/IP 가 가장 대표적이다.
	-Network Media(Network facility, Transmission medium) : 단계별 네트워크 장비(hub, swith, bridge, not, router..)

	-transmission rate : host가 데이터를 전송(port out)시키는 속도
	-propogation speed : 상대호스트(net media 일수도 end host 일수도) sender가 보낸 데이터를 받는데 걸리는 시간 (케이블, 실질적 거리, 거치는 Network Media 들에 따라 달라질수 있다.)

	-NAT(network address translation) : 컴퓨터 네트워킹에서 쓰이는 용어로서, IP 패킷의 TCP/UDP 포트 숫자와 소스 및 목적지의 IP 주소 등을 재기록하면서 라우터를 통해 네트워크 트래픽을 주고 받는 기술
		-NAT IP : 외부로 나갈때 표출되는 ip로 보면 된다. (공인 ip를 절약하기 위해 내부의 여러 호스트들이 외부로 연결될때는 하나의 NAT ip로 나가게 된다.)

	-RTT (Round-trip time) : RTT is the duration, measured in milliseconds, from when a browser sends a request to when it receives a response from a server. 
		-It’s a key performance metric for web applications and one of the main factors, along with Time to First Byte (TTFB), when measuring page load time and network latency.
	
	
-OSI 7 Layer :
	-7 Application Layer :
		-관련 프로토콜 : http, ftp, smtp, 
		-관련 장비 : L4-7-switch, web-switch, content-switch (특정 app 프로토콜에 대한 load balancing이 주 목적이다)
		
	-6 Presentation Layer : 
		-Data encryption/decryption : 어떤 의미에서 하는지 잘 모르겠음, ssl은 L5에서 처리 되는듯
		-Character/string conversion : 6레이어는 app레이어에서 내려온(또는 5레이어에서 올라온) 데이터를 사로 다른 기종간 데이터 교환이 가능하도록 standard 형식의 데이터 포맷으로 맞추는 작업을 한다.(char, integer는 몇바이트로 변환할지...등등)
			-각 host(pc, 서버, 전화기, tv)와 network device들간에 서로 인식하는 데이터 형식이 다르기 때문
		-Data compression : application 레벨과는 별도로 전송 효율성을 높이기 위해 standard 형식으로 변환된 데이터를 압축하여 아래 레이어로 내리거나 압축을 풀어 윗 레이어로 올린다.
		-Graphic handling : 내용 모르겠음??
	
	-5 Session Layer :
		-좀더 application 레이어에 가까운 개념으로 TCP connection establish를 setup, teardown 하는 관리적 주체 역할을 한다. (TCP connection은 좀더 하위레벨에서의 연결 상태라면 Session은 좀더 application 레벨의 프로세스급의 관리)
			-동일한 TCP port로 들어온느 여러 end point의 데이터를 상위 레별의 개념인 세션의 개념으로(동일한 endpoin) 묶어 위 레벨로 전달해 줄 수 있다.
			-in, out bound를 생각해 봤을때도 들어오는 나가는 데이터에 대해 동일 endpoint에 대해 session의 개념을 묶어 처리할 수 있게 해준다. (동일 세션(동일end host)에 대한 데이터의 결합등)
			-tcp 레벨의 connection이 끊기는 상황에서 상위 레이어 차원에서 복구 및 재 동기화를 처리할수 있다.
			-SSL(Secure Sockets Layer)은 이 레이어에서 동작하는 것으로 보임?? SSL 사용시 secure한 세션을 설정, 6레이어에서의 encryption은 어떤의미인지 정확히 모르겠음??
	
	-!!TCP/IP(4,3 레이어는 end host(os레벨?)에서 생성되고 관리되는 주체), tcp/ip 레이어가 in/out 상황에서 어떻게 다르게 처리되는지 확인 필요??
	-4 Transport Layer :
		-데이터 단뒤 : out->segment, in<-TCP메시지??
		-추가 주소 : Source = requester port 번호, Destination = server port 번호
		-관련 프로토콜 : TCP, UDP
		-관련 장비 : L4-Switch = L4-load-balancer = L4-Router = NAT
			-L4장비들은 여러 형태가 있을 수 있으며 그 기능은 대부분 유사하다. 하드웨어 기반의 L3에 추가적으로 port(프로토콜번호) 정보를 활용하여 여러 기능을 수행함 
		-host간 커넥션을 맺기전의 connection less 상태의 end to end(최종 host) 연결로 실제 최종 host(pc,서버)의 OS 및 App(대부분이 OS 영역일듯)와 연결되는 layer 이다.(물론 2,3레이어의 정보도 NIC를 통해 들어오긴 함)
			-port 번호를 근간으로 구분되며 L4에 5,6,7L 정보를 포함한다. 전송에서 발송하는 각종 에러에 대한 보정처리(데이터검증,재요청,순서재배열, 이러한 처리는 end host의 OS에서 하는듯??)를 처리한다.
			-out bound 시나리오 : app 데이터는 tcp 레이어에서(os) segment 단위로 나뉘어서(이때순서가명시됨) IP레이어라 내려가고 ip레이어에서는 해당 데이터에 대한 ip패킷을 구성한다.(L2 레이어의 frame 싸이즈 한계 때문에??)
			-in bound 시나리오 : ip레이어를 거쳐 tcp 레이어로 들어온 데이터는 순번을 참조하여 하나의 tcp 메시지로 조합되어(os) 상위 레이어로 올라간다. (상위 코딩 레벨에서는 조합된 메시지를 활용)
		
		-TCP : connection-oriented, 두 end host간 connection을 먼저 establish 한 후 데이터를 보내게 된다. 이후 리시버는 항상 수신받은 데이터에 대해 ack를 센드로 보내야하고(못받아도 못받음을 보내야함), 센더는 ack를 받아야 다음 패킷을 보냄
			-?? ack를 받아야 센더가 다음 패킷을 보낼텐데.. 왜 tcp에서 패킷 재정렬 기능이 필요할까?? 확인 필요!!??
				-?? 하나 하나씩이 아니라 몇개 쭉 보내고 그에대한 ack 쭉 보내고 이런식인것 같기도 함. 확인 필요!!??
			
			-TCP connection의 의미 : tpc방식은 실제 데이터를 보내기 전에 end 호스트간 센더는 앞으로 데이터를 보내겠다는 내용을 리시버는 보내라는 정보를 주고 받는데.. 이 관계가 끊기는 타임은 센더가 다 보냈어(complete), 리시버가 ok를 해야 한다.
				-센더가 complete을 보내기까지 두 호스트는 연경 상태 즉 connection established 상태로 간주되는 것이다.
				-그사이에는 주고 받는 패킷에 대해 두 end host는 ack를 수행하고 패킷 번호를 통해 순서 보정을 할수 있다.(센더는 팻킷을 순서데로 보내지만 패킷마다 실제 전달 경로(route)가 달라질수 있기 때문에 리시버는 다른 순서로 받아 질수 있다)
				
		-UDP : connectionless and unreliable protocol 이다. 센더는 리시버의 ack를 필요로하지 않으며 end host로 일방적으로 계속 데이터를 보낸다.(시간단축의 장점)
			-이러한 방식은 영상스트림, 게임, call 등과 같이 패킷하나하나의 데이터가 크게 중요하지 않은 경우에 사용될수 있다.
			
		-TCP레이어의 에러 컨트롤 이유 : 센더에 의해 세그먼트 팻킷이 잘 전달된다 하더라도 라우터등의 장비에 잠시 저장되는 과정에서(속도처리를 위한 큐잉과정) 데이터에 손상이 있을수 있기 때문이다.
		
	-3 Network Layer :
		-데이터 단위 : packet(=데이터그램?)
		-추가 주소 : Source = requester IP 주소, Destination = server IP 주소
		-관련 프로토콜 : IP, IPX
		-관련 장비 : IP Switch(L3 switch), NAT(Network Address Translation), Router
		-Network Layer 는 host의 logical Address(IP 주소) 에 대한 정보를 갖으며 해당 ip 정보를 통해 라우터는 최종 목적로 가는 최단 경로로 라우팅 한다.
			-데이터 패킷을 목적지(IP)까지 라운팅(Between inter and intra)하여 최종전달하는 역할을 한다.
			
	
	-2 Data link Layer :
		-데이터 단위 : frame (상위 레이어의 모든 데이터를 포함하여 한본에 보내지는 데이터 단위이다. 다시말해 frame안에는 TCP(http) 데이터가 포함되는 형태)
		-추가 주소 : Source = requester MAC 주소, Destination = server MAC 주소 (바라보는 주소 관점이 MAC 주소이다)
		-관련 프로토콜 : IEEE 802.2
		-관련 장비 : Bridge(두개의 LAN을 연결하는 기능과 함께 한쪽의 데이터가 불필요하게 다른쪽으로 넘어가지 않게하는 필터링 기능도 함), Switch(L2 Switch의 경우 dest Mac 주소가 명시되지않은 frame에 대해서는 연결된 전체 host로 브로드케스팅 하기도 함)
			-L2 media의 flow control :
				-Stop and Wait for flow control : 최종 host(pc,서버)가 ack를 보낸후에 다음 데이터 frame을 전송한다.
				-Sliding window : 몇개의 frame을 보내고 ack를 보낼지 media와 host가 미리 결정하고 해당 frame 갯수만큼 전송후 ack를 한다(시간 및 리소스 절약)
		-Data link Layer 는 host의 Physical Address(MAC 주소)에 대한 정보를 갖으며 에러 감지(에러수정은안함) 기능을 수행함 

		
	-1 Physical Layer : 
		-데이터 단위  : bits
		-관련 프로토콜 : EIA/TIA-232
		-관련 장비 : NIC, Hub, repeaters, Ethernet cable connectors
			-Nic, hubs, repeaters, Ethernet cable connectors등 네트워크 장비간의 통신 프로토콜이다. 
			-hub와 같은 L1 장비의 경우 ip는 물론 Mac 주소 어느것도 활용하지 않는다. (일반적인 허브는 그저 데이터를 copy하여 전체 연결된 end host로 전파만 함)
		-NIC, 스위치 등이 서로의 상태를 확인하고 transmission rate in the form of bits per second, 기계적인 통신 방식등을 서로 결정한다.
		-0,1과 같은 매우 row 데이타 형태의 시그널을 사용한다. 실제 데이터가 encapsulation되어 전달할수 있도록 한다.
		-!!?? NIC 및 네트워크 장비간에만 활요되는 레이어로 NIC를 통해 OS레벨로 올라올때는 제거되어 올라오는것 같음(또는 device간에만 활용되는 프로토콜인듯), 패킷캡처시에 보이지 않음.


-TCP 기타
	-options : 
		-connection Timeout :
		-So Timeout :
		-TCP keepalive : TCP 레이어에서 두 노드가 서로 살아있음을 알리기 위해 주고 받는 데이터 패키 및 그 매커니즘 이다. 주 목적은 상대가 살아있지 않은데 혼자 계속하여 대기하는 상태를 제거하기 위함이다. 
			-또한 NAT 장비의 경우 일정 시간동안 두 노드가 패킷 교환이 없는 경우 NAT 테이블에서 제거하는 하기때문에 이를 막기 위해서도 필요하다.(장시간 안쓰고 있는 커넥션에 대해서도 포트할당을 해준다면 한계가 있겠지?? 그래서 나름의 룰로 정리하겠지??)			
			-Keepalive time : 휴지상태에서 얼마동안 유지될경우 Keepalive를 보낼지를 정한다. 보통 2h (15분 미만으로는 설정하지 않는것을 권장)
			-Keepalive interval : Keepalive에 대한 응답을 받지 못한경우 얼마뒤에 다시 보내 볼찌.. (tcp_rexmit_interval 값보다 작은 값을 보내서는 안된다.)
			-Keepalive retry : Keepalive에 대한 응답이 없을때 몇번까지 보내보고 close 할지..
	
-UDP 기타
	-multicast :
	-broadcast :

	
	
[CODE SET]
-Encoding type : 

-URL Encoding : url 규격상 의미를 갖는 문자들(ex: &, =)이 있다 이러한 문자들이 key나 value에 사용될수 있기 때문에 이러한 값을 대처하기 위한 용도로 사용하는 인코딩이다.

-Entity Code(HTML Encoding) : 
	-엔티티 코드란 문서에서 특수 문자를 입력하기 위해 사용하는 코드 이다. 요즘은 UTF-8을 사용하여 특수문자가 깨지지 않지만 특수문자가 깨질수 있는 환경에서 계속 사용한다. (html 문서나 xml 문서등에서)
		-더 정확한 느낌은 url 인코딩과 마찮가지로 엔티티(태그문서, ex:html, xml..) 문서에서 사용되는 의미있는 문자들(ex: <,/,> 이 있다 이러한 문자들이 value에 사용될수 있기 때문에 이러한 값을 대처하기 위한 용도로 사용하는 인코딩이다.
		-앤티티 코드는 문자식 표현과 숫자식 표현이 있다 (ex : & -> &amp;(문자식), &#38;(수자식))



[OS poperating system]
-Application
-shell : 기본적으로 리눅스 OS에서 사용되는 용어
	-사용자가 kenel(+os)의 command를 사용할 수 있도록 연결해주는 인터페이스를 제공하는 단지!! 하나의 프로그램이다 다시 말해 하나의 운영체제에 대해 여러 shell을 설치할수도 있다, linux에서 기본으로 설치되는 대표 sehll은 bash, Bourne(최초쉘) 이다.
	-그럼 사용자가 직접 kenel에 명령을 날리지 왜 shell 인터페이스 만들었을까? kenel의 명령어는 더 세부적이고 사용자 활용이 떨어진다. shell은 그러한 kenel의 명령어를 이용해 사용자가 편의 명령어를 구현해논 것이고 script 문법을 제공하여 명령 조합을 만들게해준다.
	-그럼 윈도우의 command(CMD)와는 무엇이 다른가? CLI(command-line interfaces)환경을 통해 사용자의 명령어를 입력받는다는 점에서 동일하다 하지만 cmd 명령어는 windows에 국한되고 사용기능이 제한적이다 일예로 cmd에서는 |(pipe)를 통한 처리가 불가능함
	-그럼 터미널은 무엇인가? 터미널또한 단지 하나의 프로그램이다. 원격에서 서버로 접속하여 shell을 사용할수 있게 해주는 접속프로그램에 불가하다. 그래서 여러 종류의 터미널이 존재한다. (gnome-terminal, konsole, xterm...)
	-shell 작업을 할때는 root 권한을 사용하지 않도록 한다. 중요한 시스템 파일을 손상시킬수 있기때문에 일반적으로 root권한은 사용하지 않는게 좋다. 프롬프트가 #인것은 root로 접속됨을 의미한다.(다른 계정은 $로 표기된다)
	-그럼 요즘같이 GUI환경이 잘 되어 있는데 왜 굳이 CLI 환경에서 command를 사용해 작업할까? 가장큰 이유는 GUI환경에서는 특정 작업의 결과를 다른작업의 input으로 넘길수가 없어 사용자의 복잡한 작업을 처리하기 번거롭다.
		-GUI 환경에서는 파일 탐색기로 특정 디렉토리를 열어서 그안에있는 파일 정보를 확인하고 특정 이름이 포함된 파일을 삭제한다고 했을때 사람이 직접 열어서 파일명을 확인하고 일일히 삭제해야 하지만 shell을 사용하면 스크립트를 이용하여 하나의 명령어 조합을 만들어 낼수있다.
		
	-windows CMD : 
		-windows OS에서 제공(기본제공)하는 리눅스의 shell과 유사한 기능을 담당하는 프로그램이다. 다만 그 기능이 shell에 비해 약하고 shell의 기능중 매우 중요한 1차 커맨드의 처리결과를 2차 커맨드의 input으로 주기위한 |(pipe) 기능이 없다.
		-|(pepe) 기능이 없지만 .bat .com 스크립트(둘이동일?) 문법을 통해 shell의 기능과 유사한 기능을 구현 할수 있다.
			-.bat : batch language를 통해 command를 활용한 명령 스크립트를 만들수 있다(dos시대에서 유례). com 스크립트에 배해 상대적으로 오래된 기능이며 요즘은?(com도오래됨) com script를 사용하며 더 기능이 많다.
			-.cmd : batch language와 유사한 더 개선된 스크립트 이다. 더많은 많은 펑션과 로직을 제공한다. (.bat과 .com은 해석하는 interpreter 각각 다르다)
		
	-windows powerShell : windows CMD의 어드벤스 버전이다.(2006년 introduced), powershell 스크립트를 comdlet이라 부르기도 한다.
		-administrative 작업과 관련한 기능의 스크립트를 구성할 수 있다.
		-.net으로 빌드한 라이브러리를 직접 호출하여 활용 할수 있따.
		-리눅스 shell의 |(pipe)와 같은 기능을 제공하여 처리결과를 다음 command의 인풋으로 처리할 수 있다.
		-!!요즘 대세인 MS cloud 상품의 기능과 연결할수 있는 기능을 제공한다.
		-리눅스 시스템을 지원한다.(내용확인 필요!!??)
	
-kernel
	-컴퓨터 운영체제의 핵심이 되는 프로그램 영역으로 시스템의 모든 것을 통제하며 응용프로그램에 필요한 여러가지 로레벨단의 서비스 제공한다.
	-시스템 보안, 어플리케이션 프로세스간 스케중링 및 자원 할당, 하드웨어와 통신(하드웨어와의 통신을 위하여 각가의 모든 하드웨어와 일일히 프로토콜을 마출수 없기때문에 HAL 을 두고 좀더 추상화된 인터페이슬 제공하고 있다)
	
-HAL(hardware abstraction layer) : 하드웨어 추상화 레이어
	-커널이 모든 디바이스와 일일히 프로토콜을 마출수 없기 때문에 특정 디바이스류! 들에 대해서 공통된 기능을 추상화해 놓은 레이어 이다.
	-마우스를 예로 드면 커널이 세상의 모든 마우스 제조사와 프로토콜을 마출수 없기 때문에 마우스 기능(포인트좌표, 우클릭, 좌클릭 등등)에 대한 추상화 레이어를 만들어 두고 상위 레이어는 각 디바이스와 연결할때 HAL을 하나의 디바이스로 인식하여 인터페이스에 대한 처리를 하면된다.
	-그럼 HAL은 어떻게 디바이스와 프로토콜을 마추는가? 각 제조사는 기본적인 기능에 대해서는 이미 규격을 따로있을것이고 고유의 특정한 기능이 있다면 이 기능에 대해 디바이스 드라이버를 제공하여 OS HAL의 규격과 프로토콜을 마춰낼수 있다.

-device driver
	-항상 그런것은 아니지만 드라이버는 OS의 HAL 레이어와 특정 업체의 디바이스간 프로토콜을 마추는 용도로 사용한다. 드라이버는 좀더 로레벨적 프로그램으로 특정 메모리또는 회로에 비트값을 전달해주는 방식으로 디바이스를 컨트롤 할수 있게 해준다.
	-OS 상위레벨 또는 어플리케이션은 HAL을 바라보고 동작한다고 보면되고, 디바이스는 드라이버를 통해 HAL과 연결된다고 보면된다.
	
-device 
	-물리적 장치로 특정 메모리로 비트값을 받거나 회로로 비트값을 받는 형태의 통신을 통해 본연의 기능을 수행하게 된다.




[cmd, powerShell 명령어]
	-cmd :
		-where curl : 명령어가 어디에 설치되어 있는지 확인 할수 있다 (ex: curl 실행파일 위치)
		
	-powerShell :
		-
	



[wireShark]
-주요 filter :
	-ip : ip.addr==192.168.0.11, ip.src==, ip.dst==
	-프로토콜 : dns and Http, tcp and udp
	-port : tcp.port==443, 
	-tcp 네트워크 오류 관련 flags : tcp.analysis.flags
	-제외 : !(arp or dns or icmp)
	-특정 프로토콜의 팻킷을 모아 보기(하나의 세션? 정보로 모아 보기?) : 원하는 패킷 선택 후 오른쪽 버튼, follow, 스트림 선택
	-특정 프로토콜에 포함된 단어로 필터 : tcp contains facebook, udp contains facebook
	-http 요소로 검색 : http.request, http.response.code==200
	-tcp 요소로 검색 : tcp.flags.syn==1, tcp.flags.reset==1
	-기타 : sip && rtp
	
	
[cURL]

	-curl(client URL) : 다양한 통신 프로토콜(http, https, ftp, ldap...) 통하여 데이터를 주고받기(다운로드, 업로드) 위한 변의 툴 및 lib(c,c++용?), 다운로드용으로는 wget을 사용해도됨(더편리)
		-command-line tool 형태로도 사용 가능 : 주로 http(s) 용으로 사용하는듯
			-사용법 :
				-기본 :
					-curl http:xxx.com (다운받아 내용을 콘솔에 찍어준다.)
					-curl -o content.txt http:xxx.com (내용을 content.txt파일에 저장),  -O(대문자)를 사용할 경우 파일명을 지정하지 않아도 서버(xxx.com쪽)에 저장된 파일명과 동일한 파일명으로 저장해 줌(더편리함)
					
				-기타 : 
					-특정일 이후 파일이 변경된 경우만 다운 : curl -z 21-Dec-11 http://www.example.com/yy.html
					-응답코드(200,400,404,500)만 출력 : curl -L -k -s -o /dev/null -w "%{http_code}\n" http://www.example.com/yy.html , 인증및, 리다이렉션에 대한 처리와 관련한 여러 옵션들이 있음
				
			
		-lib형태(libcurl)로도 제공하여 개발자가 이용하여 개발도 가능하다. (c,c++용 라이브러리인듯)
			-사용법 : java의 경우 process 객체를 사용하여 시스템에 설치된(요즘은 linux, mac, windows에 기본설치 되어있는듯함) curl 명령을 직접 호출하여 사용할 수도 있으나.. 요즘은 비슷한 기능의 여러 lib가 많음(Apache HttpClient..)
				---------
				String[] commands = new String {"curl", "-X", "GET", "http://checkip.amazonaws.com"};
				Process process = Runtime.getRuntime().exec(commands);
				---------
		

	
	
[Hardware]
-HSM(hardware security module) : 하드웨어적으로 암호화를 제공하는 디지터 저장 장치, 매우 중요한 인증서 및 데이터등의 경우 일반 디스크가 아니라 해당 저장장치에 저장 보관 할수 있다

-IRQ(Interrupt Request) : 컴퓨터의 보드에 연결되어 있는 주변기기들이 어떤 일이 발생하였을때 이를 CPU에 알리기위한 일련의 처리, cpu에게 알리는 일을 interrupt라고 하며 이런 line을 IRQ라고 한다.
	-CPU는 이러한 interrupt를 받으면 우선 순위에 따라 하던 일을 중단하고 그 요청을 받아 다른 일을 처리하게 된다.
		-주요 IRQ 역할 및 순서
			-0 IRQ 타이머
			-1 키보드
			-2 IRQ 캐스 케이드 공유
			-3 시리얼포트 2, COM2, COM4 ( 모뎀 / 마우스)
			-4 시리얼포트 1, COM1, COM3 ( 모뎀 / 마우스)
			-5 LPT2 병렬포트 혹은
			-6 FDD 컨트롤러
			-7 LPT1 병열 포트 등 혹은 사운드카드
			-8 RTC( Real Time Clock)
			-9 예비, 주로 미디 카드(MPU401)에서 사용 , SOUND ,VGA . USB, MPEG II
			-10 예비 , SOUND ,VGA . USB,MPEG II,
			-11 예비, SCSI 아답터, SOUND ,VGA . USB,MPEG II
			-12 PS/2 마우스
			-13 코프로세서 (수치처리보조연산자 )
			-14 IDE 하드 컨트롤러 Primary
			-15 IDE 하드 컨트롤러 Secondary
			
			


